;;; -*- Mode:Lisp; Syntax:Common-Lisp; Package:STORAGE; Lowercase:T; Base:8; -*- 
;;;>
;;;> *****************************************************************************************
;;;> ** (c) Copyright 1998-1982 Symbolics, Inc.  All rights reserved.
;;;> ** Portions of font library Copyright (c) 1984 Bitstream, Inc.  All Rights Reserved.
;;;>
;;;>    The software, data, and information contained herein are proprietary to,
;;;> and comprise valuable trade secrets of, Symbolics, Inc., which intends 
;;;> to keep such software, data, and information confidential and to preserve them
;;;> as trade secrets.  They are given in confidence by Symbolics pursuant 
;;;> to a written license agreement, and may be used, copied, transmitted, and stored
;;;> only in accordance with the terms of such license.
;;;> 
;;;> Symbolics, Symbolics 3600, Symbolics 3675, Symbolics 3630, Symbolics 3640,
;;;> Symbolics 3645, Symbolics 3650, Symbolics 3653, Symbolics 3620, Symbolics 3610,
;;;> Zetalisp, Open Genera, Virtual Lisp Machine, VLM, Wheels, Dynamic Windows,
;;;> SmartStore, Semanticue, Frame-Up, Firewall, Document Examiner,
;;;> Delivery Document Examiner, "Your Next Step in Computing", Ivory, MacIvory,
;;;> MacIvory model 1, MacIvory model 2, MacIvory model 3, XL400, XL1200, XL1201,
;;;> Symbolics UX400S, Symbolics UX1200S, NXP1000, Symbolics C, Symbolics Pascal,
;;;> Symbolics Prolog, Symbolics Fortran, CLOE, CLOE Application Generator,
;;;> CLOE Developer, CLOE Runtime, Common Lisp Developer, Symbolics Concordia,
;;;> Joshua, Statice, and Minima are trademarks of Symbolics, Inc.
;;;> 
;;;> Symbolics 3670, Symbolics Common Lisp, Symbolics-Lisp, and Genera are registered
;;;> trademarks of Symbolics, Inc.
;;;>
;;;> GOVERNMENT PURPOSE RIGHTS LEGEND
;;;> 
;;;>      Contract No.: various
;;;>      Contractor Name: Symbolics, Inc.
;;;>      Contractor Address: c/o Ropes & Gray
;;;> 			 One International Place
;;;> 			 Boston, Massachusetts 02110-2624
;;;>      Expiration Date: 2/27/2018
;;;>      
;;;> The Government's rights to use, modify, reproduce, release, perform, display or
;;;> disclose this software are restricted by paragraph (b)(2) of the "Rights in
;;;> Noncommercial Computer Software and Noncommercial Computer Software Documentation"
;;;> contained in the above identified contracts.  No restrictions apply after the
;;;> expiration date shown above.  Any reproduction of the software or portions thereof
;;;> marked with this legend must also reproduce the markings.  Questions regarding
;;;> the Government's rights may be referred to the AS&T Contracts Office of the
;;;> National Reconnaissance Office, Chantilly, Virginia 20151-1715.
;;;> 
;;;>      Symbolics, Inc.
;;;>      c/o Ropes & Gray
;;;>      One International Place
;;;>      Boston, Massachusetts 02110-2624
;;;>      781-937-7655
;;;>
;;;> *****************************************************************************************
;;;>

;;; D,#TD1PsT[Begin using 006 escapes](1 0 (NIL 0) (NIL :ITALIC NIL) "CPTFONTI")This file is shared between L-machines and I-machines.

0
;;;; Constants
#+IMach
(defconstant *ecc-log-size* 200) ;; the number of elements in *ecc-error-log*
#+IMach
(defenumerated *ecc-error-status*
	       (ecc-error-repaired		;repaired by scrubber
		 ecc-error-stuck		;still broken after scrubbing
		 ecc-error-ignored		;already went to disk, don't bother
		 ecc-error-virtual		;rest are errors not found by scrubber
		 ecc-error-physical		
		 ecc-error-unknown)
  1)						;start at 1 so 0 is invalid


;;;; Variables

;;; Parameters
(defwiredvar *storage-debug* nil "True when debugging storage (may be obsolete)")
(defwiredvar *flushable-min* 1000 "Threshold of flushable pages to call replacement algorithm")
(defwiredvar *unwired-min* 1000 "Minimum number of unwired pages")
(defwiredvar *load-map-swapin-quantum* 32. "Default number of load map pages to prefetch")
(defwiredvar *enable-sysout-at-cold-boot* nil "SYSOUT gets enabled at cold boot when true")
(defwiredvar *sysout-enabled-p* nil "SYSOUT actively enabled when true")
(defwiredvar *sysout-generation-number* 0)

(defwiredvar *load-pages-to-swap-area-p* nil
  "World load pages are incrementally copied to swap area when true.")

(defwiredvar *load-pages-to-existing-swap-space-p* t
  "Unmodified world load pages are written back to the swap area if they're part of
a block of swap space allocated for a nearby modified world load page.")

(defwiredvar *background-modified-write-quantum* 20
  "Number of flushable queue entries to consider for background writing.")

(defwiredvar *ecc-error-log*)    ;; a circular array comprising of ecc error and address pairs
(defwiredvar *ecc-log-ptr*)      ;; a pointer to the last element updated in *ecc-error-log*
(defwiredvar *ecc-log-counter*)  ;; the number of ecc errors logged

(defwiredvar *ecc-notification-on*)  ;; set when notification is on
(defwiredvar *ecc-process* nil)      ;; the ecc handler 

;;; Page ages may be from 0 to (1- %age-size), where 0 means the clock algorithm succeeds
#+3600 (defwiredvar *normal-page-age* 1 "Usual age to start a normal page at")

;;; User visible variables
(defwiredvar *page-trace-array* nil "NIL to disable page trace, else an array")
(defwiredvar *page-trace-in-progress* 0)
(defwiredvar *page-trace-start-time* nil)
(defwiredvar *page-trace-first-done* nil)
(defwiredvar *page-trace-enables* -1)
(defwiredvar *page-fault-exit-function* nil)

;;; Hooks needed for metering system.
(defwiredvar *enable-metering-on-page-fault* nil)
;; initialize when metering system is loaded.
(defwiredvar *page-fault-metering-trigger* nil) ;; (metering:find-trigger 'page-fault))
(defwiredvar *page-fault-end-metering-trigger* nil) ;;(metering:find-trigger 'page-fault-end))
;; not used for value, so they don't really need to be wired.  But for safety...
(defwiredvar page-fault)
(defwiredvar page-fault-end)
#+IMach (defwiredvar *page-fault-program-counter*)
#+IMach (defwiredvar *page-fault-frame-pointer*)
#+IMach (defwiredvar *page-fault-control-register*)

#+VLM (defwiredvar *vm-coprocessor-in-use* nil)
#+VLM (defwiredvar *vm-coprocessor-saved-reply* nil)
#+VLM (defwiredvar *vm-coprocessor-collisions* 0)

#+VLM (defwiredvar *saved-esrt* nil)

;;; the special area that contains the esrt
;;; these are filled in by the cold load generator
(defwiredvar %gc-table-area-region)
(defwiredvar %gc-table-area-region-origin)
(defwiredvar %gc-table-area-region-length)

;;; These are filled in by the cold load generator.  This area is used for dynamic allocation
;;; of the wired structures used in the disk driver and other I/O software.  It's in normal
;;; virtual address space, but all the pages in it are wired and are allocated by allocate-
;;; -unmapped-memory (the name is an historical artifact).  It's exactly like page-table-area,
;;; with the important difference that the GC scavenges it.
#+IMach (defvar-wired %wired-dynamic-area-region)
#+IMach (defvar-wired %wired-dynamic-area-region-length)
#+IMach (defvar-wired %wired-dynamic-area-region-origin)

;;; INITIALIZE-STORAGE-ARRAYS in the cold-load generator initializes the fixed and
;;; dynamically allocated arrays.
(defwiredvar storage-exists nil)		; True if initializations have been performed
(defwiredvar *storage-cold-boot* t)		; When T the next boot causes a cold boot
(defwiredvar *netboot-in-progress* nil)		; T if storage-exists, but netboot not complete
(defwiredvar *page-fault-depth*)		; Depth of faults: 0 no fault in progress.
(defwiredvar *last-aux-page-fault-vma*)		; VMA of last page-fault on top of aux stack
#+3600 (defwiredvar *phtc*)			; Page hash table cache
#+3600 (defwiredvar *phtc-size*)		; Page hash table cache size
(defwiredvar *pht*)				; Page hash table
(defwiredvar *pht-size*)			; Page hash table size (in entries)
#+3600 (defwiredvar *pht-lookup-last-vpn*)	; Last VPN argument to PHT-LOOKUP/PUT
#+3600 (defwiredvar *pht-lookup-last-index*)	; Cached result if above is non-NIL.
#+3600 (defwiredvar *pht-probes*)		; Depth meters, indexed by pht probe depth
#+IMach (defwiredvar *pht-collision-counts*)	; Parallel table to PHT
#+IMach (defwiredvar *pht-collision-counts-base*); Base address of above
#+IMach (defwiredvar *pht-collision-count*)	; Number of buckets with collision count  0
#+IMach (defwiredvar *pht-rehashes* 0)		; Number of times PHT completely reorganized
(defwiredvar *mmpt-y*)				; Main Memory Y subscript table
#+IMach (defwiredvar *mmpt-y-base*)		; Base address of above
(defwiredvar *mmpt-y-to-ppn-y*)			; Main Memory Y subscript table giving PPN Y
#+IMach (defwiredvar *mmpt-y-to-ppn-y-base*)	; Base address of above
(defwiredvar *mmpt*)				; Main Memory page table
#+IMach (defwiredvar *mmpt-base*)		; Base address of above
(defwiredvar *mmpt-size*)			; Size of MMPT
(defwiredvar *mmpt1*)				; Auxiliary MMPT (contains mmpt-thread)
#+IMach (defwiredvar *mmpt1-base*)		; Base address of above
(defwiredvar *smpt*)				; Secondary Memory page table
(defwiredvar *smpt-cached-vpn*)			; VPN of last smpt entry looked up
(defwiredvar *smpt-cached-n-pages*)		; Number of pages described by last entry
(defwiredvar *smpt-cached-dpn*)			; DPN of last entry
(defwiredvar *smpt-cached-node*)		; Node containing last entry
(defwiredvar *smpt-cached-index*)		; Index into node containing last entry
(defwiredvar *load-map-cached-vpn* nil)		; VPN of last load map entry looked up
(defwiredvar *load-map-cached-n-pages*)		; Number of pages described by last entry
(defwiredvar *load-map-cached-dpn*)		; DPN of last entry
(defwiredvar *prefetch-frames*)			; Array used by prefetch
(defwiredvar *load-bitmaps*)			; Array of bitmaps for each oblast
(defwiredvar *sysout-bitmaps* nil)		; Array of bitmaps for each oblast
(defwiredvar *pending-vpn*)			; Array of VPNs pending flush-write
(defwiredvar *pending-indices*)			; Parallel to above of mmpt-index or NIL
(defwiredvar *inhibit-read-only-in-progress*)	; When > 0 ignore %%region-read-only
(defwiredvar *transporter-read-only-vpn*)	; A read-only page to which GC is writing
(defwiredvar *read-only-n-written-pages*)	; Number of pages written inside inhibit
(defwiredvar *read-only-written-pages*)		; Array of MMPT indices
;;; *CREATING-DYNAMIC-SPACE* is true if we are creating space to grow the SMPT
;;; or the ESRT.  It prevents STORAGE-BACKGROUND-FUN from doing anything that
;;; could recurse back into the routines for manipulating SMPT and ESRT, thus
;;; it is effectively a lock on those data structures.  While growing the SMPT,
;;; it is possible to call (via PREPARE-FRAME and GC-PAGE-OUT) into the ESRT routines.
(defwiredvar *creating-dynamic-space*)		; When true locks out background writes
(defwiredvar *flushable-queue-head*)		; MMPT index of first frame in flushable queue
(defwiredvar *flushable-queue-tail*)		; MMPT index of last frame in flushable queue
(defwiredvar *flushable-queue-modified*)	; MMPT index of flushable queue background scan
#+3600 (defwiredvar *mmpt-replaceable-ppn*)	; PPN for replacement algorithm scan
#+IMach (defwiredvar *flushable-scan-pht-index*)	; PHT index for replacement algorithm scan
;;; The garbage collector has to determine whether or not there are wired pages in the space
;;; it's about to condemn.  Since the algorithm takes time proportional to the size of main
;;; memory, and has to be run before every flip, the storage system gives the GC some hints
;;; about whether or not any interesting pages have been wired recently.  For the 3600, this
;;; is just a sequence-number the GC can look at, for the I-machine keep a per-zone count.
(defwiredvar *wire/unwire-tick*)		; Incremented whenever a frame is un/wired
#+IMach (defwiredvar *zone-count-wired-pages*)	; Per zone count of frames wired

#+IMach (defparameter-wired *maximum-wired-control-stack-pages* 72.)
#+IMach (defparameter-wired *maximum-wired-pages-per-stack* 8.)
#+IMach (defvar-wired *wired-control-stack-pages*)
#+IMach (defvar-wired *active-stack-groups-head*)
#+IMach (defvar-wired *active-stack-groups-tail*)
#+IMach (defvar-wired *count-active-stack-groups*)

;; This needs to be wired on Ivory so REINITIALIZE-PHT-AND-MMPT can reset it upon
;; warm boot.  It has to do this because it can move pages around and cause the
;; scavenger to miss the pages.  Since the 3600 scans by phyisical address,
;; that's not an issue there.
(si:declare-storage-category :variable si:*scavenger-resident-pages-state*
			     #+3600 :safeguarded #+imach :wired)
(defvar si:*scavenger-resident-pages-state*)	;L machine:  Next physical address to do
						;I machine:  Next PHT index to do

;;; T when we are inside ESRT-INSERT
;;; This detects MAKE-ESRT-NODE calling CREATE-DYNAMIC-SPACE-FOR-ESRT, which can
;;; call GC-PAGE-OUT, which can call ESRT-INSERT to delete an ESRT entry or
;;; to update an ESRT entry to be the same as it already is or to have fewer
;;; bits set in its bit mask than it already does.
;;; Note that the existing ESRT entry may not be findable at this time, because
;;; the outer ESRT-INSERT is in the middle of adding another level to the tree.
;;; Because GC-PAGE-OUT will not be called for a page whose GCPT bit is set, we can
;;; rely on the existing state of the ESRT being sufficient, and can simply ignore
;;; GC-PAGE-OUT's request to update the ESRT.  At worst this will cause an extra
;;; page fetch in the next garbage collection.
;;; Note that the ESRT-DELETE routines never call MAKE-ESRT-NODE and that
;;; the ESRT-DELETE routines can never be called while inside of ESRT-INSERT.
(defwiredvar *esrt-lock* nil)

;;; T while we are inside any part of the storage system that might examine or modify
;;; a PHT or MMPT entry, NIL otherwise.  The disk driver uses this to tell when it's
;;; safe to run completion routines.
#+IMach (defwiredvar *storage-lock* nil)

;;; Set to NIL by the storage system when cold booting, T thereafter.  Used to decide
;;; whether to reuse data structures or create fresh ones during initialization.
(defvar-wired *disk-exists-p* nil)

;; These are filled in by the cold load generator
(defwiredvar %page-table-area-region)		; Region number of page table area
(defwiredvar %page-table-area-region-length)	; Region-length for page table region
(defwiredvar %page-table-area-region-origin)	; Region-origin for page table region

(defwiredvar *pma-free-pointer*)

(defconstant %n-page-waiters 10)
(defwiredvar *page-waiter-vpn*)			; VPN for which a process is waiting.
(defwiredvar *page-waiter-process*)		; Handle of waiting process.
(defwiredvar *allow-scheduling-on-page-faults* nil)

#+3600
(si:declare-storage-category :function-cell process::block-for-page-fetch :wired)

;;; Meters
(si:define-wired-meters *storage-meters*
  ;; Entry point timings
  #+3600 *ms-time-sequence-break*		; Total time spent in sequence break
  *ms-time-page-fault*				; Total time spent in page fault
  *ms-time-create-pages*			; Total time spent creating CONS pages
  *ms-time-user-prefetch-pages*			; Total time spent in explicit prefetching
  *ms-time-destroy-pages*			; Total time spent freeing swap space
  *ms-time-wiring-and-unwiring-pages*		; Total time spent wiring and unwiring pages
  #+IMach *ms-time-wiring-and-unwiring-stack-pages*
  *ms-time-stack-wiring-manager*
  *ms-time-user-flush-pages*			; Total time spend flushing pages
  ;; Internal timings included in the entry timings
  *ms-time-pending-wait*			; Time in wired-wait for not-pending-p
  *ms-time-page-idle-wait*			; Time in wired-wait for page-idle-p
  *ms-time-find-frame*				; Time finding a flushable frame to use
  *ms-time-pending-queue-full*			; Time in wired-wait for pending queue
  *ms-time-write-lock-wait*			; Time waiting for write-lock to clear
  *ms-time-smpt-create*				; Time creating a new SMPT entry
  *count-usable-pages*				; Count of usable main memory page frames
  ;; Start usable page counts
  *count-normal-pages*				; Count of normal pages
  *count-flushable-pages*			; Count of free pages
  *count-busy-pages*				; Count of pages with disk i/o in progress
  *count-wired-pages*				; Count of wired pages
  ;; Sum of above should equal usable pages.
  *count-locked-pages*				; Number of pages with the frame locked
  *count-pending*				; Number of VPNs pending flush-writes
  *count-swap-pages*				; Total number of pages in swap space
  *count-remaining-swap-pages*			; Number of available pages in swap space
  ;; Start page fault counts
  *count-map-misses*				; Number of map miss faults
  *count-page-fetches*				; Number of hard page faults
  *count-page-fetch-user-waits*			; Number of hard page faults we could schedule across
  *count-write-first-faults*			; Number of write-first faults
  *count-flushable-page-faults*			; Number of references to flushable pages
  *count-prefetched-page-faults*		; Number of references to prefetched pages
  *count-busy-page-faults*			; Number of references to pages in disk wait
  *count-inhibited-read-only-faults*		; Number of writes to read-only pages permitted
  ;; Sum of above meters should equal total number of page faults
  *count-load-fetches*				; Number of count-page-fetches from load map
  *count-load-prefetches*			; Number of prefetches from load map
  *count-created-pages*				; Number of pages created by consing
  *count-page-prefetches*			; Number of actual disk prefetches
  *count-discarded-prefetched-pages*		; Number of discarded prefetched page's
  *count-forced-modified-page-writes*		; Number of waits for write of a modified page
  *count-smpt-inserts*				; Number of inserts into SMPT (num of entries)
  *count-smpt-right-inserts*			; Inserted into neighboring right node
  *count-smpt-left-inserts*			; Inserted into neighboring left node
  *count-smpt-appends*				; Created a new empty node
  *count-smpt-splits*				; Created a node dividing full nodes contents
  *count-smpt-empty-node-steals*		; Stole some entries to avoid becoming empty
  *count-smpt-empty-node-shifts*		; Stole all entries to avoid becoming empty
  *count-smpt-balances*				; Globally balanced the SMPT
  #+3600 *count-pht-linear-probes*		; Number of probes after rehash overflow
  *count-flushed-pages*				; Number of normal pages ever flushed
  *count-flushed-modified-pages*		; Number of those that were modified
  #+IMach *count-replacement-algorithm-steps*	; Number of frames scanned by clock algorithm
  )


;;;; Initialization

;;; Add a dynamic array which was allocated by grabbing contiguous
;;; physical addresses to the paging tables.  The address in the array
;;; header is in vma=pma space but we account for the pages in
;;; page-table-area
#-VLM
(defwiredfun include-dynamic-array (array name starting-vma &optional (byte-packing 0))
  (declare (values next-vma))
  (let ((pma (ldb %%vma-pma (%pointer (array-indirect-pointer array))))
	(words (rot (array-long-length-field array) (- byte-packing))))
    (unless (= starting-vma (address-plus %page-table-area-region-origin
					  (region-free-pointer %page-table-area-region)))
      (wired-ferror :fatal
		    "Mis-ordered allocation in PAGE-TABLE-AREA including ~A"
		    name))
    ;; sometimes the arrays are not contiguous, either due to alignment
    ;; or skipping bad pages; in this case, we skip to the next virtual
    ;; page so we don't map the same vpn to two different ppn's
    (unless (= (ldb %%vma-word-offset pma) (ldb %%vma-word-offset starting-vma))
      (setf starting-vma
	    (dpb pma %%vma-word-offset (address-plus starting-vma page-size))))
    (let* ((next-vma (address-plus starting-vma words))
	   (next-free-pointer (address-difference next-vma %page-table-area-region-origin)))
      (unless ( %page-table-area-region-length next-free-pointer)
	(wired-ferror :fatal
		      "Exceeded virtual address space of PAGE-TABLE-AREA including ~A"
		      name))
      (loop for vpn from (extract-vpn starting-vma)
	    for ppn from (extract-ppn pma) to (extract-ppn (address-plus pma (1- words)))
	    do
	(let ((mmpt-index (mmpt-lookup ppn)))
	  (cond ((or (null mmpt-index)
		     ;; "Bad" pages don't exist either
		     (= (mmpt-status mmpt-index) %mmpt-status-frame-error))
		 (wired-ferror :fatal "Trying to include space for paging table ~A, ~
				     but PPN ~O ~A"
			       name ppn (if (null mmpt-index) "doesn't exist" "is bad")))
		(( (mmpt-invalid-vpn mmpt-index) 0)
		 (create-page-in-frame mmpt-index vpn))	;+ A little slow...
		((= (mmpt-vpn mmpt-index) vpn))
		(t
		 (wired-ferror :fatal "Trying to preload VPN ~O of paging table ~A, ~
				     but page already has VPN ~O loaded"
			       vpn name (mmpt-vpn mmpt-index))))
	  (when ( (mmpt-status mmpt-index) %mmpt-status-wired)
	    (wire-frame mmpt-index (pht-lookup vpn)))))
      (setf (region-free-pointer %page-table-area-region) next-free-pointer)
      next-vma)))

;;; Update the paging datastructures to include space for which the virtual address
;;; has already been allocated.
#-VLM
(defwiredfun include-preloaded-space (vma-low vma-high pma-low &optional (fun #'wire-frame))
  (loop for vpn from (extract-vpn vma-low)
		below (extract-vpn (address-plus vma-high page-size -1))
	for ppn from (extract-ppn pma-low)
	do
    (let* ((mmpt-index (mmpt-lookup ppn))
	   (pht-index
	     (cond ((null mmpt-index)
		    ;; --- we don't check for bad-pages in here, the fep
		    ;; will have had to deal with that already
		    (wired-ferror :fatal "Trying to include space for preloaded area ~A, ~
					  but PPN ~O doesn't exist"
				  vma-low ppn))
		   (( (mmpt-invalid-vpn mmpt-index) 0)
		    (create-page-in-frame mmpt-index vpn)
		    (pht-lookup vpn))
		   ((= vpn (mmpt-vpn mmpt-index))
		    (pht-lookup vpn))
		   (t
		    (wired-ferror :fatal "Trying to preload VPN ~O at PPN ~O in ~A ~
				          space, but page already has VPN ~O loaded"
				  vpn ppn vma-low (mmpt-vpn mmpt-index))))))
      (when ( (mmpt-status mmpt-index) %mmpt-status-wired)
	(funcall fun mmpt-index pht-index)
	#+3600 (setf (mmpt-modified mmpt-index) 1)
	#+IMach (setf (pht-modified pht-index) 1)))))

;;; Update the paging datastructures to include space for which there is no virtual
;;; address.  Allocate some vma space from the paging-table-area.
#+3600						;Yes, #+3600.  This is unused in IMach
(defwiredfun include-preloaded-physical-space (&rest pma-n-word-pairs)
  (let ((prev-ppn nil)
	(vma (address-plus %page-table-area-region-origin
			   (region-free-pointer %page-table-area-region))))
    (loop for (pma n-words) on pma-n-word-pairs by #'cddr
	  do (cond ((not (zerop n-words))
		    (if (neq prev-ppn (ldb %%pma-page-num pma))	; In case not contiguous
			;; Must page align the vma
			(setq vma (dpb 0
				       %%vma-word-offset
				       (address-plus vma (1- page-size)))))
		    (include-preloaded-space
		      vma (address-plus vma n-words) pma #'wire-frame)
		    (setq vma (address-plus vma n-words)
			  prev-ppn (ldb %%pma-page-num (address-plus pma n-words))))))
    (setq vma (dpb 0 %%vma-word-offset (address-plus vma (1- page-size))))
    (setf (region-free-pointer %page-table-area-region)
	  (address-difference vma %page-table-area-region-origin))))

#+(and IMach (not VLM))
;;; Update the paging datastructures for some pages in vma=pma space.  The corresponding
;;; MMPT entries get the virtual address and the frames are permanently wired.  The
;;; addresses are not put in the PHT.
(defwiredfun include-fixed-space (vma-low vma-high)
  (with-quick-mmpt-accessors
    (with-quick-mmpt1-accessors
      (loop for vpn from (extract-vpn vma-low)
		    below (extract-vpn (address-plus vma-high page-size -1))
	    for ppn from (extract-ppn (ldb %%vma-pma vma-low))
	    do
	(let ((mmpt-index (mmpt-lookup ppn)))
	  (cond ((null mmpt-index)
		 ;; --- we don't check for bad-pages in here, the fep
		 ;; will have had to deal with that already
		 (wired-ferror :fatal "Trying to include space for preloaded area ~A, ~
				       but PPN ~O doesn't exist"
			       vma-low ppn))
		(( (mmpt-invalid-vpn mmpt-index) 0)
		 (update-status-counters (mmpt-status mmpt-index))
		 (setf (mmpt-entry mmpt-index)
		       (dpbs vpn %%mmpt-vpn %mmpt-status-wired %%mmpt-status 0))
		 (setf (mmpt-wired-count mmpt-index) -1)
		 (incf* *count-wired-pages*))
		(t
		 (wired-ferror :fatal "Trying to preload VPN ~O at PPN ~O in ~A ~
				       space, but page already has VPN ~O loaded"
			       vpn ppn vma-low (mmpt-vpn mmpt-index)))))))))

;;; Initialize the storage system.
(defwiredfun initialize-storage ()
  #+(and (not VLM) IMach) (%clear-map-cache)	;VLM only if Load World were allowed
  (when *storage-cold-boot*			; Set by disk-save
    ;; This kludge is because the V127 FEP doesn't fill this in.
    ;; Remove it when things work again.
    #+3600 (when (not (variable-boundp %hardware-configuration))
	     (setf %hardware-configuration 0))
    (setq storage-exists nil)			; Cold initialize storage
    #+3600 (setq si:disk-exists nil))		; Cold initialize the disk
  #+3600 (si:initialize-disk)			; Reset the disk driver
  (setq *page-fault-depth* 0)			; Always reset to no page fault in progress
  #+IMach (setq *storage-lock* nil)
  (with-storage-lock
    #+VLM
    (cond (storage-exists
	    (setq *read-only-n-written-pages* 0
		  *inhibit-read-only-in-progress* 0)
	    (initialize-disk)
	    ;; may have been changed
	    (adjust-*count-swap-pages*))
	  (t
	    ;; --- probabaly don't need most of this either!
	    (initialize-storage-globals)
	    ;; from (take your pick) ...-storage-globals or -finish-up
	    (setq *count-swap-pages*
		  (setq *count-remaining-swap-pages*
			(swap-count)))
	    ;; from ...-load-bitmap-and-sysout-array used by GC
	    (build-address-space-map)
	    ;; On VLM, this actually sets them
	    #+ignore
	    (recompute-read-only-bits)
	    (restore-saved-ephemeral-bits)
	    (setq *disk-exists-p* nil)
	    (initialize-disk)
	    (setq *sysout-enabled-p* *enable-sysout-at-cold-boot*)
	    (setq storage-exists t)))
    #-VLM
    (cond ((and storage-exists (not *netboot-in-progress*))
	   (reinitialize-storage)
	   #+IMach (initialize-disk))
	  (t
	   (initialize-storage-globals)
	   (initialize-storage-initialize-mmpt-y)
	   (initialize-storage-initialize-mmpt)
	   #+IMach (initialize-ecc-log)
	   (initialize-storage-initialize-pht)
	   (initialize-storage-clear-pht)
	   (initialize-storage-account-for-wired-arrays)
	   (initialize-storage-create-smpt)
	   ;; Can't be done until storage tables have been built.
	   #+IMach (setq *disk-exists-p* nil)
	   #+IMach (initialize-disk)
	   (unless (si:perform-netboot-if-necessary)
	     (initialize-storage-create-load-bitmap-and-sysout-array))
	   (initialize-storage-finish-up))))
  t)

(defwiredfun initialize-storage-globals ()
  (setf (region-free-pointer %page-table-area-region) 0)
  (setq *storage-cold-boot* nil
	*page-fault-exit-function* nil
	*smpt-cached-vpn* nil
	*load-map-cached-vpn* nil
	*creating-dynamic-space* nil
	*esrt-lock* nil
	*page-trace-array* nil
	*read-only-n-written-pages* 0
	*inhibit-read-only-in-progress* 0
	*transporter-read-only-vpn* nil
	*wire/unwire-tick* 0
	#+IMach *address-space-map-address* #+IMach nil
	;; Clear meters and variables
	#+3600 *mmpt-replaceable-ppn* #+IMach *flushable-scan-pht-index* 0
	*ms-time-page-fault* 0
	*ms-time-create-pages* 0
	*ms-time-user-prefetch-pages* 0
	*ms-time-destroy-pages* 0
	*ms-time-wiring-and-unwiring-pages* 0
	#+IMach *ms-time-wiring-and-unwiring-stack-pages* #+IMach 0
	*ms-time-user-flush-pages* 0
	#+3600 *ms-time-sequence-break* #+3600 0
	*ms-time-pending-wait* 0
	*ms-time-page-idle-wait* 0
	*ms-time-find-frame* 0
	*ms-time-pending-queue-full* 0
	*ms-time-write-lock-wait* 0
	*ms-time-smpt-create* 0
	*count-usable-pages* 0
	*count-normal-pages* 0
	*count-flushable-pages* 0
	*count-busy-pages* 0
	*count-wired-pages* 0
	*count-locked-pages* 0
	*count-pending* 0
	*count-map-misses* 0
	*count-page-fetches* 0
	*count-page-fetch-user-waits* 0
	*count-write-first-faults* 0
	*count-flushable-page-faults* 0
	*count-prefetched-page-faults* 0
	*count-busy-page-faults* 0
	*count-inhibited-read-only-faults* 0
	*count-load-fetches* 0
	*count-load-prefetches* 0
	*count-created-pages* 0
	*count-page-prefetches* 0
	*count-discarded-prefetched-pages* 0
	*count-forced-modified-page-writes* 0
	*count-smpt-inserts* 0
	*count-smpt-right-inserts* 0
	*count-smpt-left-inserts* 0
	*count-smpt-appends* 0
	*count-smpt-splits* 0
	*count-smpt-empty-node-steals* 0
	*count-smpt-empty-node-shifts* 0
	*count-smpt-balances* 0
	#+3600 *count-pht-linear-probes* #+3600 0
	*count-flushed-pages* 0
	*count-flushed-modified-pages* 0
	#+IMach *count-replacement-algorithm-steps* #+IMach 0
	#+IMach *wired-control-stack-pages* #+IMach 0
	#+IMach *active-stack-groups-head* #+IMach nil
	#+IMach *active-stack-groups-tail* #+IMach nil
	#+IMach *count-active-stack-groups* #+IMach 0
	#+IMach *pht-rehashes* #+Imach 0)
  ;; microcode meters
  #+3600 (setq %count-map-reloads 0)
  #+(and IMach (not VLM)) (setf (%read-internal-register %register-count-map-reloads) 0)
  (dotimes (i %pending-size) (setf (aref *pending-indices* i) nil))
  #+3600 (dotimes (i (1+ %pht-probes-max)) (setf (aref *pht-probes* i) 0))
  #+IMach (dotimes (i 32.) (setf (aref *zone-count-wired-pages* i) 0))
  ;;+++ If *storage-debug* is true, must manually patch *pma-free-pointer*
  #-VLM
  (unless *storage-debug*
    (setq *pma-free-pointer* (dpb 0 %%pma-word-offset
				  (address-plus
				    (max* #+3600 (+ %unwired-physical-address-low
						    (address-difference
						      %unwired-virtual-address-high
						      %unwired-virtual-address-low))
					  #+IMach %unwired-physical-address-high
					  %wired-physical-address-high)
				    page-size
				    -1))))
  ;; The space between region-created-pages for the wired system and
  ;; %wired-virtual-address-high hasn't necessarily been written, so initialize
  ;; it with good ECC.  Since region-created-pages isn't wired, use the
  ;; free pointer instead.
  #+(and (not VLM) IMach)
  (let ((base
	  ;; Knows that this area number is the same as the region number.
	  (address-plus (region-origin sys:wired-control-tables)
			(region-free-pointer sys:wired-control-tables))))
    (%block-store-tag-and-pointer
      base
      (%pointer-difference %wired-virtual-address-high base)
      dtp-null base 1))
  ;; Initialize swap space counts
  #-VLM
  (progn 
    (setq *count-swap-pages* (swap-count swap-map-address swap-map-size))
    (setq *count-remaining-swap-pages* *count-swap-pages*))
  nil)

#+3600
;;; Initialize MMPT-Y from hardware configuration, determine required MMPT size.
(defwiredfun initialize-storage-initialize-mmpt-y ()
  (let ((mmpt-y-max -1))
    ;; Initialize MMPT-Y.  Must be done to calculate size of MMPT
    (dotimes (i %mmpt-y-size)
      (setf (aref *mmpt-y* i) 0)
      (setf (aref *mmpt-y-to-ppn-y* i) 0))
    (loop for slot below 32.			;size of machine-configuration-table
	  as config = (aref machine-configuration-table slot)
	  when (= %config-memory-board (ldb %%config-board-type config))
	    do (loop with base-ppn = (lsh slot (- 19. page-width))
		     with last-ppn = (ldb %%ppn-mmpt-y
					  (+ base-ppn (ldb %%config-last-page config)))
		     for y upfrom (ldb %%ppn-mmpt-y
				       (+ base-ppn (ldb %%config-first-page config)))
			   to last-ppn
		     when (zerop (mmpt-y-valid y))
		       do (alter-mmpt-y y *mmpt-y*
					valid 1
					index (incf mmpt-y-max))
			  ;; Create inverse map for the benefit of mmpt-index-to-ppn
			  (setf (aref *mmpt-y-to-ppn-y* mmpt-y-max) y)))
    ;; Clear GC tags for all the memory boards.
    (loop for slot below 32.			; Size of machine-configuration-table
	  as config = (aref machine-configuration-table slot)
	  when (= %config-memory-board (ldb %%config-board-type config))
	    do (loop with base-ppn = (lsh slot (- 19. page-width))
		     with first-page = (ldb %%config-first-page config)
		     with last-page =  (ldb %%config-last-page config)
		     with last-ppn = (+ base-ppn last-page)
		     for ppn upfrom (+ base-ppn first-page) to last-ppn
		     do (%gc-tag-write (dpb ppn %%pma-page-num 0) nil)))
    (setq *mmpt-size* (* %mmpt-x-size (1+ mmpt-y-max)))))

#+(and IMach (not VLM))
;;; Initialize MMPT-Y from hardware configuration, determine required MMPT size.
(defwiredfun initialize-storage-initialize-mmpt-y ()
  (let ((ppn-y-bound
	  (ldb %%ppn-mmpt-y
	       (+ (main-memory-map-ppn (1- main-memory-map-size))
		  (main-memory-map-n-pages (1- main-memory-map-size)))))
	(mmpt-y-bound 0))
    ;; Allocate *MMPT-Y* and initialize it from the main memory map.
    (allocate-wired-array-space *mmpt-y* ppn-y-bound 0)
    (setq *mmpt-y-base* (array-indirect-pointer *mmpt-y*))
    (loop for mmm-index from 0 below main-memory-map-size do
      (let* ((base-y (ldb %%ppn-mmpt-y (main-memory-map-ppn mmm-index)))
	     (bound-y (+ base-y (ldb %%ppn-mmpt-y (main-memory-map-n-pages mmm-index)))))
	(loop for y from base-y below bound-y do
	  (when ( (mmpt-y-entry-valid (mmpt-y-entry y)) 0)
	    (wired-ferror :fatal "Duplicate entry in main memory map."))
	  ;; Check to make sure the physical address isn't part of the boot prom or IBUS
	  ;; configuration space, then add it into the MMPT-Y.
	  (when (or (< y (ldb %%pma-mmpt-y  #o777400000))
		    ( y (ldb %%pma-mmpt-y #o1000000000)))
	    (setf (mmpt-y-entry y)
		  (make-mmpt-y-entry valid 1
				     index (shiftf mmpt-y-bound (1+ mmpt-y-bound))))))))
    ;; Allocate *MMPT-Y-TO-PPN-Y* and initialize it from *MMPT-Y*.
    (allocate-wired-array-space *mmpt-y-to-ppn-y* mmpt-y-bound 0)
    (setq *mmpt-y-to-ppn-y-base* (array-indirect-pointer *mmpt-y-to-ppn-y*))
    (let ((mmpt-y 0))
      (loop for ppn-y below ppn-y-bound do
	(let ((entry (mmpt-y-entry ppn-y)))
	  (when (= (mmpt-y-entry-valid entry) 1)
	    (setf (mmpt-y-to-ppn-y-entry (shiftf mmpt-y (1+ mmpt-y))) ppn-y)))))
    (setq *mmpt-size* (* %mmpt-x-size mmpt-y-bound))))

;;; Initialize MMPT and MMPT1, making all extant pages flushable.
#-VLM
(defwiredfun initialize-storage-initialize-mmpt ()
  ;; Create MMPT, marking all pages as invalid and flushable.
  (allocate-wired-array-space *mmpt* *mmpt-size*
			      (%logdpbs 1 %%mmpt-invalid-vpn
					%mmpt-status-flushable %%mmpt-status
					#+3600 (dpb 0 %%mmpt-age 0)
					#+IMach 0))
  #+IMach (setq *mmpt-base* (array-indirect-pointer *mmpt*))
  ;; Create MMPT1, an art-16b on 3600s, an art-32b on 4000s.
  #+3600 (allocate-wired-array-space *mmpt1* (/2 *mmpt-size*) 0 0 1)
  #+IMach (allocate-wired-array-space *mmpt1* *mmpt-size* 0)
  #+IMach (setq *mmpt1-base* (array-indirect-pointer *mmpt1*))
  ;; Link all MMPT1 entries together into a continuous flushable queue.  Since the
  ;; very uppermost MMPT index is used as the flushable queue end marker, we may have
  ;; to "truncate" the flushable list by one entry, and mark the last frame as unusable.
  (let ((entries (min* *mmpt-size* %flushable-queue-end)))
    #+3600 (with-quick-mmpt1-accessors
	     (loop for i below entries do
	       (setf (mmpt-thread i) (1+ i))))
    #+IMach (%block-store-cdr-and-contents *mmpt1-base* entries 0 1 1)
    ;; Last entry in flushable queue terminates the thread.
    (setf (mmpt-thread (1- entries)) %flushable-queue-end)
    (setq *flushable-queue-head* 0 *flushable-queue-tail* (1- entries))
    (setq *flushable-queue-modified* nil)
    (setq *count-flushable-pages* entries)
    (setq *count-usable-pages* entries)
    (when (> *mmpt-size* %flushable-queue-end)
      (setf (mmpt-status %flushable-queue-end) %mmpt-status-frame-error))
    #+IMach
    ;; Note bad pages in mmpt
    (with-quick-mmpt-accessors
      (loop for index below bad-memory-pages-size
	    do
	(loop with bad-ppn-base = (bad-memory-pages-ppn index)
	      with bad-ppn-pages = (bad-memory-pages-n-pages index)
	      with bad-ppn-limit = (+ bad-ppn-base bad-ppn-pages)
	      ;; take them out of the flushable queue (we assume this
	      ;; still leaves a non-empty queue, you are in deep puckies if
	      ;; not)
	      initially (shiftf (mmpt-thread (mmpt-lookup bad-ppn-base))
				(mmpt-thread (mmpt-lookup (1- bad-ppn-limit)))
				%flushable-queue-end)
			(decf *count-usable-pages* bad-ppn-pages)
			(decf *count-flushable-pages* bad-ppn-pages)
	      for bad-ppn from bad-ppn-base below bad-ppn-limit
	      ;; mark them bad
	      do (setf (mmpt-entry (mmpt-lookup bad-ppn))
		       (%logdpbs 1 %%mmpt-invalid-vpn
				 %mmpt-status-frame-error %%mmpt-status
				 0)))))
    ))

#+3600
;;; Create and initialize PHT and associated tables.
(defwiredfun initialize-storage-initialize-pht ()
  (setq *pht-size* (pht-hash-size (truncate (* *count-usable-pages* %pht-density-numerator)
					    %pht-density-denominator)))
  (allocate-wired-array-space *pht* *pht-size*)
  ;; Create and initialize PHTC
  (setq *phtc-size* (* 1024. 4))		;+++ should be dynamic from 4K to 64K by ^2s
  (allocate-wired-array-space *phtc* *phtc-size* -1 (1- (* 1024. 64.)))	; 64K aligned
  ;; Tell ucode where the tables are
  (%phtc-setup (ldb (byte 24. 0) (%pointer (locf (aref *phtc* 0)))))	;+++ only works for 4K
  nil)

#+3600
(defwiredfun initialize-storage-clear-pht ()
  (setq *pht-lookup-last-vpn* nil)		;invalidate lookup cache
  (%block-store-cdr-and-contents (locf (aref *pht* 0)) *pht-size* 0 nil 0))

#+(and IMach (not VLM))
;;; Create and initialize PHT and associated tables.
(defwiredfun initialize-storage-initialize-pht ()
  ;; Determine PHT size.  Pick the lowest power of two that yields density less than 66%. 
  ;; Use brute force: all the more intelligent approaches rely on unwired numerics code.
  (loop with minimum = (floor (* *count-usable-pages* 3) 2)
	for pp from 10
	for entries = (rot 1 pp)
	until ( entries minimum)
	finally (setq *pht-size* entries))
  ;; Create PHT and tell the microcode about it.  Use a physical address so that
  ;; PHT references do not displace more useful data from the cache.
  (allocate-wired-array-space *pht* (*2 *pht-size*))	;*pht-size* is #entries
  (setf (%read-internal-register %register-pht-base)
	(setf (array-indirect-pointer *pht*)
	      (let ((pma (ldb %%vma-pma (%pointer (array-indirect-pointer *pht*)))))
		(system-case
		  (MacIvory-1&2 (%make-unmapped-address pma))
		  (otherwise (%make-physical-address pma))))))
  ;; PHT mask is (* (1- buckets) 8), or (* (1- entries/4) 8).
  ;; Also, set the high 4 bits, specifying that all reference bits be cleared.
  (setf (%read-internal-register %register-pht-mask)
	(%logdpb #b1111 (byte 4 28.) (*8 (1- (/4 *pht-size*)))))
  ;; Allocate and initialize PHT collision count table.
  ;; One 4-bit entry per bucket (4 entries) in the PHT.  The cold-load generator sets up
  ;; the array prefix, so all we do is compute the size in words.  *PHT-SIZE* is the number
  ;; of entries, so we have *PHT-SIZE*/4 buckets, and we pack 8 collision counts per word,
  ;; so we need *PHT-SIZE*/32 words.
  (allocate-wired-array-space *pht-collision-counts* (/32 *pht-size*) 0 0 3)
  (setq *pht-collision-counts-base* (array-indirect-pointer *pht-collision-counts*))
  nil)

#+(and IMach (not VLM))
;;; Zero PHT and collision counts, for both cold and warm boot.
(defwiredfun initialize-storage-clear-pht ()
  (with-system-block-registers (1)
    (setf (%block-register 1) *pht-base*)
    ;; Invalidate all PHT entries.  All we really need to do is set the vpn to -1, but
    ;; other places may depend on the contents of invalid pht entries.
    ;; - The GC wants the ephemeral-reference bits off.
    ;; - The replacement algorithm wants fault-request on and the reference bits off.
    ;; - The write-protect mechanism wants write-protect and modified off.
    ;; - The static-space GC can twiddle transport-trap at random.
    ;; Set the chain bit on every PHT0 word.
    ;; Cf. PHT-REMOVE.
    (let ((pht0 (%set-tag (%logdpbs %pht0-invalid-vpn %%pht0-vpn
				    1 %%pht0-fault-request
				    0)
			  (dpb 1 %%q-cdr-code-within-tag dtp-fixnum)))
	  (pht1 0))
      ;; No need for (si:prepare-for-block-write), since address is unmapped.
      (loop repeat *pht-size* do
	(%block-write 1 pht0)
	(%block-write 1 pht1)))
    ;; Zero all collision counts
    (setf (%block-register 1) *pht-collision-counts-base*)
    (loop repeat (/32 *pht-size*) do (%block-write 1 0))
    (setq *pht-collision-count* 0))
  nil)

#+3600
(defwiredfun initialize-storage-account-for-wired-arrays ()
  ;; Include dynamic arrays (must be done in order they were allocated).
  (let ((vma %page-table-area-region-origin))
    (setq vma (include-dynamic-array *mmpt* "*MMPT*" vma))
    (setq vma (include-dynamic-array *mmpt1* "*MMPT1*" vma 1))
    (setq vma (include-dynamic-array *pht* "*PHT*" vma))
    (include-dynamic-array *phtc* "*PHTC*" vma))
  ;; Setup tables to include pages loaded by FEP
  (include-preloaded-space 0 %wired-virtual-address-high %wired-physical-address-low)
  (if (and fep-preloaded-size (plusp fep-preloaded-size))
      (include-preloaded-physical-space fep-preloaded-address fep-preloaded-size)
    (include-preloaded-physical-space load-map-address load-map-size
				      load-map-dpn-address load-map-size
				      bad-memory-pages-address bad-memory-pages-size
				      swap-map-address swap-map-size
				      swap-map-dpn-address swap-map-size))
  ;;+ temporary space loaded by boot simulator until paging totally up.
  (when (plusp %unwired-virtual-address-low)
    ;; When not instabooting, include the loaded unwired portion of the world load
    ;; in the storage tables.
    (include-preloaded-space %unwired-virtual-address-low
			     (min* %unwired-virtual-address-high
				   %page-table-area-region-origin)
			     %unwired-physical-address-low
			     (if *storage-debug* #'wire-frame #'normalize-frame))
    ;;++ anything more that already got allocated above the page-table-area (e.g. pkgs)
    (if (> %unwired-virtual-address-high %page-table-area-region-origin)
	(include-preloaded-space (address-plus %page-table-area-region-origin 600000)
				 %unwired-virtual-address-high
				 (address-plus
				   %unwired-physical-address-low
				   (address-difference
				     (address-plus %page-table-area-region-origin 600000)
				     %unwired-virtual-address-low))
				 (if *storage-debug* #'wire-frame #'normalize-frame)))))

#+(and IMach (not VLM))
;; The VLM would only need this to tell DISK-SAVE to always save the
;; wired core (and not the FEP).  We can just code that into DISK-SAVE.
;; (In fact, since there is no paging code anymore, there is no need for
;; a wired core:  it can be treated just like the rest of the world.)
(defwiredfun initialize-storage-account-for-wired-arrays ()
  ;; Include dynamic arrays (must be done in order they were allocated).
  (let ((vma %page-table-area-region-origin))
    (setq vma (include-dynamic-array *mmpt-y* "*MMPT-Y*" vma))
    (setq vma (include-dynamic-array *mmpt-y-to-ppn-y* "*MMPT-Y-TO-PPN-Y*" vma))
    (setq vma (include-dynamic-array *mmpt* "*MMPT*" vma))
    (setq vma (include-dynamic-array *mmpt1* "*MMPT1*" vma #+3600 1))
    (setq vma (include-dynamic-array *pht* "*PHT*" vma))
    (include-dynamic-array *pht-collision-counts* "*PHT-COLLISION-COUNTS*" vma 3))
  (include-fixed-space
    (%logdpb %vma-equals-pma %%vma-equals-pma %fep-physical-address-low)
    (%logdpb %vma-equals-pma %%vma-equals-pma %fep-physical-address-high))
  (include-preloaded-space
    %wired-virtual-address-low %wired-virtual-address-high %wired-physical-address-low)
  ;; Include unwired space loaded by Load Complete World.
  (when (plusp %unwired-physical-address-low)
    (let ((pma %unwired-physical-address-low))
      (loop for index below load-map-size do
	(let ((vpn (load-map-vpn index))
	      (n-pages (load-map-n-pages index)))
	  (when ( (ldb %%vpn-equals-ppn vpn) %vma-equals-pma)
	    (include-preloaded-space
	      (deposit-vpn vpn 0)
	      (deposit-vpn (+ vpn n-pages) 0)
	      (shiftf pma (address-plus pma (deposit-vpn n-pages 0)))
	      #'normalize-frame)))))))

#-VLM
(defwiredfun initialize-storage-create-smpt ()
  ;; Now all crucial tables are representative of main memory state.
  ;; Initialize the SMPT (must be done after mmpt is entirely initialized)
  (setq *smpt* (make-smpt-leaf nil)))		; Make top level leaf

#-VLM
(defwiredfun initialize-storage-create-load-bitmap-and-sysout-array ()
  ;; Initialize the address space map before %REGION-NUMBER is called, below
  #+IMach
  (build-address-space-map)
  (let ((*load-bitmaps* *load-bitmaps*))
    (declare (zl:unspecial *load-bitmaps*) (sys:array-register *load-bitmaps*))
    (si:with-fast-storage-accessors (region-origin region-free-pointer region-bits)
      ;; Initialize the array of bitmaps of pages that are in the load file
      ;; Initially each element of this array is zero
      (dotimes (i %number-of-bitmaps)
	(setf (aref *load-bitmaps* i) 0))
      ;; In each element of *load-bitmaps* where a bitmap will be required, put its length
      (dotimes (i load-map-size)
	(loop with start-vpn = (load-map-vpn i)
	      with end-vpn = (+ start-vpn (load-map-n-pages i) -1)
	      with limit = (ldb %%vpn-bitmap-num end-vpn)
	      for bitmap from (ldb %%vpn-bitmap-num start-vpn) to limit
	      as size = (1+ (if (= bitmap limit)
				(ldb %%vpn-bitmap-index end-vpn)
			      (dpb -1 %%vpn-bitmap-index 0)))
	      do (when (> size (aref *load-bitmaps* bitmap))
		   (setf (aref *load-bitmaps* bitmap) size))))
      (when (zerop %unwired-virtual-address-low)
	;; When instabooting stacks go into these bitmaps, too
	(dotimes (i (si:n-regions))
	  (when (ldb-test %%region-stack (region-bits i))
	    (loop with origin = (region-origin i)
		  with end-vpn = (extract-vpn (address-plus origin (region-free-pointer i) -1))
		  with limit = (ldb %%vpn-bitmap-num end-vpn)
		  for bitmap from (ldb %%vpn-bitmap-num (extract-vpn origin)) to limit
		  as size = (1+ (if (= bitmap limit)
				    (ldb %%vpn-bitmap-index end-vpn)
				  (dpb -1 %%vpn-bitmap-index 0)))
		  do (when (> size (aref *load-bitmaps* bitmap))
		       (setf (aref *load-bitmaps* bitmap) size))))))
      ;; Now create the 2-level arrays.  Put nil in entries where no bitmap is required.
      ;; create-dynamic-array initializes the array elements to nil.
      (dotimes (i %number-of-bitmaps)
	(let ((length (aref *load-bitmaps* i)))
	  (setf (aref *load-bitmaps* i) (and (plusp length)
					     (create-dynamic-array art-boolean length)))))
      ;; And set the bitmap for all pages in the load map
      (dotimes (i load-map-size)
	(let ((base-vpn (load-map-vpn i)))
	  (when ( (ldb %%vpn-equals-ppn base-vpn) %vma-equals-pma)
	    (loop for vpn upfrom base-vpn below (+ base-vpn (load-map-n-pages i)) do
	      (when (and (not (page-resident-p vpn))
			 ;; Only set bit for pages that are real.  IDS merging can
			 ;; reincarnate pages that have really been destroyed.
			 (%region-number (deposit-vpn vpn 0)))
		(setf (load-bitmap vpn) t))))))
      (when (zerop %unwired-virtual-address-low)
	;; When instabooting, add in all stack pages
	(dotimes (i (si:n-regions))
	  (when (ldb-test %%region-stack (region-bits i))
	    (loop with origin = (region-origin i)
		  for vpn from (extract-vpn origin)
			  to (extract-vpn (address-plus origin (region-free-pointer i) -1))
		  do (setf (load-bitmap vpn) t)))))
      ;; Initialize sysout array if enabled
      (if (not (setq *sysout-enabled-p* *enable-sysout-at-cold-boot*))
	  ;; Reset the variable to NIL if sysout's not enabled, because right now it
	  ;; might contain a bogus pointer left from before the disk save.
	  (setq *sysout-bitmaps* nil)
	(setq *sysout-bitmaps* (create-dynamic-array art-q %number-of-bitmaps))
	(dotimes (i %number-of-bitmaps)
	  (let ((bitmap (aref *load-bitmaps* i)))
	    (setf (aref *sysout-bitmaps* i)
		  (and bitmap (create-dynamic-array art-boolean
				#+3600 (array-normal-length-field bitmap)
				#+IMach (length bitmap))))))))))

#+VLM
(defwiredfun restore-saved-ephemeral-bits ()
  (when (null *saved-esrt*)
    (return-from restore-saved-ephemeral-bits nil))
  (let ((page-bit-tables *saved-esrt*))
    (declare (sys:array-register page-bit-tables))
    (macrolet ((page-bit (vpn &environment environment)
		 (once-only (vpn &environment environment)
		   `(let ((index (ldb %%vpn-bitmap-index ,vpn))
			  (map (aref page-bit-tables (ldb %%vpn-bitmap-num ,vpn))))
		      (if map
			  (aref map index)
			  nil)))))
      (dotimes (region (si:n-regions))
	(unless (or
		  ;; Don't do FEP-AREA, triggers race condition
		  (eq region 0)			;FEP-AREA
		  (eq (ldb %%region-space-type (region-bits region)) %region-space-free))
	  ;; --- Bleah, this needs a co-proc op to quickly set them
	  (loop for vpn upfrom (extract-vpn (region-origin region))
		repeat (ceiling-page-size (region-free-pointer region))
		as index = (vm-lookup vpn)
		unless (or (page-bit vpn) (null index))
		  do (vm-write-attribute ephemeral-reference index nil))
	  )))
    (setq *saved-esrt* nil)
    ;; --- free the pages?
    (setf (region-free-pointer %GC-table-area-region) 0)))

#-VLM
(defwiredfun initialize-storage-finish-up ()
  ;; Enable storage so you can create smpt entries (which can fault)
  (setq storage-exists t)
  ;; Initialize swap space counts
  (setq *count-swap-pages* (swap-count swap-map-address swap-map-size))
  (setq *count-remaining-swap-pages* *count-swap-pages*)
  #+3600 
  (progn
    ;; tell ucode where the tables are
    (%block-store-cdr-and-contents (locf (aref *phtc* 0)) *phtc-size* 0 -1 0)
    (%phtc-setup (ldb (byte 24. 0) (%pointer (locf (aref *phtc* 0))))))	;+++ only works for 4K
  ;;+ Make SMPT entries for unwired space
  ;; This follows setting storage-exists since SMPT references can map-miss.
  ;; If a warm boot happens here we won't really lose since these entries don't
  ;; NEED to be made.
  ;; [6/11/84 I think this code is never needed anymore, no :load-world Lcons command]
  ;; [2/03/87 What goes around comes around]
  (with-quick-mmpt-accessors
    (dotimes (mmpt-index *mmpt-size*)
      (if (and (zerop (mmpt-invalid-vpn mmpt-index))
	       ( %mmpt-status-wired (mmpt-status mmpt-index)))
	  (smpt-create (mmpt-vpn mmpt-index)))))
  ;; Bring the ESRT into main memory and wire it down.
  ;; There had better be enough main memory!  If we have to evict a page
  ;; while doing this, there might be a page fault on the ESRT.
  (let ((from-vpn (extract-vpn %gc-table-area-region-origin))
	(to-vpn (extract-vpn (address-plus
			       %gc-table-area-region-origin
			       (region-free-pointer %gc-table-area-region)
			       -1))))
    (prefetch-pages from-vpn (1+ (- to-vpn from-vpn)) nil t)
    (wire-pages from-vpn (1+ (- to-vpn from-vpn)))))


;;;; Warm boot

#-VLM
;;; Called whenever the integrity of the storage system is suspect, such a by a warm boot.
;;; Also can be called if the PHT is suspect since it will just be rebuilt from the MMPT.
;;; Must always be called on the aux stack!
(defwiredfun reinitialize-storage ()
  ;; Clear random variables
  (setq *smpt-cached-vpn* nil
	*load-map-cached-vpn* nil
	*page-trace-array* nil
	*page-trace-in-progress* 0)
  ;; Clear PHTC (actually, map cache and phtc are cleared by ucode)
  #+3600 (%block-store-cdr-and-contents (locf (aref *phtc* 0)) *phtc-size* 0 -1 0) ; Clear PHTC
  #+3600 (%phtc-setup (ldb (byte 24. 0) (%pointer (locf (aref *phtc* 0)))));++only works for 4K
  #+IMach (%clear-map-cache)
  ;; Rebuild the PHT and make the MMPT's status consistant and stable (abort any
  ;; disk IO in progress).  Also rebuild the page counts.
  (setq *creating-dynamic-space* nil
	*read-only-n-written-pages* 0
	*inhibit-read-only-in-progress* 0
	*transporter-read-only-vpn* nil
	*count-normal-pages* 0
	*count-flushable-pages* 0
	*count-busy-pages* 0
	*count-wired-pages* 0
	*count-locked-pages* 0
	*flushable-queue-head* nil
	*flushable-queue-tail* nil
	*flushable-queue-modified* nil)
  (reinitialize-pht-and-mmpt)
  ;; Clear out the pending queue.
  (setq *count-pending* 0)
  (dotimes (i %pending-size) (setf (aref *pending-indices* i) nil))
  ;; Reset SMPT
  ;;+++ Check SMPT for consistancy (not in the middle of a split)
  ;; If warm-boot out of GC-PAGE-OUT, restore GCPT
  (when *gc-page-out-pma*
    #+3600 (%gc-tag-write *gc-page-out-pma* t)
    #+IMach
    ;; Set ephemeral-reference bits in the PHT entry corresponding to that physical address.
    (let ((mmpt-index (mmpt-lookup (extract-ppn (%pointer *gc-page-out-pma*)))))
      (when (and (not (null mmpt-index))
		 (= (mmpt-invalid-vpn mmpt-index) 0))
	(let ((pht-index (pht-lookup (mmpt-vpn mmpt-index))))
	  (when (not (null pht-index))
	    (setf (pht-ephemeral-reference pht-index) #b1111))))))
  ;;+++ ought to check ESRT for consistency (warm boot out of modifying it)
  (setq *esrt-lock* nil)
  ;; FEP might have added more swap space.
  (adjust-*count-swap-pages*))

#+3600
(defwiredfun reinitialize-pht-and-mmpt ()
  (with-quick-pht-and-mmpt-accessors
    (with-quick-mmpt1-accessors
      (initialize-storage-clear-pht)
      ;; Rebuild PHT from scratch, adjust MMPT as needed, and rebuild flushable queue.
      (loop for mmpt-index below *mmpt-size*
	    as mmpt-entry = (mmpt-entry mmpt-index)
	    as mmpt-status = (mmpt-entry-status mmpt-entry)
	    do
	(when ( (mmpt-entry-write-lock mmpt-entry) 0)
	  (setf (mmpt-entry-write-lock mmpt-entry) 0)
	  (setf (mmpt-entry-modified mmpt-entry) 1)
	  (setf (mmpt-entry mmpt-index) mmpt-entry))
	(cond ((or (= mmpt-status %mmpt-status-frame-error)
		   (= mmpt-status %mmpt-status-data-error))
	       nil)
	      ((or ( (mmpt-entry-invalid-vpn mmpt-entry) 0)
		   (= mmpt-status %mmpt-status-reading))
	       ;; Page is marked as invalid or has a disk read in progress.  Just flush it,
	       ;; marking it as invalid.  If the page was being fetched in, it will be
	       ;; restarted if it's really needed.
	       (setf (mmpt-entry mmpt-index) (%logdpbs 1 %%mmpt-invalid-vpn
						       %mmpt-status-flushable %%mmpt-status
						       mmpt-entry))
	       (incf* *count-flushable-pages*))
	      (t
		(let ((pht-index (pht-put (mmpt-entry-vpn mmpt-entry)
					  (mmpt-index-to-ppn mmpt-index))))
		  (select mmpt-status
		    (%mmpt-status-normal
		      (incf* *count-normal-pages*)
		      (setf (pht-fault-request pht-index) 0))
		    (%mmpt-status-writing
		      ;; For a write in progress, can't just throw away the page since this
		      ;; might be the only copy.  Reset the status to normal and mark it as
		      ;; modified so another write will be reissued sometime.
		      (incf* *count-normal-pages*)
		      (setf (mmpt-entry mmpt-index) (%logdpbs %mmpt-status-normal %%mmpt-status
							      0 %%mmpt-flushing
							      0 %%mmpt-write-lock	;!!!
							      1 %%mmpt-modified
							      mmpt-entry))
		      (setf (pht-fault-request pht-index) 0))
		    ((%mmpt-status-flushable
		       %mmpt-status-prefetched
		       %mmpt-status-prefetched-mark)
		     (incf* *count-flushable-pages*))
		    (%mmpt-status-preparing
		      (setf (mmpt-entry mmpt-index)
			    (dpb %mmpt-status-flushable %%mmpt-status mmpt-entry))
		      (incf* *count-flushable-pages*))
		    (%mmpt-status-wired
		      (incf* *count-wired-pages*)
		      (setf (pht-fault-request pht-index) 0))
		    (t (invalid-frame-status mmpt-index))))))
	(when (or (plusp (mmpt-entry-write-lock mmpt-entry))
		    (plusp (mmpt-entry-flushing mmpt-entry)))
	    (invalid-frame-status mmpt-index))
	;; If this frame is flushable, push it on the head of the flushable queue, otherwise
	;; just set the thread to something innocuous.  Yeah, this makes the queue come out
	;; a different order after a warm boot.
	(if (not (bit-member (mmpt-status mmpt-index) *flushable-status*))
	    (setf (mmpt-thread mmpt-index) %flushable-queue-end)
	  ;; If this is the first flushable queue entry, set up the tail pointer.
	  (if (not (null *flushable-queue-head*))
	      (setf (mmpt-thread mmpt-index) (shiftf *flushable-queue-head* mmpt-index))
	    (setf (mmpt-thread mmpt-index) %flushable-queue-end)
	    (setq *flushable-queue-head* mmpt-index)
	    (setq *flushable-queue-tail* mmpt-index)))))))

#+(and IMach (not VLM))
(defwiredfun reinitialize-pht-and-mmpt ()
  ;; We can't take any I/O interrupts while the PHT is inconsistent, because interrupt
  ;; handlers can reference wired virtual addresses.
  (%set-trap-mode trap-mode-io)
  (with-quick-pht-and-mmpt-accessors
    (with-quick-mmpt1-accessors
      (let ((ephemeral-reference-bits 0))
	;; See if any ephemeral storage exists, in order to most conservatively set
	;; the existing ephemeral reference bits.  This code knows that no regions
	;; span ephemeral groups.
	(si:with-fast-storage-accessors (region-bits si:region-quantum-origin)
	  (loop with quantum for region below (si:n-regions)
		when (and ( (ldb %%region-space-type (region-bits region))
			     %region-space-free)
			  (= (ldb %%quantum-zone-num
				  (setq quantum (si:region-quantum-origin region)))
			     %ephemeral-zone))
		  do (setq ephemeral-reference-bits
			   (logior (rot 1 (ldb %%quantum-ephemeral-group quantum))
				   ephemeral-reference-bits))))
	;; Scan through the PHT, transferring information from PHT1.modified and
	;; PHT1.ephemeral-reference to the cdr code of the corresponding MMPT entries.
	;; Below we'll use this to initialize the new PHT entries; otherwise we'd have
	;; to assume that every page in memory was modified with ephemeral references.
	(with-quick-mmpt-lookups
	  (setf (%block-register 1) *pht-base*)
	  (loop repeat *pht-size* do
	    (let ((pht0 (%block-read 1 :fixnum-only t :set-cdr-next nil))
		  (pht1 (%block-read 1 :fixnum-only t :set-cdr-next nil)))
	      (when ( (ldb %%pht0-vpn pht0) %pht0-invalid-vpn)
		(let* ((mmpt-index (mmpt-lookup (ldb %%pht1-ppn pht1)))
		       (mmpt-entry (mmpt-entry mmpt-index)))
		  (when (and (= (mmpt-entry-invalid-vpn mmpt-entry) 0)
			     (= (mmpt-entry-vpn mmpt-entry) (ldb %%pht0-vpn pht0)))
		    (setf (%p-cdr-code (%pointer-plus *mmpt-base* mmpt-index))
			  (lognot
			    (dpb (if (ldb-test %%pht1-ephemeral-reference pht1) 1 0)
				 (byte 1 1)
				 (ldb %%pht1-modified pht1))))))))))
	(initialize-storage-clear-pht)
	;; Rebuild PHT from scratch, adjust MMPT as needed, and rebuild flushable queue.
	(loop for mmpt-index below *mmpt-size*
	      as mmpt-entry = (mmpt-entry mmpt-index)
	      as mmpt-status = (mmpt-entry-status mmpt-entry)
	      as cdr-code = (%p-cdr-code (%pointer-plus *mmpt-base* mmpt-index))
	      ;; If the frame was write-locked, we'll mark it as modified when all is
	      ;; said and done.  Otherwise, use the hint from the cdr code.
	      as modified = (or (= (shiftf (mmpt-entry-write-lock mmpt-entry) 0) 1)
				(= (ldb (byte 1 0) cdr-code) 0))
	      ;; We don't know exactly which ephemeral reference bits were set, just
	      ;; that some were.
	      as ephemeral-reference = (= (ldb (byte 1 1) cdr-code) 0)
	      do
	  (cond ((or (= mmpt-status %mmpt-status-frame-error)
		     (= mmpt-status %mmpt-status-data-error))
		 nil)
		((or ( (mmpt-entry-invalid-vpn mmpt-entry) 0)
		     (= mmpt-status %mmpt-status-reading))
		 ;; Page is marked as invalid or has a disk read in progress.  Just flush it,
		 ;; marking it as invalid.  If the page was being fetched in, it will be
		 ;; restarted if it's really needed.
		 (setq mmpt-entry (%logdpbs 1 %%mmpt-invalid-vpn
					    %mmpt-status-flushable %%mmpt-status
					    mmpt-entry))
		 (incf* *count-flushable-pages*))
		((and (= (ldb %%vpn-equals-ppn (mmpt-entry-vpn mmpt-entry)) %vma-equals-pma)
		      ( (dpb 0 %%vpn-equals-ppn (mmpt-entry-vpn mmpt-entry))
			 (extract-ppn %fep-physical-address-low))
		      (< (dpb 0 %%vpn-equals-ppn (mmpt-entry-vpn mmpt-entry))
			 (extract-ppn %fep-physical-address-high)))
		 ;; FEP pages aren't recorded in PHT.  Just maintain wired counter.
		 (when ( mmpt-status %mmpt-status-wired)
		   (wired-ferror :fatal "Unwired frame containing vma=pma address"))
		 (incf* *count-wired-pages*))
		(t
		 (let* ((vpn (mmpt-entry-vpn mmpt-entry))
			(pht-index (pht-put vpn (mmpt-index-to-ppn mmpt-index))))
		   (when modified
		     (setf (pht-modified pht-index) 1))
		   (when ephemeral-reference
		     (setf (pht-ephemeral-reference pht-index)
			   ;; Binding stacks must always have ephemeral reference bits set.
			   (if (and ( (%read-internal-register %register-chip-revision) 2)
				    (= (ldb %%vpn-zone-and-subzone vpn)
				       (dpb %safeguarded-zone %%subzone-zone-num
					    %safeguarded-subzone-binding-stack)))
			       #b1111
			       ephemeral-reference-bits)))
		   ;; Insure a write-first fault, so the sysout bit gets updated.
		   ;; There wasn't any place to save the pht-write-protect bit from
		   ;; the previous incarnation of the PHT, so try to recompute it.
		   ;; This necessarily loses the %%region-read-only status, since
		   ;; it doesn't work to call %region-number here and since we
		   ;; don't know whether read-only might have been suppressed.
		   (when (and *sysout-enabled-p*
			      (not modified)
			      ;; These tables are in inaccessible virtual memory at this
			      ;; point, so we have to write-protect all candidate pages.
			      #+ignore (not (sysout-bitmap vpn))
			      #+ignore (load-bitmap vpn)
			      (bit-member mmpt-status
					  (logior (rot 1 %mmpt-status-normal)
						  (rot 1 %mmpt-status-flushable)
						  (rot 1 %mmpt-status-prefetched)
						  (rot 1 %mmpt-status-prefetched-mark)
						  (rot 1 %mmpt-status-wired))))
		     (setf (pht-write-protect pht-index) 1))
		   (select mmpt-status
		     (%mmpt-status-normal
		      (incf* *count-normal-pages*)
		      (setf (pht-fault-request pht-index) 0))
		     (%mmpt-status-writing
		      ;; For a write in progress, can't just throw away the page since this
		      ;; might be the only copy.  Reset the status to normal and mark it as
		      ;; modified so another write will be reissued sometime.
		      (incf* *count-normal-pages*)
		      (setq mmpt-entry (%logdpbs %mmpt-status-normal %%mmpt-status
						 0 %%mmpt-flushing
						 0 %%mmpt-write-lock	;!!!
						 mmpt-entry))
		      (setf (pht-modified pht-index) 1)
		      (setf (pht-fault-request pht-index) 0))
		     ((%mmpt-status-flushable
			%mmpt-status-prefetched
			%mmpt-status-prefetched-mark)
		      (incf* *count-flushable-pages*))
		     (%mmpt-status-preparing
		      (setq mmpt-entry (dpb %mmpt-status-flushable %%mmpt-status mmpt-entry))
		      (incf* *count-flushable-pages*))
		     (%mmpt-status-wired
		      (incf* *count-wired-pages*)
		      (setf (pht-fault-request pht-index) 0))
		     (t (invalid-frame-status mmpt-index))))))
	  (when (or (plusp (mmpt-entry-write-lock mmpt-entry))
		    (plusp (mmpt-entry-flushing mmpt-entry)))
	    (invalid-frame-status mmpt-index))
	  ;; Write back the modified entry, explicitly clearing the cdr code.
	  (%memory-write (%pointer-plus *mmpt-base* mmpt-index) mmpt-entry)
	  ;; If this frame is flushable, push it on the head of the flushable queue, otherwise
	  ;; just set the thread to something innocuous.  Yeah, this makes the queue come out
	  ;; a different order after a warm boot.
	  (if (not (bit-member (mmpt-status mmpt-index) *flushable-status*))
	      (setf (mmpt-thread mmpt-index) %flushable-queue-end)
	    ;; If this is the first flushable queue entry, set up the tail pointer.
	    (if (not (null *flushable-queue-head*))
		(setf (mmpt-thread mmpt-index) (shiftf *flushable-queue-head* mmpt-index))
	      (setf (mmpt-thread mmpt-index) %flushable-queue-end)
	      (setq *flushable-queue-head* mmpt-index)
	      (setq *flushable-queue-tail* mmpt-index))))
	;; Clobber this so the scavenger won't miss any pages when it starts back up.
	(setq si:*scavenger-resident-pages-state* -1)))))



;;; Allocate some space in WIRED-DYNAMIC-AREA.  Find enough frames to hold the assigned
;;; virtual addresses and update the tables to describe them.  Each of the frames needs to be
;;; chosen carefully to not incur any I/O traffic.  We scan through the flushable queue
;;; manually, filtering out the desired frames and calling the replacement algorithm as
;;; necessary to get more to choose from.
(defwiredfun allocate-unmapped-memory (n-words)
  (with-storage-lock
    (with-quick-pht-and-mmpt-accessors
      (let* ((free-pointer (region-free-pointer %wired-dynamic-area-region))
	     (vma (address-plus %wired-dynamic-area-region-origin free-pointer))
	     #-VLM (base-vpn (extract-vpn vma))
	     #-VLM (bound-vpn (extract-vpn (address-plus vma (+ n-words page-size -1))))
	     #-VLM (mmpt-index *flushable-queue-head*))
	(when (> (+ free-pointer n-words) %wired-dynamic-area-region-length)
	  (wired-ferror :fatal "Wired dynamic area overflow."))
	(setq *creating-dynamic-space* t)
	;; Even in the real system, this probably would work, rather
	;; than duplicating all that code, but I'm too lazy to prove
	;; that...
	#+VLM
	(create-dynamic-space-internal vma n-words nil)
	#-VLM
	(loop for vpn from base-vpn below bound-vpn do
	  (let ((pht-index (pht-lookup vpn)))
	    (if (null pht-index)
		(loop do
		  (when (= mmpt-index %flushable-queue-end)
		    ;; We've scanned through the whole flushable queue.  Try to flush some
		    ;; more pages and continue scanning from where we left off (the current
		    ;; tail).
		    (let ((next *flushable-queue-tail*)
			  (count (- bound-vpn vpn)))
		      (when (> count *count-normal-pages*)
			(wired-ferror :fatal
			  "Can't find enough frames for dynamic allocation"))
		      (flush-n-pages (+ count *count-flushable-pages*))
		      (if ( next %flushable-queue-end)
			  (setq mmpt-index next)
			(setq mmpt-index *flushable-queue-head*))))
		  ;; See if this frame is acceptable, meaning at least that it won't require
		  ;; creating another SMPT entry, and optionally that it won't require
		  ;; creating another ESRT entry.
		  (when (bit-member (mmpt-status mmpt-index) *flushable-status*)
		    (when (or ( (mmpt-invalid-vpn mmpt-index) 0)
			      #+3600
			      (= (mmpt-modified mmpt-index) 0)
			      #+IMach
			      (let ((pht-index (pht-lookup (mmpt-vpn mmpt-index))))
				(= (pht-modified pht-index) 0)))
		      (create-page-in-frame mmpt-index vpn)
		      (wire-frame mmpt-index (pht-lookup vpn))
		      (return nil)))
		  (setq mmpt-index (mmpt-thread mmpt-index)))
	      ;; Make sure the page is wired.
	      (wait-until-frame-prepared pht-index)
	      (wire-frame (mmpt-lookup (pht-ppn pht-index)) pht-index))))
	;; Initialize the memory all the way up to the next page boundary.
	(let ((limit (dpb 0 %%vma-word-offset (+ vma n-words (1- page-size)))))
	  (%block-store-tag-and-pointer vma (- limit vma) dtp-null vma 1))
	;; Fill the part we're actually using with NILs.
	(%block-store-cdr-and-contents vma n-words 0 nil 0)
	(setf (region-free-pointer %wired-dynamic-area-region) (+ free-pointer n-words))
	(setq *creating-dynamic-space* nil)
	(%make-pointer dtp-locative vma)))))

(defwiredfun allocate-unmapped-array (length)
  (unless (< length (expt 2 (byte-size #+3600 array-normal-length-field
				       #+IMach array-short-length-field)))
    (wired-ferror :fatal "Attempt to allocate a ~D-word unmapped array" length))
  (let ((array (%make-pointer dtp-array (allocate-unmapped-memory (1+ length)))))
    (%p-store-cdr-type-and-pointer
      array %header-type-array dtp-header-i
      #+3600 (si:build-defstorage-word array-dispatch-field %array-dispatch-word
                                       array-type-field art-q
                                       array-normal-length-field length)
      #+IMach (si:build-defstorage-word array-type-field art-q
                                        array-short-length-field length))
    array))

;;;; Dynamic storage allocation

;;; Wire n-words starting at the VMA assuming the pages are nonextant.
;;; Used for dynamic allocation of wired storage arrays in true virtual space
(defwiredfun create-dynamic-space (n-words)
  (when (plusp n-words)
    (setq *creating-dynamic-space* t)
    (let* ((free-pointer (region-free-pointer %page-table-area-region))
	   (vma (address-plus %page-table-area-region-origin free-pointer)))
      (when (> (+ free-pointer n-words) %page-table-area-region-length)
	(wired-ferror :fatal "Exceeding allocated virtual address space of PAGE-TABLE-AREA"))
      (create-dynamic-space-internal vma n-words t)
      ;; Initialize the memory all the way up to the next page boundary.
      (let ((limit (dpb 0 %%vma-word-offset (+ vma n-words (1- page-size)))))
	(%block-store-tag-and-pointer vma (- limit vma) dtp-null vma 1))
      (setf (region-free-pointer %page-table-area-region) (+ free-pointer n-words))
      (setq *creating-dynamic-space* nil)
      (%make-pointer dtp-locative vma))))

;;; Same as above, but allocates in GC-TABLE-AREA
(defwiredfun create-dynamic-space-for-esrt (n-words)
  (when (plusp n-words)
    (let ((old-creating-dynamic-space *creating-dynamic-space*))    
      (setq *creating-dynamic-space* t)
      (let* ((free-pointer (region-free-pointer %GC-table-area-region))
	     (vma (address-plus %GC-table-area-region-origin free-pointer)))
	(when (> (+ free-pointer n-words) %GC-table-area-region-length)
	  (wired-ferror :fatal "Exceeding allocated virtual address space of GC-TABLE area"))
	(create-dynamic-space-internal vma n-words nil)
	(let ((limit (dpb 0 %%vma-word-offset (+ vma n-words (1- page-size)))))
	  (%block-store-tag-and-pointer vma (- limit vma) dtp-null vma 1))
	(setf (region-free-pointer %GC-table-area-region) (+ free-pointer n-words))
	(setq *creating-dynamic-space* old-creating-dynamic-space)
	(%make-pointer dtp-locative vma)))))

(defwiredfun create-dynamic-array
	     (type length &optional (initial-value nil) (via #'create-dynamic-space))
  (when (or (minusp length)
	    ( length
	       #+3600 (defsysbyte-limit-value array-normal-length-field)
	       #+IMach (defsysbyte-limit-value array-short-length-field)))
    (wired-ferror :fatal "Bad length to create-dynamic-array" length))
  (select type
    (art-q
     (let ((array (funcall via (1+ length))))
       (%p-store-cdr-type-and-pointer
	 array %header-type-array dtp-header-i
	 #+3600 (si:build-defstorage-word array-dispatch-field %array-dispatch-word
					  array-type-field art-q
					  array-normal-length-field length)
	 #+IMach (si:build-defstorage-word array-type-field art-q
					   array-short-length-field length))
       (%block-store-cdr-and-contents (%make-pointer-offset dtp-locative array 1) length
				      0 initial-value 0)
       (%make-pointer dtp-array array)))
    (art-boolean
     (let* ((words (ceiling length 32.))
	    (array (funcall via (1+ words))))
       (%p-store-cdr-type-and-pointer
	 array %header-type-array dtp-header-i
	 #+3600 (si:build-defstorage-word array-dispatch-field %array-dispatch-boolean
					  array-type-field art-boolean
					  array-normal-length-field length)
	 #+IMach (si:build-defstorage-word array-type-field art-boolean
					   array-short-length-field length))
       (%block-store-cdr-and-contents (%make-pointer-offset dtp-locative array 1) words
				      0 (if initial-value -1 0) 0)
       (%make-pointer dtp-array array)))
    (otherwise
     (wired-ferror :fatal "Bad type to create-dynamic-array" type))))

;;; Find enough frames to hold the given virtual addresses and update the tables to describe
;;; them.  Each of the frames needs to be chosen carefully to not require recursive dynamic
;;; allocation.  We scan through the flushable queue manually, filtering out the desired
;;; frames and calling the replacement algorithm as necessary to get more to choose from.
(defwiredfun create-dynamic-space-internal (vma n-words ephemeral-ok-p)
  #+VLM (declare (ignore ephemeral-ok-p))
  #+VLM
  (progn
    ;; No faults are enabled on created pages by default on Rev. 5a
    (create-pages vma n-words))
  #-VLM
  (with-storage-lock
    (with-quick-pht-and-mmpt-accessors
      (let ((base-vpn (extract-vpn vma))
	    (bound-vpn (extract-vpn (address-plus vma (+ n-words page-size -1))))
	    (mmpt-index *flushable-queue-head*))
	(loop for vpn from base-vpn below bound-vpn do
	  (let ((pht-index (pht-lookup vpn)))
	    (if (null pht-index)
		(loop do
		  (when (= mmpt-index %flushable-queue-end)
		    ;; We've scanned through the whole flushable queue.  Try to flush some
		    ;; more pages and continue scanning from where we left off (the current
		    ;; tail).
		    (let ((next *flushable-queue-tail*)
			  (count (- bound-vpn vpn)))
		      (when (> count *count-normal-pages*)
			(wired-ferror :fatal
			  "Can't find enough frames for dynamic allocation"))
		      (flush-n-pages (+ count *count-flushable-pages*))
		      (if ( next %flushable-queue-end)
			  (setq mmpt-index next)
			(setq mmpt-index *flushable-queue-head*))))
		  ;; See if this frame is acceptable, meaning at least that it won't require
		  ;; creating another SMPT entry, and optionally that it won't require
		  ;; creating another ESRT entry.
		  (when (bit-member (mmpt-status mmpt-index) *flushable-status*)
		    (when (or ( (mmpt-invalid-vpn mmpt-index) 0)
			      #+3600
			      (and (or (= (mmpt-modified mmpt-index) 0)	;no SMPT creation
				       (smpt-lookup (mmpt-vpn mmpt-index)))
				   (or ephemeral-ok-p	;no ESRT creation
				       (not (%gc-tag-read
					      (deposit-ppn (mmpt-index-to-ppn mmpt-index)
							   0)))))
			      #+IMach
			      (let ((pht-index (pht-lookup (mmpt-vpn mmpt-index))))
				(and (or (= (pht-modified pht-index) 0)	;no SMPT creation
					 (smpt-lookup (mmpt-vpn mmpt-index)))
				     (or ephemeral-ok-p	;no ESRT creation
					 (= (pht-ephemeral-reference pht-index) 0)))))
		      (create-page-in-frame mmpt-index vpn)
		      (wire-frame mmpt-index (pht-lookup vpn))
		      (return nil)))
		  (setq mmpt-index (mmpt-thread mmpt-index)))
	      ;; Make sure the page is wired.
	      (wait-until-frame-prepared pht-index)
	      (wire-frame (mmpt-lookup (pht-ppn pht-index)) pht-index))))))))

;;; Allocate a dynamic wired array in VMA-EQUALS-PMA space.  Used only
;;; for dynamic paging tables which can't tolerate a fault (e.g. MMPT,
;;; PHT, PHTC) [--- ptw 11/90:  Actually, it's that they can't tolerate a
;;; PHT-lookup since they are used to rebuild the PHT during
;;; reinitialize]
#-VLM
(defwiredfun allocate-wired-array-space
	     (var n-words &optional (initial-value nil) (alignmask 0) (byte-packing 0))
  (tagbody
    hardluck
       (let* ((pma (logand (lognot alignmask) (address-plus *pma-free-pointer* alignmask)))
	      (vma (%logdpb %vma-equals-pma %%vma-equals-pma pma)))
	 (unless (zerop (%logldb %%vma-equals-pma pma))
	   (wired-ferror :fatal "Exceeding VMA-EQUALS-PMA space"))
	 ;; We hope this doesn't happen, but if there are bad pages in
	 ;; low memory, we skip them and try again.  Any good pages we
	 ;; don't use will still be available for VM.
	 #+IMach
	 (loop with array-base = (extract-ppn pma)
	       with array-limit = (extract-ppn (address-plus pma n-words))
	       for index below bad-memory-pages-size
	       as bad-base = (bad-memory-pages-ppn index)
	       as bad-limit = (+ bad-base (bad-memory-pages-n-pages index))
	       when (not (or (< bad-limit array-base) (< array-limit bad-base)))
		 do ;; skip the rest of the current page in VM
		    (setq *pma-free-pointer* (deposit-ppn bad-limit 0))
		    (go hardluck))
	 (setq *pma-free-pointer* (address-plus pma n-words))
	 (setf (array-indirect-pointer var) (%make-pointer dtp-locative vma))
	 (setf (array-long-length-field var) (rot n-words byte-packing))
	 ;; Initialize array
	 ;; We need to make sure the last page is fully initialized, so we don't have any
	 ;; pages with bad ECC mapped into virtual address space.
	 (let ((bound (%logdpb 0 %%vma-word-offset (address-plus vma n-words page-size -1))))
	   (%block-store-cdr-and-contents
	     vma (address-difference bound vma) 0 initial-value 0))
	 var)))


;;;; Address Space Map

;; Quick way to test for end of threaded list of regions,
;; also for dummy -1 entries placed in the address space map for free memory
(defsubst region-valid-p (region)
  (zerop (ldb (byte 1 15.) region)))

#+3600 (progn

(defwiredvar *address-space-map*) ;Set up by the cold loader

(defwiredfun %region-number (address)
  ;; Get all bits of region number from map
  (let ((region (aref *address-space-map* (ldb %%vma-quantum-num (%pointer address)))))
    (and (region-valid-p region)
	 region)))

(defsubst %set-region-number (quantum region-or-nil)
  (setf (aref *address-space-map* quantum) (or region-or-nil -1)))

) ;3600

#+IMach (progn

;;; The address space map maps from quantum numbers to regions.
;;; This mapping can be constructed easily from the wired region tables,
;;; so the address space map is not stored in cold loads.  Rather,
;;; it is constructed at cold-booting time from the wired region tables.
;;;
;;; The mapping is implemented (conceptually) as an array of arrays.

(defwiredvar *address-space-map-address* nil)

(defwiredfun build-address-space-map ()
  (si:with-fast-storage-accessors (region-bits region-quantum-origin region-quantum-length)
    ;; Ensure that the region arrays are set up properly to match the memory used and allocated
    ;; by the FEP.
    ;; ZL:SETF is to get around a bug in CL:SETF which defeats array registers.
    (zl:setf (region-free-pointer 0) %fep-physical-address-high)
    (zl:setf (region-quantum-length 1)
	     (%fixnum-ceiling (%pointer-difference %wired-virtual-address-high
						   %wired-virtual-address-low)
			      %address-space-quantum-size))
    ;; Create the top-level array.
    (setq *address-space-map-address*
	  (create-dynamic-space (lsh 1 (byte-size %%quantum-address-space-map-high))))
    ;; Fill it with nils.
    (%block-store-cdr-and-contents *address-space-map-address*
				   (lsh 1 (byte-size %%quantum-address-space-map-high))
				   0 nil 0)
    ;; Fill in the actual values from the region tables.
    (dotimes (region (si:n-regions))
      (when ( (ldb %%region-space-type (region-bits region)) %region-space-free)
	(%aux-set-address-space-map (region-quantum-origin region)
				    (region-quantum-length region)
				    region)))))

;; This must be called on the aux stack, since it can call create-dynamic-space.
(defwiredfun %aux-set-address-space-map (quantum-origin quantum-length region-or-nil)
  (let ((quantum-limit (+ quantum-origin quantum-length)))
    (loop for quantum from quantum-origin below quantum-limit do
      (%set-region-number quantum region-or-nil))))

;; This must be called on the aux stack, since it can call create-dynamic-space.
(defwiredfun %set-region-number (quantum region-or-nil)
  (let* ((high-addr (%pointer-plus *address-space-map-address*
				   (ldb %%quantum-address-space-map-high quantum)))
	 (high (%memory-read high-addr :cycle-type %memory-raw)))
    (when (null high)
      (if (null region-or-nil)
	  (return-from %set-region-number nil)
	(enter-storage-system *ms-time-create-pages*
	  (setq high (create-dynamic-space
		       (lsh 1 (byte-size %%quantum-address-space-map-low))))
	  (%block-store-cdr-and-contents high
					 (lsh 1 (byte-size %%quantum-address-space-map-low))
					 0 -1 0)
	  (%memory-write high-addr high))))
    (unless region-or-nil
      (setq region-or-nil -1))
    (let* ((low-addr (%pointer-plus high (ldb %%quantum-address-space-map-low quantum)))
	   (word (%memory-read low-addr :cycle-type %memory-raw :fixnum-only t))
	   (new-word (if (zerop (ldb %%quantum-address-space-map-offset quantum))
			 (%logdpb region-or-nil (byte 20  0) word)
			 (%logdpb region-or-nil (byte 20 20) word))))
      (%memory-write low-addr new-word)
      nil)))

(defwiredfun %region-number (reference)
  ;; This can be called before *address-space-map-address* is
  ;; initialized, via setup-frame  prepare-frame  create-page-in-frame 
  ;; create-dynamic-space-internal  create-dynamic-space  build-address-space-map.
  ;; Rather than fix that path, return NIL.
  (let* ((pointer (%pointer reference))
	 (high (%memory-read (%pointer-plus (or *address-space-map-address*
						(return-from %region-number nil))
					    (ldb %%vma-address-space-map-high pointer))
			     :cycle-type %memory-raw)))
    (when high
      (let* ((word (%memory-read (%pointer-plus high
						(ldb %%vma-address-space-map-low pointer))
				 :cycle-type %memory-raw :fixnum-only t))
	     (region (if (zerop (ldb %%vma-address-space-map-offset pointer))
			 (ldb (byte 20  0) word)
			 (ldb (byte 20 20) word))))
	(when (region-valid-p region)
	  region)))))

) ;; Imach

;;;; Page fault

#+3600
;;; Called by the page fault escape function on the auxiliary stack.
(defwiredfun page-fault (vma fault-type)
  (declare (unsafeguarded-reference nth *page-fault-types*))
  (declare (safeguarded-reference process::block-for-page-fetch))
  (declare (dbg:error-reporter))
  (enter-storage-system *ms-time-page-fault*
    (compiler:%error-when (not storage-exists)
      (wired-ferror :fatal
        "Page fault (VMA:~\\SI:ADDRESS\\, TYPE:~O) prior to INITIALIZE-STORAGE completing"
	vma fault-type))
    (cond ((= *page-fault-depth* 0)
	   (setq *page-fault-depth* 1)
	   (setq *last-aux-page-fault-vma* vma))
	  ((> (incf* *page-fault-depth*) 3)
	   ;; --- This number used to be 2, which means a hard page fault from
	   ;; user code can still take a soft page fault on the SMPT.  That was
	   ;; all well and good until the EGC and IDS started interacting.
	   ;; There are paths through which the following can happen:
	   ;;             Main stack takes page fault
	   ;;             -> PAGE-FAULT, type 2 (pht-miss) -> ...
	   ;;             -> STORAGE-BACKGROUND-FUN -> ...
	   ;;             -> WRITE-FRAME -> ... -> ESRT-INSERT
	   ;;     ESRT-INSERT takes a page fault at pc 226 doing a RPLACD into the ESRT
	   ;;             -> PAGE-FAULT, type 0 (write-fault) -> ...
	   ;;             -> RESIDENT-PAGE-FAULT
	   ;;     RESIDENT-PAGE-FAULT takes a page fault at at pc 72 arefing
	   ;;     an element of *SYSOUT-BITMAPS*.
	   ;;             -> PAGE-FAULT, type 2 (pht-miss) -> ...
	   ;;             -> WIRED-FERROR "recursive page-fault of depth 3"
	   ;; For 6.1 make this number be 3.  A more correct solution is to
	   ;; have the wiring of the pages turn off write-protect and set the
	   ;; IDS bit.  That solution is thought to be more risky than this one.
	   (wired-ferror :fatal "Recursive page-fault of depth ~D. (zero offset)"
			 *page-fault-depth*)))
    (let* ((vpn (extract-vpn vma))
	   (pht-index (pht-lookup vpn))
	   (wait-pht-index nil))
      (cond ((not (null pht-index))
	     (resident-page-fault vma fault-type pht-index))
	    ((not (= fault-type %page-pht-miss))
	     (wired-ferror nil
			   "Bad fault type ~A on non-resident virtual address ~\\SI:ADDRESS\\"
			   (nth fault-type *page-fault-types*) vma))
	    (t
	     (setf wait-pht-index (pht-miss-handler vma))))
      (decf* *page-fault-depth*)
      ;; If this is the first frame in the aux stack buffer, faulter is in the other stack buffer.
      ;; Otherwise faulter is also in the aux stack buffer and we can just return.
      (cond ((not (zerop (frame-bottom-bit (%stack-frame-pointer))))
	     (compiler:%error-when wait-pht-index
	       (let ((vpn (extract-vpn vma)))
		 (when (and *allow-scheduling-on-page-faults*
			    (not %transport-in-progress)
			    (not %stack-group-lock)
			    (not (logtest si:%sg-stack-load-started
					  %other-stack-group-status-bits))
			    (zerop (ldb sys:%%sg-halt-on-error
					sys:%other-stack-group-status-bits))
			    (> (%pointer-difference %stack-buffer-limit %other-stack-pointer)
			       100)
			    process::*preemption-enabled*
			    (not inhibit-scheduling-flag))
		   (dotimes (index %n-page-waiters)
		     (when (null (aref *page-waiter-vpn* index))
		       (setf (aref *page-waiter-process* index) nil)
		       (setf (aref *page-waiter-vpn* index) vpn)
		       (cond ((page-idle-p vpn wait-pht-index)
			      (setf (aref *page-waiter-vpn* index) nil))
			     (t
			      (incf* *count-page-fetch-user-waits*)
			      (setf process::*preemption-enabled* nil)
			      (force-funcall-in-main-stack-buffer
				#'process::block-for-page-fetch vma index)
			      (exit-storage-system)
			      (%resume-main-stack-buffer))))))
		 ;; Disk done calls normalize which sets caches
		 (wait-for-page-idle vpn wait-pht-index)))
	     (compiler:%error-when *page-fault-exit-function*
	       (when (and (not %transport-in-progress)
			  (not %stack-group-lock)
			  (not (logtest si:%sg-stack-load-started
					%other-stack-group-status-bits))
			  (zerop (ldb sys:%%sg-halt-on-error
				      sys:%other-stack-group-status-bits))
			  (> (%pointer-difference %stack-buffer-limit %other-stack-pointer)
			     100))
		 (force-funcall-in-main-stack-buffer
		   (cl:shiftf *page-fault-exit-function* nil) vma fault-type)))
	     (exit-storage-system)
	     (%resume-main-stack-buffer))
	    (t
	     (when wait-pht-index
	       (wait-for-page-idle vpn wait-pht-index))))
      nil)))

#+IMach
(def-trap-handler page-fault
		  ((%page-not-resident-trap-vector
		     %page-fault-request-trap-vector
		     %page-write-fault-trap-vector)
		   trap-mode-extra-stack)
		  (trap-vector-index fault-pc original-vma)
  (declare (wired-function)
	   (unsafeguarded-reference cli::rescue-hung-instruction process::block-for-page-fetch)
	   (safeguarded-reference si:stack-overflow-trap-handler)
	   (dbg:error-reporter))
  ;; Invalidate the flavor mapping table cache since a page fault can happen at a
  ;; time which will leave it inconsistent.
  (setf (%read-internal-register %register-mapping-table-cache) nil)
  (si:saving-registers-for-trap-for-effect
    (enter-storage-system *ms-time-page-fault*
      (let ((wait-pht-index nil)
	    (vma (%pointer original-vma))
	    (fault-type (select trap-vector-index
			  (%page-not-resident-trap-vector %page-pht-miss)
			  (%page-fault-request-trap-vector %page-fault-requested)
			  (%page-write-fault-trap-vector %page-write-fault)
			  (otherwise
			   (wired-ferror :fatal "Incorrect trap vector index for PAGE-FAULT")))))
	(compiler:%error-unless (= (%data-type original-vma) dtp-locative)
	  (wired-ferror :fatal "Bad VMA argument ~S for PAGE-FAULT" vma))
	(compiler:%error-when (not storage-exists)
	  (wired-ferror :fatal
			"Page fault (VMA:~\\SI:ADDRESS\\, TYPE:~O) prior to INITIALIZE-STORAGE completing"
			vma trap-vector-index))
	(cond ((= *page-fault-depth* 0)
	       (compiler:%error-when (< (%pointer-difference
					  (%read-internal-register %register-control-stack-extra-limit)
					  (%read-internal-register %register-fp))
					%page-fault-extra-stack-size)
		 (wired-ferror :proceedable-halt
			       "Warning:  Estimate insufficient stack space for page-fault"))
	       (setq *page-fault-depth* 1)
	       (setq *last-aux-page-fault-vma* vma)
	       (setq *page-fault-program-counter* fault-pc)
	       (setq *page-fault-frame-pointer* (%read-internal-register %register-fp))
	       (setq *page-fault-control-register*
		     (%read-internal-register %register-control-register)))
	      ((> (incf* *page-fault-depth*) 3)
	       ;; See discussion above...
	       (wired-ferror :fatal "Recursive page-fault of depth ~D. (zero offset)"
			     *page-fault-depth*)))
	(let ((pht-index (pht-lookup (extract-vpn vma))))
	  (cond ((not (null pht-index))
		 (resident-page-fault vma fault-type pht-index))
		(t
		 (compiler:%error-unless (= fault-type %page-pht-miss)
		   (wired-ferror nil "Bad fault type ~O on non-resident virtual address ~\\SI:ADDRESS\\"
				 fault-type vma))
		 (setf wait-pht-index (pht-miss-handler vma)))))
	(decf* *page-fault-depth*)
	(block wait-for-page
	  #-VLM
	  (when wait-pht-index
	    (let ((vpn (extract-vpn vma)))
	      (when (and *allow-scheduling-on-page-faults*
			 (zerop si:%transport-trap-level)
			 (= (ldb %%cr.trap-mode (%saved-control-register)) trap-mode-emulator)
			 process::*preemption-enabled*
			 (not inhibit-scheduling-flag)
			 (not si:%stack-group-lock)
			 ;; Make sure we aren't in the middle of a stack group switch.
			 ;; This can only happen during co-routining, otherwise
			 ;; *preemption-enabled* would have already been NIL.
			 (not (si:bit-test si:%sg-stack-load-started
					   si:%current-stack-group-status-bits))
			 ;; Not enough room to funcall BLOCK-FOR-PAGE-FETCH on
			 ;; main-stack?
			 (> (%pointer-difference
			      (%read-internal-register %register-control-stack-limit)
			      (%read-internal-register %register-fp))
			    #o100))
		(dotimes (index %n-page-waiters)
		  (when (null (aref *page-waiter-vpn* index))
		    (setf (aref *page-waiter-process* index) nil)
		    (setf (aref *page-waiter-vpn* index) vpn)
		    (cond ((page-idle-p vpn wait-pht-index)
			   (setf (aref *page-waiter-vpn* index) nil))
			  (t
			   (incf* *count-page-fetch-user-waits*)
			   (exit-storage-system)
			   ;; Safely exit to the scheduler
			   (setf process::*preemption-enabled* nil)
			   (%set-trap-mode sys:trap-mode-emulator)
			   (process::block-for-page-fetch original-vma index)
			   (return-from wait-for-page))))))
	      ;; Disk done calls normalize which sets caches
	      (wait-for-page-idle vpn wait-pht-index)))
	  (compiler:%error-when (not (null *page-fault-exit-function*))
	    (when (and (= *page-fault-depth* 0)
		       (zerop si:%transport-trap-level)
		       (not %stack-group-lock)
		       (= (ldb %%cr.trap-mode (cli::%saved-control-register)) trap-mode-emulator)
		       (> (%pointer-difference
			    (%read-internal-register %register-control-stack-limit)
			    (%read-internal-register %register-fp))
			  100))
	      (exit-storage-system)
	      (%set-trap-mode trap-mode-emulator)
	      (funcall (shiftf *page-fault-exit-function* nil) vma fault-type)))))))
  (cli::check-for-hung-instruction fault-pc))

(defwiredfun pht-miss-handler (vma)
  (compiler:%error-when (> *page-fault-depth* 1)
    (wired-ferror :fatal
		  "Page fault on non-resident virtual address ~\\SI:ADDRESS\\ during a page-fault"
		  vma))
  (let ((vpn (extract-vpn vma))
	(region (%region-number vma)))
    (compiler:%error-when (null region)
      ;; If the page belongs to no region whatsoever, signal an error immediately.
      #+3600
      ;; See SIGNAL-PAGE-FAULT-ON-UNALLOCATED-VMA before you change this message.
      (wired-ferror 'page-fault-on-unallocated-vma
		    "Page fault on unallocated VMA ~\\SI:ADDRESS\\, %other-pc ~S,
%other-frame-pointer ~S, %other-stack-pointer ~S"
		    vma %other-pc %other-frame-pointer %other-stack-pointer)
      #+IMach
      (wired-ferror 'page-fault-on-unallocated-vma
		    "Page fault on unallocated VMA ~\\SI:ADDRESS\\" vma)
      (return-from pht-miss-handler nil))
    (when ( (deposit-vpn vpn 0)
	     (address-plus (region-origin region) (si:real-region-free-pointer region)))
      ;; If the page contains only locations greater than or equal to the free
      ;; pointer of the containing region, just create the page full of trap
      ;; pointers, which will cause data type errors at a higher level.  Note that
      ;; there may already be disk space allocated to represent this page, but
      ;; that disk block may not be initialized.  This will do the right thing in
      ;; that case.
      (create-page-range vpn 1)
      (return-from pht-miss-handler nil))
    #+VLM
    (wired-ferror nil "Miss fault on extant virtual address ~\\SI:ADDRESS\\?" vma)
    #-VLM
    (let ((swapin-quantum (ldb %%region-swapin-quantum (region-bits region))))
      (cond ((= swapin-quantum 0)
	     (swap-fetch vpn vma))
	    ((< swapin-quantum 4)
	     (with-disk-wakeup-optimization
	       (swap-fetch vpn vma)
	       (prefetch-pages (1+ vpn) swapin-quantum)))
	    (t
	     (swap-fetch vpn vma)
	     (prefetch-pages (1+ vpn) swapin-quantum)))
      (incf* *count-page-fetches*)
      (pht-lookup vpn))))

#+3600
;;; VMA is already resident.  Determine reason for fault.
;;; Note that if this code just returns without loading the map cache, when the
;;; faulted instruction is executed the fault will reoccur.  This is used for
;;; those pages whose state is changing (e.g. being read or written to disk).
(defwiredfun resident-page-fault (vma fault-type pht-index)
  (declare (dbg:error-reporter))
  (with-quick-pht-accessors
    (let ((pht-entry (pht-entry pht-index)))
      (if (not (zerop (ldb %%pht-entry-pending pht-entry)))
	  ;; VPN is pending: page is waiting for a flush-write to complete before being read
	  (wait-until-frame-prepared pht-index t)
	;; VPN isn't pending: the page is really resident.
	(let ((mmpt-index (mmpt-lookup (ldb %%pht-entry-ppn pht-entry))))
	  (or mmpt-index
	      (wired-ferror :fatal "System page hash table points to a nonextant ~@
				 physical page at PHT index: ~O" pht-index))
	  (select fault-type
	    (%page-pht-miss			;+ Until ucode does pht lookups.
	     ;; This actually means paging-cache miss (map cache and phtc) for now
	     (cond ((zerop (ldb %%pht-entry-fault-request pht-entry))
		    (incf* *count-map-misses*)
		    (cache-put mmpt-index))	; Just load caches
		   (t
		    (decode-fault-request vma pht-index mmpt-index))))
	    (%page-write-fault
	     ;; This happens upon a write reference to a location which has write-protect
	     ;; set in the caches.  Determine if the page is really write protected, and
	     ;; if not, set its modified flag and clear the write-protect in the caches.
	     ;; This mechanism is used to set the modified flag without requiring incurring
	     ;; the hardware cost similar to the page reference tags.  The overhead is
	     ;; acceptable since it only occurs for the first write reference per disk read.
	     ;;
	     ;; Normally the page is really write protected if mmpt-write-protect is set.
	     ;; However, when *sysout-enabled-p* is true, the first time a page is loaded
	     ;; from the world load file both mmpt-write-protect and mmpt-modified will
	     ;; be true;  mmpt-modified is set to force the page out to the swap area to
	     ;; make subsequent fetches faster, and mmpt-write-protect is set to force
	     ;; a write-first fault so the sysout bitmap can be updated.
	     (with-quick-mmpt-accessors
	       (when *sysout-enabled-p*
		 (let ((vpn (extract-vpn vma)))
		   (when (not (zerop (mmpt-write-protect mmpt-index)))
		     ;; This probably is a page which has been loaded from
		     ;; the world load file and is being modified 
		     (setf (sysout-bitmap vpn) t)
		     ;; Reset the write-protect correctly
		     (setf (mmpt-write-protect mmpt-index)
			   (let ((region-number (%region-number (* vpn page-size))))
			     (if (and region-number
				      (ldb-test %%region-read-only
						(region-bits region-number)))
				 1		; Write protected
			       0))))))
	       (let ((mmpt-entry (mmpt-entry mmpt-index)))
		 ;; Make sure page is valid.
		 (unless (or (= %mmpt-status-normal (mmpt-entry-status mmpt-entry))
			     (= %mmpt-status-wired (mmpt-entry-status mmpt-entry)))
		   (wired-ferror nil "Write to a ~O page at virtual address ~\\SI:ADDRESS\\"
				 (mmpt-entry-status mmpt-entry) vma))
		 ;; Recheck write protect to see if write reference is allowed.
		 (cond ((zerop (mmpt-entry-write-protect mmpt-entry))
			;; Yep, a write first fault.  Set modified bits, and clear write
			;; protect.
			(incf* *count-write-first-faults*)
			(setf (mmpt-entry mmpt-index) (dpb 1 %%mmpt-modified mmpt-entry))
			(cache-put mmpt-index))
		       ((plusp *inhibit-read-only-in-progress*)
			;; Overriding a write-protected page.
			(incf* *count-inhibited-read-only-faults*)
			;; Remember it for later undoing.
			(when (< *read-only-n-written-pages* %read-only-written-pages-size)
			  (setf (aref *read-only-written-pages* *read-only-n-written-pages*)
				mmpt-index))
			(incf *read-only-n-written-pages*)
			;; Set modified bit and allow writing.
			(setf (mmpt-entry mmpt-index) (dpb 1 %%mmpt-modified mmpt-entry))
			(cache-put mmpt-index t))
		       (%transport-in-progress
			;; Transporter can write in read-only by special dispensation.
			(clear-transporter-read-only-vpn)
			(setq *transporter-read-only-vpn* (extract-vpn vma))
			(setf (mmpt-entry mmpt-index) (dpb 1 %%mmpt-modified mmpt-entry))
			(cache-put mmpt-index t))
		       (t
			;; Before changing this error message, see SIGNAL-WRITE-IN-READ-ONLY.
			(wired-ferror 'write-in-read-only
			  "Write to a write-protected virtual address ~\\SI:ADDRESS\\"
			  vma))))))
	    (%page-fault-requested
	     (decode-fault-request vma pht-index mmpt-index))
	    (otherwise
	     ;; Should never happen on a resident page unless ucode PHT lookup is wrong
	     (wired-ferror :fatal
			   "Bad fault type ~O on resident virtual address ~\\SI:ADDRESS\\"
			   fault-type vma))))))))

#+3600
(defwiredfun clear-transporter-read-only-vpn ()
  (when *transporter-read-only-vpn*
    (cache-remove (deposit-vpn *transporter-read-only-vpn* 0))
    (setq *transporter-read-only-vpn* nil)))

#+IMach
;;; VMA is already resident.  Determine reason for fault.
(defwiredfun resident-page-fault (vma fault-type pht-index)
  (declare (dbg:error-reporter))
  #-VLM
  (when ( (pht-pending pht-index) 0)
    ;; VPN is pending: page is waiting for a flush-write to complete before being read
    (return-from resident-page-fault
      (wait-until-frame-prepared pht-index t)))
  ;; VPN isn't pending: the page is really resident.
  (let (#-VLM(mmpt-index (mmpt-lookup (pht-ppn pht-index))))
    #-VLM
    (when (null mmpt-index)
      (wired-ferror :fatal "PHT entry at ~O points to a nonextant physical page" pht-index))
    (cond #-VLM
	  ((= (pht-fault-request pht-index) 1)
	   (decode-fault-request vma pht-index mmpt-index))
	  ((= fault-type %page-write-fault)
	   ;; Simpler than on the 3600.  Since the hardware supports a modified bit,
	   ;; there are no write-first faults.  So we know that this is a write-protect
	   ;; violation, due either to sysout or a write to a read-only region.
	   (let ((status (mmpt-status mmpt-index)))	;sanity check page status
	     (unless (or (= %mmpt-status-normal status) (= %mmpt-status-wired status))
	       (wired-ferror nil "Write to a ~O page at virtual address ~\\SI:ADDRESS\\"
			     status vma)))
	   #-VLM ; --- for now (I think SYSOUT should be done in C)
	   ;; Record the page in the sysout map, and reset write-protect appropriately.
	   (when *sysout-enabled-p*
	     (setf (sysout-bitmap (extract-vpn vma)) t)
	     (incf* *count-write-first-faults*)
	     (setf (pht-write-protect pht-index)
		   (let ((region (%region-number vma)))
		     (if (not (null region))
			 (ldb %%region-read-only (region-bits region))
			 0))))
	   ;; If the page is still write-protected, the page is read-only.  Signal an
	   ;; error unless read-only has been inhibited, then allow the write.
	   (when ( (pht-write-protect pht-index) 0)
	     (when (= *inhibit-read-only-in-progress* 0)
	       (if (not %transport-in-progress)
		   ;; Proceeding will leave that page unwrite-protected while it's resident.
		   (wired-ferror 'write-in-read-only
				 "Write to write-protected virtual address ~\\SI:ADDRESS\\"
				 vma)
		   ;; Transporter can write in read-only by special dispensation.
		   (clear-transporter-read-only-vpn)
		   (setq *transporter-read-only-vpn* (extract-vpn vma))
		   (setf (pht-write-protect pht-index) 0)
		   (cache-remove vma)
		   (return-from resident-page-fault nil)))
	     ;; Overriding a write-protected page.
	     (incf* *count-inhibited-read-only-faults*)
	     ;; Try to remember it for later undoing.
	     (when (< *read-only-n-written-pages* %read-only-written-pages-size)
	       (setf (aref *read-only-written-pages* *read-only-n-written-pages*)
		     mmpt-index))
	     (incf *read-only-n-written-pages*)
	     ;; Allow writing to this page.  Let the hardware take care of setting
	     ;; the modified bit, since some processor implementations may include a
	     ;; comparator to avoid modifying pages unless their contents changes.
	     (setf (pht-write-protect pht-index) 0))
	   ;; Remove the page from the map cache to force the hardware to reload it.
	   (cache-remove vma))
	  ;; The page wasn't resident (no PHT entry, or fault request was set) when the
	  ;; hardware did its lookup, but became resident in the window before the
	  ;; storage system was locked against disk completion interrupts.  Just return
	  ;; and try again.
	  ((= fault-type %page-pht-miss))
	  (t
	   (wired-ferror :fatal
			 "Bad fault type ~O on resident virtual address ~\\SI:ADDRESS\\"
			 fault-type vma)))))

#+IMach
(defwiredfun clear-transporter-read-only-vpn ()
  (when *transporter-read-only-vpn*
    (let ((pht-index (pht-lookup *transporter-read-only-vpn*)))
      (when pht-index
	(setf (pht-write-protect pht-index) 1)
	(cache-remove (deposit-vpn *transporter-read-only-vpn* 0))))
    (setq *transporter-read-only-vpn* nil)))

;;; Decode the reason for pht-fault-request being set on a resident page.
#-VLM
(defwiredfun decode-fault-request (vma pht-index mmpt-index)
  (select (mmpt-status mmpt-index)
    (%mmpt-status-flushable
     ;; Remove from flushable page queue.
     (normalize-frame mmpt-index pht-index)
     (when *page-trace-array*
       (page-trace-insert %page-trace-flushable-page-fault vma))
     (incf* *count-flushable-page-faults*))
    (%mmpt-status-prefetched
     ;; Change status to normal.  No need to remove from flushable cache
     ;; since it checks for flushable status when dequeueing.
     (normalize-frame mmpt-index pht-index)
     (when *page-trace-array*
       (page-trace-insert %page-trace-prefetched-page-fault vma))
     (incf* *count-prefetched-page-faults*))
    ((%mmpt-status-reading %mmpt-status-writing)
     ;; Wait for read to complete.  Page is probably being prefetched if reading,
     ;; or flushed by background process if writing.
     ;; If writing, don't really need to wait for disk done if updating of
     ;; the modified bit could be smart, but infrequency of occurance should
     ;; make this ok. +++?
     (incf* *count-busy-page-faults*)
     (wait-for-page-idle (extract-vpn vma) pht-index))
    (%mmpt-status-prefetched-mark
     (normalize-frame mmpt-index pht-index)
     (when *page-trace-array*
       (page-trace-insert %page-trace-prefetched-page-fault vma))
     (incf* *count-prefetched-page-faults*)
     ;; Prefetch next group
     (prefetch-pages (1+ (extract-vpn vma))
		     (ldb %%region-swapin-quantum (region-bits (%region-number vma)))))
    (otherwise
     (wired-ferror :fatal
		   "PHT-FAULT-REQUEST invalid for a ~O page at virtual address ~\\SI:ADDRESS\\"
		   (mmpt-status mmpt-index) vma))))

;;; Called by the user with a %FUNCALL-IN-AUX-STACK.  This entry point is needed
;;; just for metering purposes.
(defwiredfun user-prefetch-pages (vma n-pages
				      &optional (load-map-only-p nil) (normalize-p nil))
  (enter-storage-system *ms-time-user-prefetch-pages*
    (prefetch-pages (extract-vpn vma) n-pages load-map-only-p normalize-p)))

;;; Must be called on the auxiliary stack.
;;; Prefetch in the pages starting at VMA for N-PAGES.
;;; If LOAD-MAP-ONLY-P is true, only prefetch from the load file.
;;; If NORMALIZE-P is true, normalize the page as if demand fetched instead of prefetched.
(defwiredfun prefetch-pages (vpn n-pages &optional (load-map-only-p nil) (normalize-p nil))
  #+VLM
  ;; Perhaps the VLM will someday advise the host to prefetch?
  (progn vpn n-pages load-map-only-p normalize-p nil)
  #-VLM
  (let ((region (%region-number (deposit-vpn vpn 0))))
    (if (not (null region))
	(let* ((end-swapin-vpn (+ vpn n-pages))
	       (region-end (address-plus (region-origin region)
					 (si:real-region-free-pointer region)))
	       ;; Don't prefetch beyond the end of the region
	       (end-swapin-vpn (if ( (deposit-vpn end-swapin-vpn 0) region-end)
				   (if (zerop (ldb %%vma-word-offset region-end))
				       (extract-vpn region-end)
				     ;; Keep end-swapin-vpn exclusive
				     (1+ (extract-vpn region-end)))
				 end-swapin-vpn))
	       ;; The VPN to mark for automatic prefetching in a sequential region
	       (mark-vpn (if (= %paging-type-sequential
				(ldb %%region-paging-type (region-bits region)))
			     (max* (1- end-swapin-vpn) vpn)
			   nil)))
	  (prefetch-pages-internal vpn end-swapin-vpn mark-vpn load-map-only-p normalize-p))
      (load-bitmap vpn
	(setf (load-bitmap vpn) nil)))))

#-VLM (PROGN
(defwiredfun prefetch-pages-internal (start-vpn end-vpn mark-vpn load-map-only-p normalize-p)
  (with-quick-pht-and-mmpt-accessors
    (macrolet ((touch-page (mmpt-index pht-index &environment environment)
		 ;; Try to keep this page from being replaced.
		 (once-only (mmpt-index pht-index &environment environment)
		   `(let ((mmpt-status (mmpt-status ,mmpt-index)))
		      (cond ((= mmpt-status %mmpt-status-normal)
			     #+IMach (setf (pht-reference-bits ,pht-index) 0)
			     #+3600 (setf (mmpt-age ,mmpt-index) *normal-page-age*))
			    ((bit-member mmpt-status *flushable-status*)
			     ;; +++ When prefetching a resident, flushable page, we'd ideally
			     ;; like to move the frame from whereever it is in the flushable
			     ;; queue to the end of the queue.  However, there's no way to do
			     ;; that without a linear scan, so instead we normalize the frame
			     ;; but label it as having not been referenced in a while, so the
			     ;; replacement algorithm flushes it sooner.
			     (normalize-frame ,mmpt-index ,pht-index)
			     (when (not normalize-p)
			       #+3600 (progn (%reference-tag-write
					       (dpb (pht-ppn pht-index) %%pma-page-num 0)
					       nil)
					     (setf (mmpt-age ,mmpt-index) 0))
			       #+IMach (setf (pht-reference-bits pht-index) #b10))))))))
      (let ((second-pass-needed nil))
	;; Prefetch swapin-quantum pages.
	;; First, scan through the vpn range setting the age of all resident pages
	;; so they won't be flush-written to make room for another page just to
	;; be read in again.  This has to be done in a separate pass prior to
	;; finding frames for the non-resident pages.  If this isn't done
	;; some pages won't be prefetched at all since the routine will be
	;; faked out into thinking they are resident while their flush
	;; write is in progress.
	(loop for vpn from start-vpn below end-vpn do
	  (let ((pht-index (pht-lookup vpn)))
	    (if (or (null pht-index) ( (pht-pending pht-index) 0))
		(setq second-pass-needed t)
	      (let ((mmpt-index (mmpt-lookup (pht-ppn pht-index))))
		(touch-page mmpt-index pht-index)
		;; If the load map is being evacuated, make sure the page gets written.
		(when (and load-map-only-p *load-pages-to-swap-area-p*)
		  (load-bitmap vpn
		    #+3600 (setf (mmpt-modified mmpt-index) 1)
		    #+IMach (setf (pht-modified pht-index) 1)
		    (setf (aref map index) nil)))))))
	;; Then scan through the vpn range to prefetch all the nonresident
	;; pages.  To minimize the disk latency the modified page writes
	;; are grouped together with a blocking factor of %prefetch-size
	;; followed by a group of corresponding prefetch reads.
	(when second-pass-needed
	  (loop for vpn from start-vpn by %prefetch-size do
	    (loop for i below %prefetch-size
		  for prefetch-vpn from vpn
		  ;; Keep on prefetching until end of range or else
		  ;; the disk queue is full and hanging isn't desired.
		  while (< prefetch-vpn end-vpn)
		  finally (prefetch-enq-reads vpn i mark-vpn normalize-p)
		  do
	      (cond ((or (null load-map-only-p)
			 (load-bitmap prefetch-vpn))
		     (let ((pht-index (pht-lookup prefetch-vpn)))
		       (cond (pht-index
			      ;; Page is already resident or trying to be
			      (when (zerop (pht-pending pht-index))
				(touch-page (mmpt-lookup (pht-ppn pht-index)) pht-index))
			      ;; Don't need to read it from disk
			      (setf (aref *prefetch-frames* i) nil))
			     (t
			      ;; Page is not resident
			      (let ((mmpt-index (find-frame (- end-vpn prefetch-vpn))))
				(cond (mmpt-index
				       (setf (aref *prefetch-frames* i) mmpt-index)
				       ;; Enqueue all the disk writes in a block
				       (prepare-frame mmpt-index prefetch-vpn))
				      (t
				       (setf (aref *prefetch-frames* i) nil))))))))
		    (t
		     ;; Only prefetching from the load map, but page isn't there.
		     (setf (aref *prefetch-frames* i) nil))))
		while (< vpn end-vpn)))))))

;;; After enqueuing all the disk writes for the selected frames, enqueue the disk reads
;;; After enqueuing all the disk writes for the selected frames, enqueue the disk reads
(defwiredfun prefetch-enq-reads (starting-vpn n-entries mark-vpn normalize-p)
  (with-disk-wakeup-optimization
    (do ((i 0 (1+ i))
	 (prefetch-vpn starting-vpn (1+ prefetch-vpn)))
	(( i n-entries))
      (let ((mmpt-index (aref *prefetch-frames* i)))
	(when (not (null mmpt-index))
	  (swap-prefetch prefetch-vpn mmpt-index mark-vpn normalize-p))))))

;;; Set the pages' status to immediately flushable.  If WRITE-P is true,
;;; enqueue the writes for any modified pages now.
(defwiredfun flush-pages (base-vpn n-pages &optional (write-p nil) head-enqueue-p)
  (enter-storage-system *ms-time-user-flush-pages*
    (with-quick-pht-and-mmpt-accessors
      (do* ((vpn base-vpn (1+ vpn))
	    (end-vpn (+ vpn n-pages)))
	   (( vpn end-vpn))
	(let ((pht-index (pht-lookup vpn)))
	  (when (and pht-index (zerop (pht-pending pht-index)))
	    (let ((mmpt-index (mmpt-lookup (pht-ppn pht-index))))
	      (when (bit-member (mmpt-status mmpt-index) *normalizable-status*)
		(let ((modified-p #+3600 ( (mmpt-modified mmpt-index) 0)
				  #+IMach ( (pht-modified pht-index) 0)))
		  ;; queue the write first, lest the backgound task see
		  ;; the frame on the flushable queue
		  (when (and modified-p write-p)
		    (write-frame mmpt-index #+IMach pht-index))
		  ;; Don't enqueue modified at the head of the list
		  ;; unless we wrote it and head-enqueue-p is not
		  ;; :unmodified
		  (flush-frame mmpt-index pht-index
		    (and head-enqueue-p
			 (or (not modified-p)
			     (and write-p
				  (not (eq head-enqueue-p :unmodified))))))
		  )))))))))

(defwiredfun not-pending-p (pht-index)
  "Returns true if the PHT-PENDING flag is clear for the given PHT index."
  (zerop (pht-pending pht-index)))

(defwiredfun page-idle-p (vpn pht-index)
  "AUX: Returns true if the page is resident without io in progress or not resident."
  #+3600
  (let ((pht-entry (pht-entry pht-index)))
    (or (null pht-entry)			; In case a flush write completes
	(and (zerop (ldb %%pht-entry-pending pht-entry))
	     (let* ((mmpt-index (mmpt-lookup (ldb %%pht-entry-ppn pht-entry)))
		    (mmpt-entry (mmpt-entry mmpt-index)))
	       (or ( (mmpt-entry-vpn mmpt-entry) vpn)	; Also in case a flush write completes
		   (let ((status (mmpt-entry-status mmpt-entry)))
		     (and ( status %mmpt-status-reading)
			  ( status %mmpt-status-writing))))))))
  #+IMach
  (or (= (pht-vpn pht-index) %pht0-invalid-vpn)
      (and (= (pht-pending pht-index) 0)
	   (let ((mmpt-entry (mmpt-entry (mmpt-lookup (pht-ppn pht-index)))))
	     (or ( (mmpt-entry-vpn mmpt-entry) vpn)	; Also in case a flush write completes
		 (let ((status (mmpt-entry-status mmpt-entry)))
		   (and ( status %mmpt-status-reading)
			( status %mmpt-status-writing))))))))

(defwiredfun pending-queue-not-full-p ()
  "AUX: Returns true if the pending queue is not full."
  (< *count-pending* (1- %pending-size)))

(defwiredfun wait-for-page-idle (vpn pht-index)
  "AUX: Wait for the page to be resident and without any io in progress."
  (or (page-idle-p vpn pht-index)
      (timed-wired-wait *ms-time-page-idle-wait* t 30000. #'page-idle-p vpn pht-index)))

(defwiredfun write-unlocked-p (mmpt-index)
  "Returns true if the frame's write-lock is clear (no background writes in progress)."
  (zerop (mmpt-write-lock mmpt-index)))

(defwiredfun wait-until-frame-unlocked (mmpt-index &optional (disk-permit t))
  "AUX: Wait for the frame's write-lock to be clear (no background writes in progress).
   If DISK-PERMIT is true, permit enqueuing of more background writes while waiting."
  (or (write-unlocked-p mmpt-index)
      (timed-wired-wait *ms-time-write-lock-wait* disk-permit 30000.
			#'write-unlocked-p mmpt-index)))

(defwiredfun wait-until-frame-prepared (pht-index &optional (disk-permit t))
  "AUX: Wait for the frame to really contain the desired page.  Doesn't wait for the
   page's status to be unbusy.  This is used after prepare-frame before any
   manipulation of the frame's datastructure to insure that any flush writes
   have completed.
   If DISK-PERMIT is true, permit enqueuing of more background writes while waiting."
  (or (zerop (pht-pending pht-index))
      (timed-wired-wait *ms-time-pending-wait* disk-permit 30000. #'not-pending-p pht-index)))
) ;#-VLM

;;;+++ TEMPORARY until integrated into scheduler
(defwiredfun wired-wait (disk-permit ms-limit function &rest arguments)
  (declare (unsafeguarded-reference process-wait SI:PROCESS-SPIN-WAIT))
  (declare (sys:downward-funarg function))
  (declare (future-common-lisp:ignorable disk-permit))
  ;; Issue deferred wakeups, in case you plan to wait on one of
  ;; them!
  (without-disk-wakeup-optimization
    (cond ((%auxiliary-stack-p)
	   ;; Unlock storage system to allow completion routines to run.
	   (without-storage-lock
	     ;; Turn on the "disk" or "wait" run bar
	     (let ((old-run-light (si:get-run-light process-run-light)))
	       (when old-run-light
		 (si:clear-run-light process-run-light))
	       (si:set-run-light disk-run-light)
	       (do ((start-time (%microsecond-clock))
		    (us-limit (* ms-limit 1000.)))
		   ((apply function arguments))
		 ;; Check for timeout.
		 (when (< us-limit (wired-time-difference (%microsecond-clock) start-time))
		   (unless (si:check-disk-hung)
		     (wired-ferror :proceedable-halt
				   "Wired-wait timeout, predicate ~S false for over ~D. ms."
				   function ms-limit))
		   (setq start-time (%microsecond-clock)))	;Make error proceedable
		 ;; Service "interrupts"
		 #-VLM (storage-background-fun disk-permit)
		 (si:sequence-break-internal))
	       ;; Turn off the run bar
	       (si:clear-run-light disk-run-light)
	       (when old-run-light
		 (si:set-run-light process-run-light)))))
	  ((or (null process::*preemption-enabled*)
	       inhibit-scheduling-flag)
	   (apply #'si:process-spin-wait "Wired wait" function arguments))
	  (t
	   (apply #'process-wait "Wired wait" function arguments))))
  nil)


#-VLM (PROGN
;;;; Swap management

;;; Fetch in the page from either the swap or load space.  If from the load space, also
;;; prefetch in the subsequent *load-map-swapin-quantum* pages.
;;; Returns the PPN fetched into.  Doesn't wait for the fetch to complete.
;;; Must be called on the aux stack.
(defwiredfun swap-fetch (vpn &optional vma)
  (cond ((load-bitmap vpn)
	 ;; In load map.  Fetch the page, followed by *load-map-swapin-quantum* prefetches
	 (let ((ppn (swap-fetch-1 vpn %class-fetch-load vma)))
	   (incf* *count-load-fetches*)
	   (disk-enqueue-wakeup)		; Enqueue wakeup prior to load prefetches
	   (when (and *load-pages-to-swap-area-p*
		      ;; this really wants to be smarter.  In
		      ;; particular, it should prefetch pages with a
		      ;; restriction that the DPN doesn't vary too much.
		      (zerop *sysout-generation-number*))
	     (let* ((prefetch-vma (deposit-vpn (1+ vpn) 0))
		    (region (%region-number prefetch-vma)))
	       (when (and region
			  ( (region-origin region) prefetch-vma)
			  (not (ldb-test %%region-stack (region-bits region))))
		 (prefetch-pages (1+ vpn) *load-map-swapin-quantum* t))))
	   ppn))
	(t
	 ;; Not in load map.
	 (prog1 (swap-fetch-1 vpn %class-fetch vma)
		(disk-enqueue-wakeup)))))

;;; Do the dirty work required to enqueue the disk read.  Returns the PPN enqueued to.
(defwiredfun swap-fetch-1 (vpn class vma)
  "Must be called on the aux stack"
  ;; Must create the smpt entry if need be prior to finding a frame for the fetch.
  (let ((dpn (swap-read-lookup vpn)))
    (cond (dpn
	   (when *load-pages-to-swap-area-p*
	     (smpt-create vpn))
	   ;; Page exists on disk.  Read it in.
	   (let ((mmpt-index (find-frame 1 t)))
	     (let ((ppn (mmpt-index-to-ppn mmpt-index)))
	       (prepare-frame mmpt-index vpn)
	       ;; Start the disk fetching the demanded page
	       (disk-enqueue-page-read class dpn ppn)
	       (when *page-trace-array*
		 (page-trace-insert class (or vma (deposit-vpn vpn 0))))
	       ppn)))
	  ((%region-number (deposit-vpn vpn 0))
	   ;; Page is not on disk.  Just create it full of trap pointers.  It is either
	   ;; a stack page that has been deleted or a page past a free pointer that is
	   ;; being referenced erroneously; the trap pointer will cause a data type error.
	   ;; The %region-number check is only to detect total malfeasance in the paging code.
	   (create-page-range vpn 1)
	   (pht-ppn (pht-lookup vpn)))		; Return the PPN
	  (t
	   (wired-ferror :fatal "Page fault on nonextant page number ~O (octal)" vpn)))))

;;; Enqueue a prefetch for a page, reading it from the load or paging space.
;;; Unlike swap-fetch, this takes a mmpt-index instead of finding one for itself
;;; so prefetch-pages can enqueue all the flush writes prior to enqueuing any of
;;; the reads (which are probably contiguous) to minimize seeking.
;;;+++ Unfortunately can't create the smpt entry here since the frame is already
;;; selected.  At least the number of load prefetches is very small.
(defwiredfun swap-prefetch (vpn mmpt-index mark-vpn &optional (normalize-p nil))
  "Must be called on the auxiliary stack"
  (let ((dpn (swap-read-lookup vpn)))
    (cond ((not (null dpn))
	   ;; Page exists on disk
	   (let* ((load-map-p (load-bitmap vpn))
		  (class
		    (cond ((eq vpn mark-vpn)	;mark-vpn might be nil
			   (if load-map-p %class-prefetch-load-mark %class-prefetch-mark))
			  (normalize-p
			   (if load-map-p %class-fetch-load %class-fetch))
			  (t
			   (if load-map-p %class-prefetch-load %class-prefetch)))))
	     (cond ((not normalize-p)
		    (incf* *count-page-prefetches*)
		    (when load-map-p (incf* *count-load-prefetches*)))
		   (t
		    (incf* *count-page-fetches*)
		    (when load-map-p (incf* *count-load-fetches*))))
	     (disk-enqueue-page-read class dpn (mmpt-index-to-ppn mmpt-index))
	     (when *page-trace-array*
	       (page-trace-insert class (deposit-vpn vpn 0)))))
	  ((%region-number (deposit-vpn vpn 0))
	   ;; Page is not on disk.  Just create it full of trap pointers.  It is either
	   ;; a stack page that has been deleted or a page past a free pointer that is
	   ;; being referenced erroneously; the trap pointer will cause a data type error.
	   ;; The %region-number check is only to detect total malfeasance in the paging code.
	   ;; Can't just call create-page since the frame has already been prepared
	   ;; by prefetch.
	   (let ((pht-index (pht-lookup vpn)))
	     ;; If flush-writing, the VPN will be pending.  Must wait for the flush-write to
	     ;; complete before trying to normalize the frame.
	     (wait-until-frame-prepared pht-index)
	     #+3600 (setf (mmpt-modified mmpt-index) 1)
	     #+IMach (setf (pht-modified pht-index) 1)
	     (normalize-frame mmpt-index pht-index)
	     (let ((vma (deposit-vpn vpn 0)))
	       (%block-store-tag-and-pointer vma page-size dtp-null vma 1))))
	  (t
	   (wired-ferror :fatal "Page prefetch on nonextant page number ~O (octal)" vpn)))))

(defwiredfun load-map-lookup (vpn)
  (declare (values dpn start-dpn n-pages))
  (when (or (and *load-map-cached-vpn*
		 ( vpn *load-map-cached-vpn*)
		 (< vpn (+ *load-map-cached-vpn* *load-map-cached-n-pages*)))
	    (loop with low = 0 with high = load-map-size	;low inclusive, high exclusive
		  when ( low high) return nil
		  as mid = (lsh (+ low high) -1)
		  as v = (load-map-vpn mid)
		  do (cond ((< vpn v)
			    (setq high mid))
			   (( vpn (+ v (load-map-n-pages mid)))
			    (setq low (1+ mid)))
			   (t (setq *load-map-cached-vpn* v
				    *load-map-cached-n-pages* (load-map-n-pages mid)
				    *load-map-cached-dpn* (load-map-dpn mid))
			      (return t)))))
    (values (+ *load-map-cached-dpn* (- vpn *load-map-cached-vpn*))
	    *load-map-cached-dpn*
	    *load-map-cached-n-pages*)))

;;; Lookup the VPN's secondary memory address, returning the DPN.
;;; The DPN returned should be used only for read operations since it may
;;; be either in the swap space or load band.
(defwiredfun swap-read-lookup (vpn)
  (if (load-bitmap vpn) (load-map-lookup vpn) (smpt-lookup vpn)))

;;; Lookup the VPN's secondary memory address, creating one if none exist.
;;; This should only be called for memory to disk write operations, so the
;;; load map need not be checked and the DPN is always in the swap area.
(defwiredfun swap-write-lookup (vpn)
  (smpt-create vpn))

(defwiredfun swap-count (addr size)
  (loop for i below size
	as n = (%p-contents-offset addr i)
	sum (if (minusp n)
		(swap-count (%p-contents-as-locative-offset addr i)
			    %swap-map-extension-size)
		n)))

(defwiredfun adjust-*count-swap-pages* ()
  (declare (values adjustment))
  (let ((old-remaining *count-remaining-swap-pages*)
	(new-remaining (swap-count swap-map-address swap-map-size)))
    (setf *count-remaining-swap-pages* new-remaining)
    (let ((increment (- new-remaining old-remaining)))
      (incf *count-swap-pages* increment)
      increment)))

;;; Assign some contiguous disk space in the swap space, assigning less
;;; if no contiguous chunk big enough.
(defwiredfun swap-assign (n-pages vpn)
  (declare (values dpn n-pages))
  (labels ((swap-scan (n-pages vpn addr dpn-addr size)
	     (declare (values n-pages locf-n-pages locf-dpn))
	     vpn				;+ Not currently used.  Can be used to enhance swap locality sometime
	     (let ((best-n-pages 0)
		   best-locf best-locf-dpn)
	       (cl:dotimes (i size (values best-n-pages best-locf best-locf-dpn))
		 (let* ((locf (%p-structure-offset addr i))
			(n (location-contents locf))
			locf-dpn)
		   (if (minusp n)
		       ;; N is actually a pointer to an extension table
		       (multiple-value-setq (n locf locf-dpn)
			 (swap-scan n-pages vpn
				    (%make-pointer dtp-locative n)	; Make a loc for fun
				    (%p-contents-as-locative-offset dpn-addr i)
				    %swap-map-extension-size))
		       (setq locf-dpn (%p-structure-offset dpn-addr i)))
		   (cond (( n n-pages)
			  (return (values n locf locf-dpn)))
			 ((> n best-n-pages)
			  (setq best-n-pages n
				best-locf locf
				best-locf-dpn locf-dpn))))))))
    (loop doing
      (multiple-value-bind (n locf-n-pages locf-dpn)
	  (swap-scan n-pages vpn swap-map-address swap-map-dpn-address swap-map-size)
	(if (plusp n)
	    (let ((dpn (location-contents locf-dpn))
		  (assigned-n-pages (min* n n-pages)))
	      (decf (location-contents locf-n-pages) assigned-n-pages)
	      (incf (location-contents locf-dpn) assigned-n-pages)
	      (decf* *count-remaining-swap-pages* assigned-n-pages)
	      (return (values dpn assigned-n-pages)))
	    ;; if we get here, hopefully some more paging space was added
	    ;; and the processor continued.  Go around the loop again and
	    ;; try to assign the space. 
	    (wired-ferror
	      :proceedable-halt
	      #+3600 "Out of paging space.  To continue, use the Add Paging-file command, and then Continue."
	      #+IMach "Out of paging space.  To continue, use the Add Paging File command, and then Continue."
	     )
	    (adjust-*count-swap-pages*))))))

(defwiredfun swap-deassign (dpn n-pages)
  (let ((null-count-addr nil)
	(null-dpn-addr nil))
    (labels ((deassign-merge (dpn n-pages count-addr dpn-addr size)
	       (declare (values dpn n-pages))
	       (prog ()
		  merge-again
		     (dotimes (i size)
		       (cond ((minusp (%p-contents-offset count-addr i))
			      ;; Link to another table
			      (multiple-value-bind (x-dpn x-n-pages)
				  (deassign-merge
				    dpn n-pages
				    (%p-contents-as-locative-offset count-addr i)
				    (%p-contents-as-locative-offset dpn-addr i)
				    %swap-map-extension-size)
				(when (or ( dpn x-dpn) ( n-pages x-n-pages))
				  (setq dpn x-dpn n-pages x-n-pages)
				  (go merge-again))))
			     ((zerop (%p-contents-offset count-addr i))
			      (unless null-count-addr
				(setq null-count-addr (%p-structure-offset count-addr i)
				      null-dpn-addr (%p-structure-offset dpn-addr i))))
			     ((= dpn (+ (%p-contents-offset dpn-addr i)
					(%p-contents-offset count-addr i)))
			      ;; Merge dpn range into end of existing entry
			      (setq dpn (%p-contents-offset dpn-addr i)
				    n-pages (+ n-pages (%p-contents-offset count-addr i)))
			      (setf (%p-contents-offset count-addr i) 0)
			      (go merge-again))
			     ((= (+ dpn n-pages) (%p-contents-offset dpn-addr i))
			      ;; Merge dpn range into beginning of existing entry
			      (setq n-pages (+ n-pages (%p-contents-offset count-addr i)))
			      (setf (%p-contents-offset count-addr i) 0)
			      (go merge-again)))))
	       (values dpn n-pages)))
      (multiple-value-bind (dpn n-pages)
	  (deassign-merge dpn n-pages
			  swap-map-address swap-map-dpn-address swap-map-size)
	;; Put DPN range into either a found or created null entry, or create a new entry
	;; Couldn't merge the dpn range into any existing entry.
	(cond (null-count-addr
	       ;; Found or made a null entry.  Stick the range in there.
	       (%p-store-contents null-dpn-addr dpn)
	       (%p-store-contents null-count-addr n-pages))
	      (t
	       ;; Tables full.  Make a new extension.
	       (let ((count-addr (create-dynamic-space %swap-map-extension-size))
		     (dpn-addr (create-dynamic-space %swap-map-extension-size)))
		 ;; Clear the new table
		 (%block-store-cdr-and-contents count-addr %swap-map-extension-size 0 0 0)
		 (%block-store-cdr-and-contents dpn-addr %swap-map-extension-size 0 0 0)
		 ;; Copy the first entry into the new extension
		 (%p-store-contents count-addr (%p-contents-offset swap-map-address 0))
		 (%p-store-contents dpn-addr (%p-contents-offset swap-map-dpn-address 0))
		 ;; Update the top table to point to the new extension
		 (%p-store-contents swap-map-address
				    (%logdpb 1 (byte 01 37) (%pointer count-addr)))
		 (%p-store-contents swap-map-dpn-address
				    (%logdpb 1 (byte 01 37) (%pointer dpn-addr)))
		 ;; And finally, store the new entry
		 (%p-store-contents-offset dpn dpn-addr 1)
		 (%p-store-contents-offset n-pages count-addr 1)))))
      ;; This n-pages is outside the multiple-value-bind, which is important!
      (incf* *count-remaining-swap-pages* n-pages))))

;;; Advertised function to add a paging file
(defun add-paging-file (file prepend-p)
  (with-open-file (f (fs:merge-pathnames file "FEP:>.page")
		     :direction :block
		     :if-exists :overwrite
		     :if-does-not-exist :error
		     :if-locked :error)
    (let ((data-map (send f :create-data-map)))
      ;; tell the fepfs host we're using it
      #+Imach (unless (send (send (send f :pathname) :host) ':mark-fepfs-host-in-use :paging t)
		(return-from add-paging-file nil))
      (si:with-wired-structure data-map
	(%funcall-in-aux-stack #'aux-add-paging-file-data-map data-map prepend-p))
      (si:gc-daemon-requeue)
      t)))

;;; Internal workhorse, must be called on aux stack.
(defwiredfun aux-add-paging-file-data-map (data-map prepend-p)
  (let ((old-remaining *count-remaining-swap-pages*))
    ;; If the swap map is too small, they'll get prepended anyways; but if
    ;; that's what the user really wants, we move all the existing entries
    ;; to the end first -- to make sure
    (when prepend-p
      (loop repeat swap-map-size
	    for from downfrom (1- swap-map-size)
	    as count = (shiftf (%p-contents-offset swap-map-address from) 0)
	    with to = (1- swap-map-size) do
	(when (plusp count)
	  (setf (%p-contents-offset swap-map-address to) count
		(%p-contents-offset swap-map-dpn-address to)
		(%p-contents-offset swap-map-dpn-address from))
	  (decf to))))
    ;; On the 3600 there is probably wasted memory beyond the swap map
    ;; that we could use; but this is safe (if slow) for both machines
    (loop for dm-index below (fill-pointer data-map) by 2 do
      (swap-deassign (aref data-map (+ dm-index 1)) (aref data-map (+ dm-index 0))))
    ;; swap-deassign adjusts *count-remaining-swap-pages*, so use the difference to
    ;; increment *count-swap-pages*
    (incf *count-swap-pages* (- *count-remaining-swap-pages* old-remaining))))


;;;; Page transformations

;;; Add a newly resident vpn to the storage tables.
(defwiredfun setup-frame (mmpt-index vpn #+IMach pht-index)
  (with-quick-mmpt-accessors
    (verify-frame-status mmpt-index (%mmpt-status-preparing
				      %mmpt-status-writing	;flush-written
				      ) nil nil)
    (let ((entry (mmpt-entry mmpt-index))
	  (write-protect
	    (let ((region (%region-number (deposit-vpn vpn 0))))
	      (if (not (null region))
		  (ldb %%region-read-only (region-bits region))
		0))))
      (when ( (mmpt-entry-status entry) %mmpt-status-writing)
	;; If already busy don't bump counter 
	(incf *count-busy-pages*))
      #+3600 (setf (mmpt-entry mmpt-index)
		   (%logdpbs vpn %%mmpt-vpn
			     0 %%mmpt-invalid-vpn	;entry is now valid
			     %mmpt-status-reading %%mmpt-status
			     write-protect %%mmpt-write-protect
			     entry))
      #+IMach (setf (mmpt-entry mmpt-index)
		   (%logdpbs vpn %%mmpt-vpn
			     0 %%mmpt-invalid-vpn	;entry is now valid
			     %mmpt-status-reading %%mmpt-status
			     entry))
      #+IMach (setf (pht-write-protect pht-index) write-protect)))
  nil)

;;; Prepare a page frame to contain a page.  If it currently contains a modified page,
;;; it must be written out before the page can actually be setup.  While the flush-
;;; write is in progress, the PHT must contain an entry for the new vpn marked as pending
;;; so that any subsequent faults will be able to wait for the page to be fetched.
;;; The new VPN is associated with the frame being flushed by being stored in a pending
;;; queue.
;;; NOTE: If you intend to immediately change the status of the frame, such as with
;;; normalize-frame or wire-frame, you must follow the call to prepare-frame with
;;; wait-until-frame-prepared in case this causes a flush write.
(defwiredfun prepare-frame (mmpt-index vpn)
  "Must be called on the auxiliary stack.  Prepare a frame to contain a page.
   Must be followed by a call to WAIT-UNTIL-FRAME-PREPARED if the status is
   going to be changed without waiting for any disk operation to finish."
  (with-quick-pht-and-mmpt-accessors
    (let* ((mmpt-entry (mmpt-entry mmpt-index))
	   (original-status (mmpt-entry-status mmpt-entry))
	   (original-vpn (mmpt-entry-vpn mmpt-entry))
	   (original-vpn-valid-p (zerop (mmpt-entry-invalid-vpn mmpt-entry)))
#+3600	   (original-modified-p (not (zerop (mmpt-entry-modified mmpt-entry))))
#+IMach	   (original-pht-index (and original-vpn-valid-p (pht-lookup original-vpn)))
#+IMach     (original-modified-p
	     (and original-vpn-valid-p ( (pht-modified original-pht-index) 0)))
	   (original-write-locked-p ( (mmpt-write-lock mmpt-index) 0))
	   (ppn (mmpt-index-to-ppn mmpt-index)))
      (update-status-counters original-status)
      (verify-frame-status mmpt-index
			   (%mmpt-status-flushable
			     %mmpt-status-prefetched
			     %mmpt-status-prefetched-mark)
			   nil
			   ;; flushable-pages can (optionally) be write-locked
			   )
      ;; Set status so page cannot be reused by any subroutines we call that allocate memory
      (setf (mmpt-status mmpt-index) %mmpt-status-preparing)
      (when (and original-vpn-valid-p
		 ( original-vpn vpn)
		 (or (= %mmpt-status-prefetched original-status)
		     (= %mmpt-status-prefetched-mark original-status)))
	(incf* *count-discarded-prefetched-pages*))
      (cond ((and original-vpn-valid-p
		  ( original-vpn vpn)
		  (or original-modified-p original-write-locked-p))
	     ;; Note that on IMach, it is plausible that an interrupt
	     ;; service routine (run by disk-wait) will try to touch the
	     ;; page we are preparing!  If we want any reference to
	     ;; fault, we have to not only get it out of the cache, we
	     ;; have to turn on fault request!  [Currently,
	     ;; decode-fault-request will barf if this page is faulted
	     ;; on -- I left that there to confirm my theory that this
	     ;; can actually happen.]  It will be the case that later we
	     ;; will either set the status to writing or remove the
	     ;; entry altogether.
	     #+3600 (setf (pht-fault-request (pht-lookup (mmpt-vpn mmpt-index))) 1)
	     #+IMach (setf (pht-fault-request original-pht-index) 1)
	     (cache-remove (deposit-vpn original-vpn 0))	;any reference will fault now
	     ;; If it is modified, we will have to queue a write.  Don't
	     ;; let a disk-wait in pending-put or
	     ;; disk-enqueue-page-write (re-) queue a background write
	     ;; on this frame instead!
	     (when original-modified-p
	       #+3600 (setf (mmpt-modified mmpt-index) 0)
	       #+IMach (setf (pht-modified original-pht-index) 0))
	     (let ((dpn (swap-write-lookup original-vpn)))	;possible overlap w/ disk
	       (when original-write-locked-p
		 ;; A background write is in progress.
		 ;; If can't delete it, then it has already been promoted to the
		 ;; foreground.  If the modified flag is still clear in the MMPT,
		 ;; no problem, by changing the page's status to flushing below,
		 ;; the background write complete will call flush-write-complete.
		 ;; However, if the page has been modified since the background
		 ;; write was enqueued, have to wait for the promoted background
		 ;; write to finish.  Otherwise, the background write will
		 ;; notice the flushing status upon completion, and reset the
		 ;; status before the real flush write has time to come along.
		 ;; Note that this hang should't hurt much more than a disk rotation.
		 (cond ((disk-background-delete ppn)
			;; Background write not promoted yet.  Don't
			;; Just cancel it.  Promote it by making it look
			;; like original-modified-p.  Leave it
			;; unmodified so you don't risk background
			;; re-queue, but be honest about the locking
			(setf (mmpt-write-lock mmpt-index) 0)
			(decf *count-locked-pages*)
			(setf original-modified-p t))
		       (original-modified-p
			;; Already promoted but page was modified while the
			;; write was in progress.  Have to wait for the write
			;; to complete before setting the flushing flag.
			(wait-until-frame-unlocked mmpt-index nil))))
	       (let ((pht-index (pht-put vpn ppn)))
		 ;; That pht-put might cause a pht rehash...
		 #+IMach (setq original-pht-index (pht-lookup (mmpt-vpn mmpt-index)))
		 ;; Now, either original-modified-p or
		 ;; original-write-locked-p got us here, if we deleted
		 ;; the background write we pretend original-modified-p,
		 ;; since it is no longer queued to write.  There used
		 ;; to be a when here to re-verify the conditions that
		 ;; took us down this path, but I believe it is
		 ;; superfluous (and in error) --ptw 4/91
		 (progn
		   ;; Either have to write out a modified page (modified
		   ;; set, or background write deleted) or else a
		   ;; promoted background write is in progress and
		   ;; modified is still clear.  In either case, just set
		   ;; pending and flushing.
		   (pending-put mmpt-index vpn)	; Create ...
		   ;; That pending put might cause a write-complete!
		   ;; Only go through with the pending strategy if a) we
		   ;; have to force a write, or b) the write-complete is
		   ;; still to come.  [Perhaps should wait for pending
		   ;; space first and then verify, rather than doing
		   ;; put/remove.]
		   (if (or original-modified-p
			   ( (mmpt-write-lock mmpt-index) 0))
		       (progn
			 (setf (pht-pending pht-index) 1)	; ... and set pht-pending
			 ;; Replacement algorithm requires reference
			 ;; bits clear when fault-request=1
			 #+IMach (setf (pht-reference-bits original-pht-index) 0)
			 (incf *count-busy-pages*)
			 ;; change status to flush-writing
			 (setf (mmpt-entry mmpt-index)
			       (%logdpbs 1 %%mmpt-flushing
					 %mmpt-status-writing %%mmpt-status
					 (mmpt-entry mmpt-index)))
			 ;; if it's modified, we need to queue our own write
			 (when original-modified-p
			   ;; Modified is already cleared above, but
			   ;; re-assert write-locked since we are
			   ;; writing the page
			   (setf (mmpt-write-lock mmpt-index) 1)
			   (incf *count-locked-pages*)
			   (incf* *count-forced-modified-page-writes*)
			   (disk-enqueue-page-write %class-write dpn ppn)
			   ;; only need to gc-page-out if it has been
			   ;; newly modified (a cancelled background
			   ;; write will have already done the
			   ;; gc-page-out, but be safe)
			   (gc-page-out original-vpn ppn t #-3600 original-pht-index)
			   (when *page-trace-array*
			     (page-trace-insert %class-write (deposit-vpn original-vpn 0))))
			 (values pht-index))
		       ;; we got screwed (or won, depending on how you
		       ;; look at it!)-- the write completed when we did
		       ;; the pending-put, so back that out and take the
		       ;; unmodified path
		       (progn
			 (pending-remove mmpt-index)
			 ;; already removed from cache above
			 (pht-remove original-vpn)
			 (when *page-trace-array*
			   (page-trace-insert
			     %page-trace-replace (deposit-vpn original-vpn 0)))
			 (setup-frame mmpt-index vpn #+IMach pht-index)
			 (values pht-index)))
		   ))))
	    ((or (not original-vpn-valid-p) ( original-vpn vpn))
	     ;; The frame is invalid, or else a different unmodified vpn.
	     (when original-vpn-valid-p
	       (let ((vma (deposit-vpn original-vpn 0)))
		 ;; Remove entry for old page
		 (cache-remove vma)
		 (pht-remove original-vpn)
		 (when *page-trace-array*
		   (page-trace-insert %page-trace-replace vma))))
	     (let ((pht-index (pht-put vpn ppn)))
	       (setup-frame mmpt-index vpn #+IMach pht-index)
	       (values pht-index)))
	    (t (wired-ferror :fatal
			     "Trying to prepare a frame with mysterious status.  Frame: ~O"
			     mmpt-index))))))

;;; Must be called on the auxiliary stack.  Transform a page into a normal page.
(defwiredfun normalize-frame (mmpt-index pht-index)
  (with-quick-pht-and-mmpt-accessors
    (let ((mmpt-entry (mmpt-entry mmpt-index)))
      (update-status-counters (mmpt-entry-status mmpt-entry))
      (setf (mmpt-entry mmpt-index)
	    (dpb %mmpt-status-normal
		 %%mmpt-status
		 #+3600 (dpb *normal-page-age* %%mmpt-age mmpt-entry)
		 #+IMach mmpt-entry))
      (incf *count-normal-pages*))
    (setf (pht-fault-request pht-index) 0)
    ;; Tell the replacement algorithms that this page was just referenced.
    #+3600 (progn
	     (%reference-tag-write (deposit-ppn (pht-ppn pht-index) 0) t)
	     (cache-put mmpt-index))
    ;; On I-machines it's faster to let the hardware load the map cache on demand.
    #+IMach (setf (pht-reference-bits pht-index) 0))
  nil)

;;; Must be called on the auxiliary stack.  Transform a page into a %mmpt-status-flushable
;;; page and insert it at the beginning or end of the flushable queue.
;;; +++ When asked to head-enqueue a frame that's already somewhere in the flushable
;;; queue, we should try to move it up somehow
(defwiredfun flush-frame (mmpt-index pht-index &optional head-enqueue-p)
  (with-quick-pht-and-mmpt-accessors
    (let* ((mmpt-entry (mmpt-entry mmpt-index))
	   (mmpt-status (mmpt-entry-status mmpt-entry)))
      (unless (bit-member mmpt-status *flushable-status*)
	(setf (pht-fault-request pht-index) 1)	; So a reference will be seen
	;; Replacement algorithm requires reference bits be clear when fault-request=1.
	#+IMach (setf (pht-reference-bits pht-index) 0)
	(cache-remove (deposit-vpn (mmpt-entry-vpn mmpt-entry) 0))
	(flushable-enqueue mmpt-index head-enqueue-p)
	(update-status-counters mmpt-status)
	(setf (mmpt-entry mmpt-index) (dpb %mmpt-status-flushable %%mmpt-status mmpt-entry))
	(incf *count-flushable-pages*)
	(when (progn #+3600 ( (mmpt-entry-modified mmpt-entry) 0)
		     #+IMach ( (pht-modified pht-index) 0))
	  (incf* *count-flushed-modified-pages*))
	(incf* *count-flushed-pages*)))
    (when *page-trace-array*
      (with-page-trace-record
	(page-trace-insert %page-trace-flush-frame (deposit-vpn (mmpt-vpn mmpt-index) 0))))))

;;; Must be called on the auxiliary stack.  Write out a page without changing its mmpt-status.
(defwiredfun write-frame (mmpt-index #+IMach pht-index)
  ;; Can't let the frame magically be reused while the write is in progress.  Can't just set
  ;; the state to writing since it would be nice to preserve the original state, be it
  ;; flushable, prefetched, prefetched-mark, etc.  Also, the lock bit does not inhibit use of
  ;; the page, just reuse of the frame, so references to the page can still work without
  ;; waiting.
  (with-quick-mmpt-accessors
    (let ((mmpt-entry (mmpt-entry mmpt-index)))
      (when (= (mmpt-entry-write-lock mmpt-entry) 0)
	(let ((vpn (mmpt-entry-vpn mmpt-entry))
	      (ppn (mmpt-index-to-ppn mmpt-index)))
	  (cache-remove (deposit-vpn vpn 0))
	  (setf (mmpt-entry mmpt-index)
		(dpb 1 %%mmpt-write-lock
		     #+3600 (dpb 0 %%mmpt-modified mmpt-entry)
		     #+IMach mmpt-entry))
	  #+IMach (setf (pht-modified pht-index) 0)
	  (incf *count-locked-pages*)
	  (disk-enqueue-page-write %class-write (swap-write-lookup vpn) ppn)
	  ;; While the page is being written out, update its ESRT entry. If this needs
	  ;; a main memory page to expand the ESRT, if all else fails it will flush this
	  ;; very frame then hang in prepare-frame or create-page-in-frame waiting for
	  ;; the disk to finish writing out the page.
	  (gc-page-out vpn ppn t #-3600 pht-index)
	  (when *page-trace-array*
	    (page-trace-insert %page-trace-write (deposit-vpn vpn 0))))))))

;;; Must be called on the auxiliary stack.  Set the page frame's status to wired.
(defwiredfun wire-frame (mmpt-index pht-index)
  (with-quick-mmpt-accessors
    (let ((original-status (mmpt-status mmpt-index)))
      (incf* *wire/unwire-tick*)
      #+IMach
      (incf* (aref *zone-count-wired-pages* (ldb %%vpn-zone-num (mmpt-vpn mmpt-index))))
      (if (= original-status %mmpt-status-wired)
	  ;; Page is already wired.  Just increment lock count.
	  (setf (mmpt-wired-count mmpt-index)
		(min* (1+ (mmpt-wired-count mmpt-index)) %maximum-wired-count))
	(when (bit-member original-status *flushable-status*)
	  (normalize-frame mmpt-index pht-index))
	(update-status-counters (mmpt-status mmpt-index))
	(incf* *count-wired-pages*)
	(setf (mmpt-status mmpt-index) %mmpt-status-wired)
	(setf (mmpt-wired-count mmpt-index) 1)))))

;;; Must be called on the auxiliary stack.  Unwire a page frame.
(defwiredfun unwire-frame (mmpt-index pht-index)
  (with-quick-mmpt-accessors
    (when (= (mmpt-status mmpt-index) %mmpt-status-wired)
      (incf* *wire/unwire-tick*)
      #+IMach
      (decf* (aref *zone-count-wired-pages* (ldb %%vpn-zone-num (mmpt-vpn mmpt-index))))
      (let ((count (mmpt-wired-count mmpt-index)))
	(when (< count %maximum-wired-count)
	  (setf (mmpt-wired-count mmpt-index) (1- count))
	  (when (= count 1)
	    (normalize-frame mmpt-index pht-index)))))))

;;; Must be called on the auxiliary stack.  If MAKE-UNUSABLE-P is true, removes the
;;; frame from the system, setting its status to %mmpt-status-frame-error.  Otherwise
;;; the page occupying the frame is just thrown out.  If IGNORE-MODIFIED-P is true
;;; and the resident page has been modified, it is not written out to swap memory.
(defwiredfun remove-frame (mmpt-index #+IMach pht-index &optional make-unusable-p ignore-modified-p)
  (with-quick-mmpt-accessors
    (let* ((mmpt-entry (mmpt-entry mmpt-index))
	   (mmpt-status (mmpt-entry-status mmpt-entry))
	   (mmpt-vpn (mmpt-entry-vpn mmpt-entry)))
      (cond (( (mmpt-entry-invalid-vpn mmpt-entry) 0)
	     (when (and make-unusable-p ( mmpt-status %mmpt-status-frame-error))
	       (update-status-counters mmpt-status)
	       (setf (mmpt-entry mmpt-index)
		     (dpbs 1 %%mmpt-invalid-vpn
			   %mmpt-status-frame-error %%mmpt-status
			   mmpt-entry))
	       (decf *count-usable-pages*)))
	    ((bit-member mmpt-status *normalizable-status*)
	     (when (or (= mmpt-status %mmpt-status-prefetched)
		       (= mmpt-status %mmpt-status-prefetched-mark))
	       (incf* *count-discarded-prefetched-pages*))
	     (update-status-counters mmpt-status)
	     ;; Set status so page cannot be reused by WRITE-FRAME or GC-PAGE-OUT
	     ;; to grow SMPT or ESRT.  Keep mmpt-entry consistent, too.
	     (setf (mmpt-entry-status mmpt-entry) %mmpt-status-preparing)
	     (setf (mmpt-entry mmpt-index) mmpt-entry)
	     ;; Note that on IMach, it is plausible that an interrupt
	     ;; service routine (run by disk-wait) will try to touch the
	     ;; page we are removing!  If we want any reference to
	     ;; fault, we have to not only get it out of the cache, we
	     ;; have to turn on fault request!  [Currently,
	     ;; decode-fault-request will barf if this page is faulted
	     ;; on -- I left that there to confirm my theory that this
	     ;; can actually happen.]  It will be the case that later we
	     ;; will either set the status to writing or remove the
	     ;; entry altogether.
	     #+IMach (progn
		       (setf (pht-fault-request pht-index) 1))
	     (cache-remove (deposit-vpn mmpt-vpn 0))	;Any reference will fault now
	     ;; If there's a background write in progress, try to abort it so we can turn
	     ;; it into a demand write.  Otherwise wait for it to complete.  Note that
	     ;; the frame may have been modified since the write was enqueued.
	     (when ( (mmpt-entry-write-lock mmpt-entry) 0)
	       ;; Background write in progress.  Delete it if not promoted, else wait.
	       (if (not (disk-background-delete (mmpt-index-to-ppn mmpt-index)))
		   ;; Already promoted.  Have to wait for the write to complete
		   ;; before smashing the state of the page.
		   (wait-until-frame-unlocked mmpt-index nil)
		 ;; Background write not promoted yet.  Just cancel it.
		 (setf (mmpt-entry-write-lock mmpt-entry) 0)
		 #+3600 (setf (mmpt-entry-modified mmpt-entry) 1)
		 #+IMach (setf (pht-modified pht-index) 1)
		 ;; Update mmpt entry in memory before changing global counter.
		 (setf (mmpt-entry mmpt-index) mmpt-entry)
		 (decf *count-locked-pages*)))
	     ;; No background writes in progress now.  If the frame is still modified,
	     ;; write it out (calling GC-PAGE-OUT), and wait for the write to complete.
	     (when (progn
		     #+3600 ( (mmpt-entry-modified mmpt-entry) 0)
		     #+IMach ( (pht-modified pht-index) 0))
	       (if ignore-modified-p
		   #+3600 (%gc-tag-write (deposit-ppn (mmpt-index-to-ppn mmpt-index) 0) nil)
		   #+IMach nil
		 (incf* *count-forced-modified-page-writes*)
		 (write-frame mmpt-index #+IMach pht-index)
		 (wait-until-frame-unlocked mmpt-index nil)))
	     (pht-remove mmpt-vpn)
	     (cond ((not make-unusable-p)
		    (setf (mmpt-entry mmpt-index)
			  (dpbs 1 %%mmpt-invalid-vpn
				%mmpt-status-flushable %%mmpt-status
				#+3600 (dpb 0 %%mmpt-age (mmpt-entry mmpt-index))
				#+IMach (mmpt-entry mmpt-index)))
		    (incf *count-flushable-pages*)
		    ;; We don't need to enqueue this frame unless it used to be normal.
		    (when (= mmpt-status %mmpt-status-normal)
		      ;; Enqueue it at the head of the queue, since it's worthless.
		      (flushable-enqueue mmpt-index t)))
		   (t
		    (setf (mmpt-entry mmpt-index)
			  (dpbs 1 %%mmpt-invalid-vpn
				%mmpt-status-frame-error %%mmpt-status
				(mmpt-entry mmpt-index)))
		    (decf *count-usable-pages*))))
	    ((or (= mmpt-status %mmpt-status-reading)
		 (= mmpt-status %mmpt-status-writing))
	     ;; Wait for the transfer to finish, and then try again.
	     (wait-for-page-idle mmpt-vpn (pht-lookup mmpt-vpn))
	     (remove-frame mmpt-index #+IMach pht-index make-unusable-p ignore-modified-p))
	    ((or (= mmpt-status %mmpt-status-wired)
		 (= mmpt-status %mmpt-status-data-error))
	     nil)				;Just ignore these pages
	    (t
	     (wired-ferror :fatal "REMOVE-FRAME can't deal with MMPT status ~O" mmpt-status))))))

(defwiredfun remove-pages (from-vpn n-pages &optional ignore-modified-p)
  (enter-storage-system *ms-time-user-flush-pages*
    (loop repeat n-pages for vpn upfrom from-vpn do
      (let ((pht-index (pht-lookup vpn)))
	(when (not (null pht-index))
	  (let ((mmpt-index (mmpt-lookup (pht-ppn pht-index))))
	    (remove-frame mmpt-index #+IMach pht-index nil ignore-modified-p)))))))

(defwiredfun remove-all-pages ()
  (enter-storage-system *ms-time-user-flush-pages*
    (loop for y below #+3600 %mmpt-y-size #+IMach (length *mmpt-y*) do
      (when ( (mmpt-y-valid y) 0)
	(loop repeat %mmpt-x-size for ppn from (* y %mmpt-x-size) do
	  (remove-page-internal ppn))))))

(defwiredfun remove-page-internal (ppn &optional make-unusable-p ignore-modified-p)
  (let ((mmpt-index (mmpt-lookup ppn)))
    (when (not (null mmpt-index))
      #+3600
      (remove-frame mmpt-index make-unusable-p ignore-modified-p)
      #+IMach
      (let ((vpn (mmpt-vpn mmpt-index)))
	(when ( (ldb %%vpn-equals-ppn vpn) %vma-equals-pma)
	  (remove-frame mmpt-index (pht-lookup vpn) make-unusable-p ignore-modified-p))))))

;;; Create a virtual page in a physical page frame.  This is used by the initialization
;;; code to include preloaded pages, and by CONS (via CREATE-PAGES) when creating new pages.
(defwiredfun create-page-in-frame (mmpt-index vpn)
  (let ((pht-index (prepare-frame mmpt-index vpn)))
    ;; If flush-writing, the VPN will be pending.  Must wait for the flush-write to
    ;; complete before trying to normalize the frame.
    (wait-until-frame-prepared pht-index)
    ;; Mark page as modified, so that write-protect does not get set in the map cache.
    ;; This is for three reasons:
    ;; (1) If write-protect is set on the wired pages, we will get into a page fault loop
    ;; (2) If called from initialize-storage, this stuff has never been written to disk
    ;; (3) If called from cons or create-dynamic-space, we're about to modify it anyway
    #+3600 (setf (mmpt-modified mmpt-index) 1)
    #+IMach (setf (pht-modified pht-index) 1)
    (normalize-frame mmpt-index pht-index)
    (when *storage-debug*
      (wire-frame mmpt-index pht-index))))

(defwiredfun update-status-counters (status)
  (select status
    (%mmpt-status-normal
     (decf *count-normal-pages*))
    (%mmpt-status-flushable
     (decf *count-flushable-pages*))
    ((%mmpt-status-prefetched %mmpt-status-prefetched-mark)
     (decf *count-flushable-pages*))
    ((%mmpt-status-reading %mmpt-status-writing)
     (decf *count-busy-pages*))
    (%mmpt-status-wired
     (decf *count-wired-pages*))
    (otherwise
     (wired-ferror :fatal "Invalidly transforming a ~O page" status))))

;; Debug support
#+Debug
(defwiredfun invalid-frame-status (index)
  (wired-ferror :proceedable-halt
		"Unexpected status for frame ~O (VMA ~O)
  Status: ~O, Flushing: ~O, Write-lock: ~O, Pending: ~O"
		index (deposit-vpn (mmpt-vpn index) 0)
		(mmpt-status index) (mmpt-flushing index) (mmpt-write-lock index)
		(when (not (zerop (mmpt-flushing index)))
		  (deposit-vpn (pending-get index) 0))
		))

;; This macro can be redefined to expand to nothing when we believe the
;; patch works
(defmacro verify-frame-status (index status &optional (flushing nil f-p) (locked nil l-p))
  #+Debug
  (progn
    (unless (consp status) (setq status (list status)))
    `(macrolet ((boole-eq (a b) `(eq (not ,a) (not ,b))))
       (let* ((entry (mmpt-entry ,index))
	      (status (mmpt-entry-status entry)))
	 (unless (and (member status (list ,@status))
		      ,@(when l-p
			  `((boole-eq ,locked (plusp (mmpt-entry-write-lock entry)))))
		      ,@(when f-p
			  `((boole-eq ,flushing (plusp (mmpt-entry-flushing entry))))))
	   (invalid-frame-status ,index))))))


;;;; Disk completion routines

(defwiredfun wakeup-page-waiter (vpn)
  (let ((vpns *page-waiter-vpn*))
    (declare (sys:array-register vpns))
    (dotimes (index %n-page-waiters)
      (when (store-conditional (locf (aref vpns index)) vpn t)
	(si:aux-process-wakeup (aref *page-waiter-process* index))))))  

;;; Mark the page as normal
(defwiredfun fetch-complete (ppn)
  (with-quick-mmpt-accessors
    (let* ((mmpt-index (mmpt-lookup ppn))
	   (vpn (mmpt-vpn mmpt-index))
	   (pht-index (pht-lookup vpn)))
      (verify-frame-status mmpt-index %mmpt-status-reading nil nil)
      ;; Insure a write-first fault, so the sysout bit gets updated.
      (when (and *sysout-enabled-p* (not (sysout-bitmap vpn)))
	#+3600 (setf (mmpt-write-protect mmpt-index) 1)
	#+IMach (setf (pht-write-protect pht-index) 1))
      (normalize-frame mmpt-index pht-index)
      (wakeup-page-waiter vpn))))

(defwiredfun fetch-load-complete (ppn)
  (with-quick-mmpt-accessors
    (let* ((mmpt-index (mmpt-lookup ppn))
	   (vpn (mmpt-vpn mmpt-index))
	   (pht-index (pht-lookup vpn)))
      (verify-frame-status mmpt-index %mmpt-status-reading nil nil)
      ;; Insure a write-first fault, so the sysout bit gets updated.
      (when *sysout-enabled-p*
	#+3600 (setf (mmpt-write-protect mmpt-index) 1)
	#+IMach (setf (pht-write-protect pht-index) 1))
      (when *load-pages-to-swap-area-p*		;Make it be written to swap area
	(setf (load-bitmap vpn) nil)
	#+3600 (setf (mmpt-modified mmpt-index) 1)
	#+IMach (setf (pht-modified pht-index) 1))
      (normalize-frame mmpt-index pht-index)
      (wakeup-page-waiter vpn))))

;;; Mark the page as prefetched
(defwiredfun prefetch-complete (ppn)
  (with-quick-mmpt-accessors
    (let* ((mmpt-index (mmpt-lookup ppn))
	   (entry (mmpt-entry mmpt-index))
	   (vpn (mmpt-entry-vpn entry)))
      (verify-frame-status mmpt-index %mmpt-status-reading nil nil)
      ;; Insure a write-first fault, so the sysout bit gets updated.
      (when (and *sysout-enabled-p* (not (sysout-bitmap vpn)))
	#+3600 (setf (mmpt-entry-write-protect entry) 1)
	#+IMach (setf (pht-write-protect (pht-lookup vpn)) 1))
      (setf (mmpt-entry mmpt-index) (dpb %mmpt-status-prefetched %%mmpt-status entry))
      (flushable-enqueue mmpt-index nil)
      (decf *count-busy-pages*)
      (incf *count-flushable-pages*))))

(defwiredfun prefetch-load-complete (ppn)
  (with-quick-mmpt-accessors
    (let* ((mmpt-index (mmpt-lookup ppn))
	   (entry (mmpt-entry mmpt-index))
	   (vpn (mmpt-entry-vpn entry)))
      (verify-frame-status mmpt-index %mmpt-status-reading nil nil)
      ;; Insure a write-first fault, so the sysout bit gets updated.
      (when *sysout-enabled-p*
	#+3600 (setf (mmpt-entry-write-protect entry) 1)
	#+IMach (setf (pht-write-protect (pht-lookup vpn)) 1))
      (when *load-pages-to-swap-area-p*		;Make it be written to swap area
	(setf (load-bitmap vpn) nil)
	#+3600 (setf (mmpt-entry-modified entry) 1)
	#+IMach (setf (pht-modified (pht-lookup vpn)) 1))
      (setf (mmpt-entry mmpt-index) (dpb %mmpt-status-prefetched %%mmpt-status entry))
      (flushable-enqueue mmpt-index nil)
      (decf *count-busy-pages*)
      (incf *count-flushable-pages*))))

;;; Mark the page as prefetched-mark
(defwiredfun prefetch-mark-complete (ppn)
  (with-quick-mmpt-accessors
    (let* ((mmpt-index (mmpt-lookup ppn))
	   (entry (mmpt-entry mmpt-index))
	   (vpn (mmpt-entry-vpn entry)))
      (verify-frame-status mmpt-index %mmpt-status-reading nil nil)
      ;; Insure a write-first fault, so the sysout bit gets updated.
      (when (and *sysout-enabled-p* (not (sysout-bitmap vpn)))
	#+3600 (setf (mmpt-entry-write-protect entry) 1)
	#+IMach (setf (pht-write-protect (pht-lookup vpn)) 1))
      (setf (mmpt-entry mmpt-index) (dpb %mmpt-status-prefetched-mark %%mmpt-status entry))
      (flushable-enqueue mmpt-index nil)
      (decf *count-busy-pages*)
      (incf *count-flushable-pages*))))

;;; Hybrid of prefetch-load and prefetch-mark
(defwiredfun prefetch-load-mark-complete (ppn)
  (with-quick-mmpt-accessors
    (let* ((mmpt-index (mmpt-lookup ppn))
	   (entry (mmpt-entry mmpt-index))
	   (vpn (mmpt-entry-vpn entry)))
      (verify-frame-status mmpt-index %mmpt-status-reading nil nil)
      ;; Insure a write-first fault, so the sysout bit gets updated.
      (when *sysout-enabled-p*
	#+3600 (setf (mmpt-entry-write-protect entry) 1)
	#+IMach (setf (pht-write-protect (pht-lookup vpn)) 1))
      (when *load-pages-to-swap-area-p*		;Make it be written to swap area
	(setf (load-bitmap vpn) nil)
	#+3600 (setf (mmpt-entry-modified entry) 1)
	#+IMach (setf (pht-modified (pht-lookup vpn)) 1))
      (setf (mmpt-entry mmpt-index) (dpb %mmpt-status-prefetched-mark %%mmpt-status entry))
      (flushable-enqueue mmpt-index nil)
      (decf *count-busy-pages*)
      (incf *count-flushable-pages*))))

;;; Transform the page (either flushable or writing) to reading the specified vpn.
(defwiredfun write-complete (ppn)
  (with-quick-mmpt-accessors
    (let* ((mmpt-index (mmpt-lookup ppn))
	   (entry (mmpt-entry mmpt-index))
	   (old-vpn (mmpt-entry-vpn entry)))
      (verify-frame-status mmpt-index (%mmpt-status-flushable	;background write
					%mmpt-status-normal	;write-frame
					%mmpt-status-writing	;flush-write
					%mmpt-status-wired	;write-all-modified
					%mmpt-status-preparing	;transition
					%mmpt-status-prefetched	;load-to-swap
					%mmpt-status-prefetched-mark	;ditto
					) (= status %mmpt-status-writing) t)
      (load-bitmap old-vpn
	(setf (aref map index) nil))
      (when ( (mmpt-entry-write-lock entry) 0)
	(setf (mmpt-entry-write-lock entry) 0)	; unlock
	(setf (mmpt-entry mmpt-index) entry)	; update mmpt
	(decf *count-locked-pages*))
      (when ( (mmpt-entry-flushing entry) 0)
	(setf (mmpt-entry-flushing entry) 0)	; Mark flush-write complete
	(setf (mmpt-entry mmpt-index) entry)	; update mmpt
	;; Remove previous vpn from system tables.  Must remain up to now in case
	;; the vpn is referred to while the write is in progress.
	;; Cache entry already removed
	(pht-remove old-vpn)
	(let* ((vpn (pending-get mmpt-index))
	       (pht-index (pht-lookup vpn)))
	  (pending-remove mmpt-index)
	  (with-quick-pht-accessors
	    (setf (pht-pending pht-index) 0))	; Make pending VPN the frame's VPN
	  (setup-frame mmpt-index vpn #+IMach pht-index))))))


;;;; Flushable page management

;;; Insert the specified frame at the beginning or end of the flushable queue.
(defwiredfun flushable-enqueue (mmpt-index head-enqueue-p)
  (with-quick-mmpt1-accessors
    ;; Make sure this frame isn't already in the queue before inserting it.
    (when (and (= (mmpt-thread mmpt-index) %flushable-queue-end)
	       ( *flushable-queue-tail* mmpt-index))
      ;; We don't change *flushable-queue-modified* here under any circumstances.  Obviously
      ;; if we're adding on to the tail of the queue the background can keep on scanning the
      ;; queue.  If we're inserting frames at the head of the queue, we might restart the
      ;; background scan from the head, but we assume that nobody's dumb enough to ask that
      ;; modified pages be enqueued at the head.
      (cond ((= *flushable-queue-head* %flushable-queue-end)
	     (setf *flushable-queue-head* mmpt-index)
	     (setf *flushable-queue-tail* mmpt-index))
	    ((not head-enqueue-p)
	     (setf (mmpt-thread *flushable-queue-tail*) mmpt-index)
	     (setf *flushable-queue-tail* mmpt-index))
	    (t
	     (setf (mmpt-thread mmpt-index) *flushable-queue-head*)
	     (setf *flushable-queue-head* mmpt-index))))))

;;; Find a usable page frame and return its MMPT index.
(defwiredfun find-frame (&optional (nframes-eventually-needed 1) require-frame-p)
  (with-quick-mmpt1-accessors
    (ms-time *ms-time-find-frame*
      (loop doing
	(when* (= *count-flushable-pages* 0)
	  (if ( *count-normal-pages* 0)
	      (flush-n-pages nframes-eventually-needed)
	    (if (not require-frame-p)
		(return nil)
	      (disk-background-promote-all)
	      (wait-for-disk-done)
	      (return
		(or (find-frame)
		    (wired-ferror :fatal "No available main memory frames"))))))
	(let ((mmpt-index *flushable-queue-head*))
	  (when* (= %flushable-queue-end mmpt-index)
	    (wired-ferror :fatal "Flushable queue empty but *COUNT-FLUSHABLE-PAGES* is ~O"
			  *count-flushable-pages*))
	  ;; If we ever pass the frame where the storage background modified scan is, make
	  ;; the scan start over from the head of the queue.
	  (when* (eq *flushable-queue-modified* mmpt-index)
	    (setq *flushable-queue-modified* nil))
	  ;; Pop this frame off the queue, and note that it isn't part of the queue anymore.
	  (let ((head (mmpt-thread mmpt-index)))
	    (setq *flushable-queue-head* head)
	    (setf (mmpt-thread mmpt-index) %flushable-queue-end)
	    ;; If the queue becomes empty as a result, we must update *flushable-queue-tail*
	    ;; accordingly, because of the special check in flushable-enqueue for the tail
	    ;; of the queue.
	    (when* (= head %flushable-queue-end) (setq *flushable-queue-tail* head)))
	  ;; If this frame is still flushable, return it.
	  (when (bit-member (mmpt-status mmpt-index) *flushable-status*)
	    (return mmpt-index)))))))

#+3600
;;; Run the replacement algorithm.  Currently a clock algorithm using a 1 bit
;;; reference tag per page set by hardware.  %SCAN-REFERENCE-TAGS will search
;;; the reference tags, clearing them as it goes, until a clear tag is found.
;;; If the found page's age field is zero it may be flushed, else the age
;;; field is decremented and the scan continued.
;;;+ May be improved by using pages with nonzero ages if no younger pages around?
(defwiredfun flush-n-pages (target-count)
  (let ((pages (min* (- target-count *count-flushable-pages*) *count-normal-pages*))
	(mmpt *mmpt*)
	(scan-ppn *mmpt-replaceable-ppn*)
	(base-ppn nil)
	(base-mmpt-index nil)
	(bound-ppn -1))				;force initial derivation
    (declare (sys:array-register mmpt))
    (when (> pages 0)
      (loop doing
	(when* ( scan-ppn bound-ppn)
	  (multiple-value-bind (mmpt-index ppn)
	      (loop for p first scan-ppn then (+ (dpb 0 %%ppn-mmpt-x p) %mmpt-x-size)
		    when (> p %ppn-max) do (return (values 0 (mmpt-index-to-ppn 0)))
		    for i = (mmpt-lookup p)
		    when (not (null i)) do (return (values i p)))
	    (setq scan-ppn ppn)
	    (setq base-ppn (dpb 0 %%ppn-mmpt-x ppn))
	    (setq base-mmpt-index (dpb 0 %%ppn-mmpt-x mmpt-index))
	    (setq bound-ppn (+ base-ppn %mmpt-x-size))))
	(let ((unreferenced-pma
		(%scan-reference-tags (deposit-ppn scan-ppn 0) (deposit-ppn bound-ppn 0))))
	  (if (null unreferenced-pma)
	      (setq scan-ppn bound-ppn)
	    (let* ((ppn (extract-ppn unreferenced-pma))
		   (mmpt-index (+ base-mmpt-index (- ppn base-ppn)))
		   (mmpt-entry (mmpt-entry mmpt-index mmpt)))
	      ;; Decrement age of unreferenced page, or flush it if it's at 0 already.
	      (when (eql (mmpt-entry-status mmpt-entry) %mmpt-status-normal)
		(let ((age (mmpt-entry-age mmpt-entry)))
		  (if (not (eql age 0))
		      (setf (mmpt-entry mmpt-index mmpt) (dpb (1- age) %%mmpt-age mmpt-entry))
		    (flush-frame mmpt-index (pht-lookup (mmpt-entry-vpn mmpt-entry)))
		    (when ( (decf pages) 0)
		      (setq *mmpt-replaceable-ppn* scan-ppn)
		      (return nil)))))
	      (setq scan-ppn (1+ ppn)))))))))

#+IMach
;;; Run the replacement algorithm.  Currently a clock algorithm implemented using two of the
;;; four reference bits in the PHT.  The hardware clears both bits whenever the corresponding
;;; page is referenced.  This algorithm scans through the PHT incrementing that two bit
;;; field, and if it finds the second bit turned on in a normal frame, it flushes it.
;;; Constraints: only Normal and Wired frames may have fault-request=0, and any frame
;;; with fault-request=1 must have reference-bits=0.
(defwiredfun flush-n-pages (target-count)
  (let ((pages (min* (- target-count *count-flushable-pages*) *count-normal-pages*))
	(steps 0))
    (when (> pages 0)
      (with-system-block-registers (1 2)
	(let ((pht-bound (%pointer-plus *pht-base* (*2 *pht-size*)))
	      (fault-request-mask (dpb 1 %%pht0-fault-request 0)))
	  (setf (%block-register 1) (%pointer-plus *pht-base* *flushable-scan-pht-index*))
	  (setf (%block-register 2) (%block-register 1))
	  (with-quick-pht-and-mmpt-accessors
	    (with-quick-mmpt-lookups
	      (loop named betsy do
		;; Note well: this loop is carefully coded to fit in the instruction
		;; cache, optimize memory traffic, sidestep hazards in the event a page
		;; is flushed, and preserve cdr codes so we don't accidently clobber a
		;; chain bit.
		(dotimes (ignore (/2 (%pointer-difference pht-bound (%block-register 1))))
		  (let ((pht0 (%block-read 1 :fixnum-only t :set-cdr-next nil)))
		    (when (not (logtest pht0 fault-request-mask)) (incf pht0))
		    (%block-write 2 pht0)
		    (let ((pht1 (%block-read 1 :fixnum-only t :set-cdr-next nil)))
		      ;; Postpone writing the PHT1 word for a couple cycles, to let
		      ;; various write buffers clear...
		      (when* (prog1 (logtest pht0 2)
				    (%block-write 2 pht1))
			(let ((pht-index
				(- (%pointer-difference (%block-register 1) *pht-base*) 2))
			      (mmpt-index (mmpt-lookup (pht1-ppn pht1))))
			  ;; A non-normal frame might have gotten its reference bits
			  ;; incremented, so we've got to clear them or they'll carry
			  ;; into the next field.
			  (setf (pht-reference-bits pht-index) 0)
			  (when (= (mmpt-status mmpt-index) %mmpt-status-normal)
			    ;; BAR-1 is caller saves
			    (si:saving-registers-for-effect (%register-bar-1)
			      (flush-frame mmpt-index pht-index))
			    (when ( (decf pages) 0)
			      (setq *flushable-scan-pht-index* (+ pht-index 2))
			      (incf* *count-replacement-algorithm-steps* steps)
			      (return-from betsy nil)))))))
		  (incf steps))
		(setf (%block-register 1) *pht-base*)
		(setf (%block-register 2) *pht-base*)))))))))


;;;; Background process management

;;; Until the real time scheduler is working, the background process
;;; should expect to be called as a simple process during a fault wait,
;;; and periodically by the scheduler.  Since it is called from fault
;;; wait it must be wired.
;;;
;;;+ Furthermore, until the wired-wait portion of the scheduler is working,
;;; the storage-background task should be a function which does a very small
;;; thing at a time since a call to it will be the body of a loop whose
;;; end test checks if the waited for page has arrived yet.
;;;
;;; Perform storage related background tasks.  Some examples are:
;;;  o	Run replacement policy to maintain at least *flushable-min* flushable pages.
;;;  o	Copy modified flushable pages back to sm.
;;; The paging system should continue to work, albeit less efficiently, if
;;; the background process isn't running, so only efficiency hacks should be
;;; added to this task list.
;;;
;;; The cond clauses should be ordered from high to low priority.
(defwiredfun storage-background-fun (&optional (disk-permit t))
  (with-storage-lock
    (if (< *count-flushable-pages* *flushable-min*)
	;; Flush 20 pages at a time until at least *flushable-min* pages exist.
	(flush-n-pages (+ *count-flushable-pages* 20))
      ;; Lowest-priority tasks.  Do all of them.
      (when (and disk-permit
		 (not *creating-dynamic-space*)
		 (disk-background-space-p))
	(storage-background-write-modified-pages *background-modified-write-quantum*)))
    nil))

(defwiredfun storage-background-write-modified-pages (quantum)
  ;; Write out modified flushable pages to the swap area.  If *flushable-queue-modified*
  ;; is nil, scan the flushable queue starting at the head, otherwise pick up where we
  ;; left off in the queue last time.
  ;; +++ should splice non-flushable frames out of the queue as we go
  (with-quick-mmpt-accessors
    (let ((mmpt-index (or *flushable-queue-modified* *flushable-queue-head*)))
      (loop repeat quantum until (= mmpt-index %flushable-queue-end) do
	(when (let ((mmpt-entry (mmpt-entry mmpt-index)))
		(and (= (mmpt-entry-invalid-vpn mmpt-entry) 0)
		     ;; If it's already being written, investigate no further.
		     (= (mmpt-entry-write-lock mmpt-entry) 0)
		     ;; Only consider flushable pages.  Prefetched pages are never modified,
		     ;; and obviously if the frame isn't flushable at all we just ignore it.
		     (= (mmpt-entry-status mmpt-entry) %mmpt-status-flushable)
		     ;; Now see if it's modified (expensive on I-machine).
		     #+3600 ( (mmpt-entry-modified mmpt-entry) 0)
		     #+IMach ( (pht-modified (pht-lookup (mmpt-entry-vpn mmpt-entry))) 0)))
	  ;; Found a modified flushable frame.  Write out all pages in that frame's track in
	  ;; dpn order so it can all be done in one disk revolution.
	  (multiple-value-bind (n-pages start-vpn start-dpn batch-p)
	      (storage-background-lookup-block (mmpt-vpn mmpt-index))
	    (when (not (null n-pages))
	      (storage-background-write-block n-pages start-vpn start-dpn batch-p)
	      ;; Return after a block of writes to let caller decide whether to do more.
	      (return nil))))
	(setq mmpt-index (mmpt-thread mmpt-index)))
      (setq *flushable-queue-modified* (and ( mmpt-index %flushable-queue-end) mmpt-index)))))

(defwiredfun storage-background-write-block (n-pages start-vpn start-dpn batch-p)
  (declare (ignore batch-p))
  (loop repeat n-pages
	for vpn from start-vpn
	for dpn from start-dpn
	;; Never hang on the background queue
	while (not (disk-background-full-p))
	do
    (let ((pht-index (pht-lookup vpn)))
      (when (and pht-index (= (pht-pending pht-index) 0))
	;; Page is really resident.  If it's really modified and not already being
	;; written, or if it's in the load map but has swap space allocated for it
	;; (by virtue of being near a modified page), write it out.
	(let* ((ppn (pht-ppn pht-index))
	       (mmpt-index (mmpt-lookup ppn))
	       (mmpt-entry (mmpt-entry mmpt-index))
	       (modified-p #+3600 ( (mmpt-entry-modified mmpt-entry) 0)
			   #+IMach ( (pht-modified pht-index) 0)))
	  (when (and (bit-member (mmpt-entry-status mmpt-entry) *normalizable-status*)
		     (or modified-p
			 ;; Perhaps migrate the page from load space.  The load bit
			 ;; will be turned off when the write completes.
			 (and *load-pages-to-existing-swap-space-p* (load-bitmap vpn)))
		     ;; Can't write it if there's already a write in progress.
		     (= (mmpt-entry-write-lock mmpt-entry) 0))
	    (cache-remove (deposit-vpn vpn 0))
	    (setf (mmpt-entry mmpt-index)
		  (dpb 1 %%mmpt-write-lock
		       #+3600 (dpb 0 %%mmpt-modified mmpt-entry)
		       #+IMach mmpt-entry))
	    #+IMach (setf (pht-modified pht-index) 0)
	    (incf *count-locked-pages*)
	    (disk-enqueue-background-page-write %class-write dpn ppn)
	    ;; While the page is being written out, update its ESRT entry.
	    (gc-page-out vpn ppn modified-p #-3600 pht-index)
	    (when *page-trace-array*
	      (page-trace-insert %page-trace-write (deposit-vpn vpn 0)))))))))

;;; The storage background has decided to write out virtual page VPN.  Lookup its disk
;;; address (allocating disk space for it if necessary).  Determine the range of virtual
;;; pages stored with VPN in contiguous disk space, merge that against the geometry and
;;; policy information for that particular disk address, and return the contigous block
;;; of virtual/disk space that should be written.
(defwiredfun storage-background-lookup-block (vpn)
  (declare (values n-pages start-vpn start-dpn batch-p))
  (multiple-value-bind (dpn block-start-dpn block-n-pages)
      (smpt-create vpn)
    (multiple-value-bind (disk-start-dpn disk-n-pages batch-p)
	(disk-background-geometry dpn)
      (let ((base-dpn
	      (max* disk-start-dpn block-start-dpn))
	    (bound-dpn
	      (min* (+ block-start-dpn block-n-pages) (+ disk-start-dpn disk-n-pages))))
	(values (- bound-dpn base-dpn) (- vpn (- dpn base-dpn)) base-dpn batch-p)))))

;;; Write all modified pages to swap space, and optionally flush all normal pages.
;;; Must be called on the aux stack.
(defwiredfun write-all-modified-pages (&optional flush-p)
  (enter-storage-system *ms-time-user-flush-pages*
    (loop for mmpt-index below *mmpt-size* do
      (let ((mmpt-entry (mmpt-entry mmpt-index)))
	(when (= (mmpt-entry-invalid-vpn mmpt-entry) 0)
	  (let ((vpn (mmpt-entry-vpn mmpt-entry)))
	    ;; On the 3600, there aren't normally any vma=pma pages recorded in the MMPT,
	    ;; except during disk-save and netbooting.  On the I-machine, the wired system
	    ;; is in vma=pma space.
	    (when (progn #+3600 (or ( (ldb %%vpn-equals-ppn vpn) %vma-equals-pma)
				    (< vpn (extract-vpn %wired-virtual-address-high)))
			 #+IMach (or ( (ldb %%vpn-equals-ppn vpn) %vma-equals-pma)
				     (and ( vpn (extract-vpn %wired-virtual-address-low))
					  (< vpn (extract-vpn %wired-virtual-address-high)))))
	      (let (#+IMach (pht-index (pht-lookup vpn)))
		(when (and #+3600 ( (mmpt-entry-modified mmpt-entry) 0)
			   #+IMach ( (pht-modified pht-index) 0)
			   (= (mmpt-entry-write-lock mmpt-entry) 0))
		  (write-frame mmpt-index #+IMach pht-index))
		(when (and flush-p (= (mmpt-entry-status mmpt-entry) %mmpt-status-normal))
		  (flush-frame mmpt-index #+3600 (pht-lookup vpn) #+IMach pht-index nil))))))))
    (disk-background-promote-all)		;flush the background queue
    (wait-for-disk-done)))
) ;#-VLM


;;;; Page cache (map and PHT caches) management

#+3600 (progn

(defwiredfun cache-put (mmpt-index &optional inhibit-read-only)
  (let* ((entry (mmpt-entry mmpt-index))
	 (vma (deposit-vpn (mmpt-entry-vpn entry) 0)))
    (unless (or (= %vma-equals-pma (ldb %%vma-equals-pma vma))
		(and ( (%pointer %stack-buffer-low) vma)	;3-arg  doesn't open-code
		     ( vma (%pointer %stack-buffer-limit))))
      (let* ((ppn (mmpt-index-to-ppn mmpt-index))
	     (write-protect (if inhibit-read-only
				(lognot (mmpt-entry-modified entry))
				(logior (mmpt-entry-write-protect entry)
					(lognot (mmpt-entry-modified entry)))))
	     (phtc-entry
	       (selector (ldb %%hardware-configuration-map-cache-format
			      %hardware-configuration)
			 =
		 (%map-cache-format-obs
		   (%logdpb (ldb %%phtc-extract-vma-tag vma) %%phtc-vma-tag
			    (dpb ppn %%phtc-ppn
				 (dpb write-protect %%phtc-write-protect 0))))
		 (%map-cache-format-nbs
		   (dpb (ldb %%phtc-extract-nbs-vma-tag-low vma) %%phtc-nbs-vma-tag-low
			(dpb (ldb %%phtc-extract-nbs-vma-tag-high vma) %%phtc-nbs-vma-tag-high
			     (dpb ppn %%phtc-nbs-ppn
				  (dpb write-protect %%phtc-nbs-write-protect 0)))))
		 )))
	(%phtc-write vma phtc-entry)
	(%map-cache-write vma phtc-entry))))
  nil)						; Make compiler happy

(defwiredfun cache-remove (vma)
  (when ( %vma-equals-pma (ldb %%vma-equals-pma vma))
    (let ((phtc-entry (%phtc-read vma)))
      (if (selector (ldb %%hardware-configuration-map-cache-format %hardware-configuration)
		    =
	    (%map-cache-format-obs (= (ldb %%phtc-extract-vma-tag vma)
				      (ldb %%phtc-vma-tag phtc-entry)))
	    (%map-cache-format-nbs (and (= (ldb %%phtc-extract-nbs-vma-tag-low vma)
					   (ldb %%phtc-nbs-vma-tag-low phtc-entry))
					(= (ldb %%phtc-extract-nbs-vma-tag-high vma)
					   (ldb %%phtc-nbs-vma-tag-high phtc-entry)))))
	  (%phtc-write vma -1))			; Flush PHTC
      (%map-cache-write vma -1)))		; Flush map cache entry
  nil)						; Make compiler happy

) ;End #+3600

#+IMach (progn

(defmacro %invalidate-map-cache-for-vma (vma &optional (use-bar 1 use-bar-p))
  (let ((form `(progn (setf (%read-internal-register ,(si:block-register-name use-bar)) ,vma)
		      (compiler:no-op)		;superstition?
		      (setf (%read-internal-register
			      ,(fintern "%REGISTER-INVALIDATE-MAP-~d" use-bar)) t))))
    (if use-bar-p form				;no need to save the bar if it was explicit.
	`(si:saving-registers-for-effect (,(si:block-register-name use-bar)) ,form))))

(defwiredfun cache-remove (vma)
  #+VLM vma
  #-VLM
  (when ( (ldb %%vma-equals-pma vma) %vma-equals-pma)
    (%invalidate-map-cache-for-vma vma))
  nil)

) ;End #+IMach


;;;; PHT management

#+3600 (progn

;;;+ is this good enough?  Or does it really have to be more prime?
(defwiredfun pht-hash-size (size)
  (do ((size (logior size 1)
	     (+ size 2)))
      ((and (plusp (rem size 3))
	    (plusp (rem size 5))
	    (plusp (rem size 7))
	    (plusp (rem size 11.))
	    (plusp (rem size 13.))
	    (plusp (rem size 17.)))
       size)))

(defsubst rehash-vpn (vpn) (dpb vpn (byte 05 32) (ldb (byte 32 05) vpn)))

(defwiredfun pht-lookup (vpn)
  ;; Check cache first
  (if (eql *pht-lookup-last-vpn* vpn)
      (prog1 *pht-lookup-last-index*
	     #|(incf* *count-pht-lookup-hits*)|#)
    ;; expected number of time through loop about 1.4 on cold booted
    ;; machine, 2.6 after several GCs (determined experimentally).
    (let* ((mmpt *mmpt*)
	   (pht *pht*)
	   (pht-size *pht-size*)
	   (hash-vpn vpn)
	   (pht-index (rem hash-vpn pht-size)))
      (declare (array-register mmpt pht))
      (loop with vpn-tag = (ldb %%pht-vpn-tag vpn)
	    with foundp = nil
	    as pht-entry = (pht-entry pht-index pht)
	    count t into probes
	    until (or (null pht-entry)
		      (and (= vpn-tag (ldb %%pht-entry-valid-vpn-tag pht-entry))
			   (= vpn (let ((mmpt-index (mmpt-lookup
						      (ldb %%pht-entry-ppn pht-entry))))
				    (if (zerop (ldb %%pht-entry-pending pht-entry))
					(mmpt-vpn mmpt-index mmpt)
					(pending-get mmpt-index))))
			   (setq foundp t))
		      (zerop (ldb %%pht-entry-collision-count pht-entry))
		      (> probes (+ pht-size %rehash-max 100)))
	    when (> probes %rehash-max)
	      do (incf* *count-pht-linear-probes*)	;At least slow case is fast.
		 (incf hash-vpn)
		 (incf pht-index)
		 (if (= pht-index pht-size) (setq pht-index 0))	;Faster than MOD.
	    else
	      do (setq hash-vpn (rehash-vpn hash-vpn))
		 (setq pht-index (rem hash-vpn pht-size))
	    finally (let ((pht-probes *pht-probes*)	;bum it all (saved ~.7 microseconds!)
			  (probe-idx (min* (1- probes) %pht-probes-max)))
		      (incf (aref pht-probes probe-idx)))
		    (setq *pht-lookup-last-vpn* vpn)
		    (return (setq *pht-lookup-last-index* (and foundp pht-index)))))))

;;; Create an entry in the PHT for a resident virtual page.

(defwiredfun pht-put (vpn ppn)
  (declare (sys:array-register pht))
  (loop with pht = *pht*
	with pht-size = *pht-size*
	for hash-vpn = vpn then (if ( %rehash-max probes)
				    (rehash-vpn hash-vpn)
				  (1+ hash-vpn))
	for index = (rem hash-vpn pht-size)
	count t into probes
	as entry = (pht-entry index pht)
	until (or (null entry)
		  (not (zerop (ldb %%pht-entry-invalid entry)))
		  (if (> probes (+ pht-size %rehash-max 100))
		      (wired-ferror :fatal "PHT is completely filled.")))
	do (let ((count (ldb %%pht-entry-collision-count entry)))
	     (unless (= count %pht-collision-count-max)
	       (setf (pht-collision-count index pht) (1+ count))))
	finally
	   ;; this code used to look better, but it also used to be slower
	   (setf (pht-entry index pht)
		 (%logdpb 1 %%pht-entry-fault-request	; Until normalize-page or the like
			  (dpb (ldb %%pht-vpn-tag vpn) %%pht-entry-valid-vpn-tag
			       (dpb ppn %%pht-entry-ppn
				    (or entry 0)))))
	   ;; Save vpn and index into the pht-lookup cache
	   (setq *pht-lookup-last-vpn* vpn
		 *pht-lookup-last-index* index)
	   (return index)))

;;; Remove an entry from the PHT for a no longer resident virtual page
(defwiredfun pht-remove (vpn)
  (declare (sys:array-register pht))
  (setq *pht-lookup-last-vpn* nil)		;Invalidate cache
  (loop with pht = *pht*
	with vpn-tag = (ldb %%pht-vpn-tag vpn)
	for hash-vpn = vpn then (if ( %rehash-max probes)
				    (rehash-vpn hash-vpn)
				  (1+ hash-vpn))
	as pht-index = (rem hash-vpn *pht-size*)
	as pht-entry = (pht-entry pht-index pht)
	as collision-count = (ldb %%pht-entry-collision-count pht-entry)
	count t into probes
	until (and (= vpn-tag (ldb %%pht-entry-valid-vpn-tag pht-entry))
		   (= vpn (let ((mmpt-index (mmpt-lookup (ldb %%pht-entry-ppn pht-entry))))
			    (if (zerop (ldb %%pht-entry-pending pht-entry))
				(mmpt-vpn mmpt-index)
			      (pending-get mmpt-index)))))
	do
	  (if (zerop collision-count)	;+ Remove later maybe
	      (wired-ferror :fatal "PHT-REMOVE decrementing a zero collision count"))
	  (when ( collision-count %pht-collision-count-max)
	    (setf (pht-entry pht-index pht)
		  (if (and (= collision-count 1)
			   (not (zerop (ldb %%pht-entry-invalid pht-entry))))
		      nil
		    (dpb (1- collision-count) %%pht-entry-collision-count pht-entry))))
	finally (setf (pht-entry pht-index pht)
		      (if (zerop collision-count)
			  nil
			(dpb 1 %%pht-entry-invalid pht-entry)))))

) ;End #+3600

#+(and IMach (not VLM)) (progn

;;; I-machine doesn't use a cache since a miss in the cache slows down lookups
;;; by about a factor of two.

(defwiredfun pht-lookup (vpn)
  (search-pht :hash-vpn vpn
	      :match-vpn vpn
	      :rehash-hook :exit-collision-chain-hack))

(defmacro increment-pht-collision-count (bucket-index)
  `(let* ((bucket (/8 ,bucket-index))
	  (address (%pointer-plus *pht-collision-counts-base* (/8 bucket)))
	  (word (%memory-read address :fixnum-only t))
	  (rotation (*4 bucket))
	  (count (logand (rot word (- rotation)) %pht-collision-count-max)))
     (when ( count %pht-collision-count-max)	;stick at maximum
       (%memory-write address
	 (logior (rot (1+ count) rotation)
		 (logand (lognot (rot %pht-collision-count-max rotation)) word)))
       ;; When incrementing from 0 to 1, clear the chain bit for this bucket.
       (when (= count 0)
	 (incf *pht-collision-count*)
	 (setf (pht-chain (+ ,bucket-index 6)) 0)))))

(defwiredfun pht-put (vpn ppn)
  ;; When half the buckets in the PHT have nonzero collision counts, rehash.
  (when (> *pht-collision-count* (/8 *pht-size*)) (pht-rehash))
  (let ((index (search-pht
		 :hash-vpn vpn
		 :match-vpn %pht0-invalid-vpn
		 :rehash-hook increment-pht-collision-count)))
    ;; Initialize PHT entry for given VPN and PPN, asserting fault-request for now.
    ;; Replacement algorithm requires reference bits clear when fault-request=1.
    ;; GC requires all pages to be created with transport-trap=1.
    (setf (pht-pht0 index)
	  (%logdpbs vpn %%pht0-vpn
		    1 %%pht0-fault-request 0))
    (setf (pht-pht1 index)
	  (%logdpbs ppn %%pht1-ppn
		    ;; Binding stacks must always have ephemeral reference bits set.
		    (if (and ( (%read-internal-register %register-chip-revision) 2)
			     (= (ldb %%vpn-zone-and-subzone vpn)
				(dpb %safeguarded-zone %%subzone-zone-num
				     %safeguarded-subzone-binding-stack)))
			#b1111
			#b0000)
		    %%pht1-ephemeral-reference
		    1 %%pht1-transport-trap 0))
    (values index)))

(defmacro decrement-pht-collision-count (bucket-index)
  `(let* ((bucket (/8 ,bucket-index))
	  (address (%pointer-plus *pht-collision-counts-base* (/8 bucket)))
	  (word (%memory-read address :fixnum-only t))
	  (rotation (*4 bucket))
	  (count (logand (rot word (- rotation)) %pht-collision-count-max)))
     (when ( count %pht-collision-count-max)	;stick at maximum
       (when (= count 0)
	 (wired-ferror :fatal "Decrementing a PHT collision count below zero."))
       (%memory-write address
	 (logior (rot (1- count) rotation)
		 (logand (lognot (rot %pht-collision-count-max rotation)) word)))
       ;; When decrementing from 1 to 0, set the chain bit for this bucket.
       (when (= count 1)
	 (decf *pht-collision-count*)
	 (setf (pht-chain (+ ,bucket-index 6)) 1)))))

(defwiredfun pht-remove (vpn)
  (check-for-memory-ecc-error)
  (let ((index (search-pht
		 :hash-vpn vpn
		 :match-vpn vpn
		 :rehash-hook decrement-pht-collision-count)))
    ;; Invalidate PHT entry.  All we really need to do is set the vpn to -1, but
    ;; other places may depend on the contents of invalid pht entries.
    ;; - The GC wants the ephemeral-reference bits off.
    ;; - The replacement algorithm wants fault-request on and the reference bits off.
    ;; - The write-protect mechanism wants write-protect and modified off.
    ;; - The static-space GC can twiddle transport-trap at random.
    ;; Cf. INITIALIZE-STORAGE-CLEAR-PHT.
    (setf (pht-pht0 index) (%logdpb -1 %%pht0-vpn (%logdpb 1 %%pht0-fault-request 0)))
    (setf (pht-pht1 index) 0)
    (values index)))

;;; Rehash the PHT in place.  We don't use any other information (from the MMPT, for
;;; instance) because that kind of knowledge is fragile and tends to rot (e.g. what
;;; should the PHT1 word for a pending frame look like?).  The rehash uses the high cdr
;;; code bit of each entry to indicate whether the entry has been relocated.  The
;;; collision count table is cleared before the rehash, and incrementally updated during
;;; the rehash; afterwards, the collision chain bits are initialized from the collision
;;; counts, in the same scan that clears all the high cdr-code bits.
(defwiredfun pht-rehash ()
  (incf* *pht-rehashes*)
  ;; Clobber this so the scavenger won't miss any pages when it starts back up.
  ;; Note that the scavenger, which runs in emulator mode, has to interlock against us.
  (setq si:*scavenger-resident-pages-state* -1)
  ;; In case there are interrupt handlers that refer to wired-but-mapped storage, run
  ;; in interrupt mode while the PHT is inconsistent.
  (si:%set-trap-mode trap-mode-io)
  (with-system-block-registers (1 2 3)
    (si:saving-registers-for-effect (%register-bar-1)
      ;; Zero all collision counts
      (setf (%block-register 1) *pht-collision-counts-base*)
      ;; No need for (si:prepare-for-block-write), since address is unmapped.
      (loop repeat (/32 *pht-size*) do (%block-write 1 0))
      (setq *pht-collision-count* 0)
      ;; Rehash in place.
      (let ((null-vpn %pht0-invalid-vpn)
	    (pht-mask *pht-mask*)
	    (null-pht0 (%logdpbs %pht0-invalid-vpn %%pht0-vpn
				 1 %%pht0-fault-request
				 0))
	    (null-pht1 0))
	;; BAR 1 is used to address the PHT hashbox (c.f. pht-initial-hash).
	;; BAR 2 is used for the outer PHT scan.
	;; BAR 3 is used for the PHT entry relocation scan.
	(setf (%block-register 2) *pht-base*)
	(loop repeat (/4 *pht-size*) for bucket-index from 0 by 8 do
	  (loop repeat 4 do
	    (let* ((pht0 (%block-read 2 :fixnum-only t :set-cdr-next nil))
		   (vpn (ldb %%pht0-vpn pht0)))
	      (if (or (= vpn null-vpn)
		      (= (logand (pht-initial-hash vpn) pht-mask) bucket-index)
		      (ldb-test (byte 1 7) (%tag pht0)))
		  ;; This is an invalid entry, a valid entry in its optimal bucket, or a
		  ;; valid entry that's already been relocated.  Leave it in place,
		  ;; skipping over the PHT1 word.
		  (%block-read 2 :fixnum-only t)
		;; This is a valid entry that needs to be relocated.
		(let ((pht1 (%block-read 2 :fixnum-only t :set-cdr-next t)))
		  ;; Invalidate the old entry.  This will also invalidate the BAR 2 data
		  ;; buffer so we don't get screwed by hazards.
		  (setf (%block-register 2) (%pointer-plus (%block-register 2) -2))
		  (%block-write 2 null-pht0)
		  (%block-write 2 null-pht1)
		  ;; Follow the rehash sequence for this entry.  If we find an invalid
		  ;; entry, install the entry there and return.  If we find a valid
		  ;; entry that isn't in its optimal bucket, install this entry in
		  ;; place of that one and repeat the procedure for the replaced entry.
		  ;; When we install each entry, set the high cdr-code bit so we know
		  ;; not to move it again.  We never move an entry that's already in
		  ;; its optimal bucket or that has its high cdr-code bit set.
		  (loop named relocate-loop do
		    (let* ((state (ldb %%pht0-vpn pht0))
			   (offset (logand (pht-initial-hash state) pht-mask)))
		      (setf (%block-register 3) (%pointer-plus *pht-base* offset))
		      (loop named relocate-one do
			(loop repeat 4 do
			  (let ((old0 (%block-read 3 :fixnum-only t :set-cdr-next nil)))
			    (when (= (ldb %%pht0-vpn old0) null-vpn)
			      ;; Found an invalid entry, store the new entry there and
			      ;; exit the loop.
			      (setf (%block-register 3)
				    (%pointer-plus (%block-register 3) -1))
			      (%block-write 3 (%set-tag pht0 (dpb 2 (byte 2 6) dtp-fixnum)))
			      (%block-write 3 pht1)
			      (return-from relocate-loop nil))
			    (when (and ( (logand (pht-initial-hash (ldb %%pht0-vpn old0))
						  pht-mask)
					  offset)
				       (not (ldb-test (byte 1 7) (%tag old0))))
			      ;; A valid entry not in its optimal bucket, with its cdr
			      ;; code indicating that it hasn't been relocated yet.  Put
			      ;; the new entry there, and start the relocation process
			      ;; over again for the old entry.
			      (let ((old1 (%block-read 3 :set-cdr-next nil)))
				(setf (%block-register 3)
				      (%pointer-plus (%block-register 3) -2))
				(%block-write 3 (%set-tag pht0 (dpb 2 (byte 2 6) dtp-fixnum)))
				(%block-write 3 pht1)
				(setq pht0 old0)
				(setq pht1 old1)
				(return-from relocate-one nil)))
			    ;; A valid entry in its optimal bucket, or one that's already
			    ;; been relocated.  Skip over the PHT1 word and keep searching.
			    (%block-read 3 :fixnum-only t)))
			(increment-pht-collision-count offset)
			;; Search next bucket in chain.
			(setf (%block-register 3)
			      (%pointer-plus
				*pht-base*
				(setq offset
				      (logand
					(dpb (setq state (pht-next-state state))
					     (byte 25. 3)
					     0)
					;; Note that the high four bits are dont-cares.
					pht-mask)))))))))))))
      ;; Initialize the PHT cdr codes.  All cdr codes should be clear, except the nochain
      ;; bit should be on the last pht0 word in each bucket with collision-count=0.
      (setf (%block-register 1) *pht-collision-counts-base*)
      (setf (%block-register 2) *pht-base*)
      (setf (%block-register 3) *pht-base*)
      ;; Outer loop reads 8 collision counts per word, inner loop processes those 8 buckets.
      (loop repeat (/8 (/4 *pht-size*)) do
	(let ((mask (%block-read 1 :fixnum-only t :set-cdr-next t)))
	  (loop repeat 8 do
	    (let ((a0 (%block-read 2 :fixnum-only t :set-cdr-next t))
		  (a1 (%block-read 2 :fixnum-only t :set-cdr-next t))
		  (b0 (%block-read 2 :fixnum-only t :set-cdr-next t))
		  (b1 (%block-read 2 :fixnum-only t :set-cdr-next t))
		  (c0 (%block-read 2 :fixnum-only t :set-cdr-next t))
		  (c1 (%block-read 2 :fixnum-only t :set-cdr-next t))
		  (d0 (%block-read 2 :fixnum-only t :set-cdr-next t))
		  (d1 (%block-read 2 :fixnum-only t :set-cdr-next t)))
	      (%block-write 3 a0)
	      (%block-write 3 a1)
	      (%block-write 3 b0)
	      (%block-write 3 b1)
	      (%block-write 3 c0)
	      (%block-write 3 c1)
	      (if (logtest (shiftf mask (rot mask -4)) #b1111)
		  (%block-write 3 d0)
		(%block-write 3 (%set-tag d0 (dpb 1 (byte 2 6) dtp-fixnum))))
	      (%block-write 3 d1)))))))
  nil)

) ;End #+(and IMach (not VLM))


#+VLM (progn

(defwiredfun pht-lookup (vpn)
  (vm-lookup vpn))
  
(defwiredfun swap-count ()
  (let ((count (extract-vpn
		 (%32-bit-difference
		   (vlm-virtual-memory-size) (vlm-world-image-size)))))
    (if (plusp count)
	count
	;; Backwards compatiblity, give some minimal amount
	(extract-vpn 10._20.)))) 

(defwiredfun adjust-*count-swap-pages* ()
  (declare (values adjustment))
  (let ((old-count *count-swap-pages*)
	(new-count (swap-count)))
    (setf *count-swap-pages* new-count)
    (let ((increment (- new-count old-count)))
      (incf *count-remaining-swap-pages* increment)
      increment)))

) ;End #+VLM



#-VLM (PROGN

;;;; MMPT management

;;; Translate a PPN into an MMPT index
;;; Returns NIL if the PPN is not in MMPT-Y
(defwiredfun mmpt-lookup (ppn)
  (let ((y-entry (mmpt-y-entry (ldb %%ppn-mmpt-y ppn))))
    (and ( (mmpt-y-entry-valid y-entry) 0)
	 (dpb (mmpt-y-entry-index y-entry) %%ppn-mmpt-y ppn))))

;;; Translate an MMPT index into a PPN.  This has a dedicated table
;;; to speed up the "search".  Old code provided for reference
(defwiredfun mmpt-index-to-ppn (mmpt-index)
  #+ignore (+ (ldb %%ppn-mmpt-x mmpt-index)
	      (loop with y = (ldb %%ppn-mmpt-y mmpt-index)
		    with mmpt-y = *mmpt-y*
		    for i upfrom 0
		    as entry = (mmpt-y-entry i mmpt-y)
		    when (and (= (mmpt-y-entry-index entry) y)
			      (not (zerop (mmpt-y-entry-valid entry))))
		      return (* i %mmpt-x-size)))
  (dpb (mmpt-y-to-ppn-y-entry (ldb %%ppn-mmpt-y mmpt-index)) %%ppn-mmpt-y mmpt-index))


;;;; Pending queue management

;;; Associate a pending VPN with this frame.
;;; This should be called from a non-interruptible context, excepting sequence breaks.
(defwiredfun pending-put (mmpt-index vpn)
  (or (pending-queue-not-full-p)
      (timed-wired-wait *ms-time-pending-queue-full* t 30000. #'pending-queue-not-full-p))
  (let ((pending-index (do ((i (rem mmpt-index %pending-size) (if ( i (1- %pending-size))
								  0
								(1+ i))))
			   ((null (aref *pending-indices* i)) i))))
    (incf *count-pending*)
    ;; The order is important here if you care about warm booting.
    (setf (aref *pending-vpn* pending-index) vpn)
    (setf (aref *pending-indices* pending-index) mmpt-index)))

;;; Get the pending VPN associated with this frame.
(defwiredfun pending-get (mmpt-index)
  (aref *pending-vpn* (do ((c 0 (1+ c))
			   (i (rem mmpt-index %pending-size) (if ( i (1- %pending-size))
								 0
							       (1+ i))))
			  ((eq (aref *pending-indices* i) mmpt-index) i)
			(if ( c %pending-size)
			    (wired-ferror :fatal "Can't find pending VPN for mmpt-index ~O"
					  mmpt-index)))))

;;; Destructively get the pending VPN associated with this frame.
;;; Called from a non-interruptible context
(defwiredfun pending-remove (mmpt-index)
  (let ((pending-index (do ((c 0 (1+ c))
			    (i (rem mmpt-index %pending-size) (if ( i (1- %pending-size))
								  0
								(1+ i))))
			   ((eq (aref *pending-indices* i) mmpt-index) i)
			 (if ( c %pending-size)
			     (wired-ferror :fatal "Can't find pending VPN for mmpt-index ~O"
					   mmpt-index)))))
    (decf *count-pending*)
    (setf (aref *pending-indices* pending-index) nil)	; Remove entry
    (aref *pending-vpn* pending-index)))


;;;; Secondary Memory Page Table (SMPT) management

;;; Before getting too grossed out by the overhead of SMPT insertion, consider:
;;;	o  SMPT-CREATE only causes an insertion to be made ONCE upon the first
;;;	   swapout of every %SMPT-QUANTUM pages.
;;;	o  Out of these inserts, on the average only 1 out of %SMPT-LEAF-MAX/4 (3 currently)
;;;	   inserts will have to go through the hairy neighbor check.
;;;	o  An even smaller percentage of inserts will have to go through the node
;;;	   split code.
;;;	o  And only 1 out of every %SMPT-BRANCH-MAX/4 (3 currently) of these inserts will
;;;	   cause a branch node to check neighbors.
;;;     o  And an even smaller percentage of those inserts will cause a branch node
;;;	   to ever split.

;;; Constructors

(defwiredfun make-smpt-branch (ascendent)
  (let ((node (create-dynamic-space %smpt-branch-size)))
    (setf (smpt-count node) 0)
    (setf (smpt-type node) %smpt-branch-node)
    (setf (smpt-ascendent node) ascendent)
    node))

(defwiredfun make-smpt-leaf (ascendent)
  (let ((node (create-dynamic-space %smpt-leaf-size)))
    (setf (smpt-count node) 0)
    (setf (smpt-type node) %smpt-leaf-node)
    (setf (smpt-ascendent node) ascendent)
    node))

;;; Lookup
;;; Metering indicated a smpt cache hit ratio greater than 80% in release 4.1
(defwiredfun smpt-lookup (vpn)
  (declare (values dpn node index))		; DPN is NIL upon miss; no index on hit
  (when (or (null *smpt-cached-vpn*)
	    (< vpn *smpt-cached-vpn*)
	    ( vpn (+ *smpt-cached-vpn* *smpt-cached-n-pages*)))
    (setq *smpt-cached-node*
	  (do ((node *smpt* (smpt-branch-lookup node vpn)))
	      (( (smpt-type node) %smpt-branch-node) node)))
    (multiple-value-setq
      (*smpt-cached-vpn* *smpt-cached-n-pages* *smpt-cached-dpn* *smpt-cached-index*)
      (smpt-leaf-lookup *smpt-cached-node* vpn)))
  (cond (*smpt-cached-vpn*
	 (values (+ *smpt-cached-dpn* (- vpn *smpt-cached-vpn*))
		 *smpt-cached-node*
		 *smpt-cached-index*))
	(t (values nil *smpt-cached-node* *smpt-cached-index*))))

;;; Creation
;;; Lookup a VPN and return the entire block, or create one upon miss
(defwiredfun smpt-create (vpn)
  (declare (values dpn start-dpn n-pages))
  (multiple-value-bind (dpn node index)
      (smpt-lookup vpn)
    (if (not (null dpn))
	(values dpn *smpt-cached-dpn* *smpt-cached-n-pages*)
      ;; No entry, allocate some disk space and insert a new entry.
      (ms-time *ms-time-smpt-create*
	(multiple-value-bind (low-vpn n-pages)
	    (smpt-find-missing-range vpn node index)
	  (let ((aligned-vpn (macrolet ((align-vpn (vpn)
					  ;; %smpt-quantum must be a power of two
					  (assert (zerop (logand %smpt-quantum
								 (1- %smpt-quantum))))
					  ;; Round to the next lower multiple of %smpt-quantum
					  `(logand ,vpn (- %smpt-quantum))))
			       (align-vpn vpn))))
	    (if (< low-vpn aligned-vpn)
		(decf n-pages (- aligned-vpn low-vpn))
	      (setq aligned-vpn low-vpn))
	    (setq n-pages (min* n-pages %smpt-quantum))
	    (multiple-value-bind (aligned-dpn n-pages-assigned)
		(swap-assign n-pages aligned-vpn)
	      (when (< n-pages-assigned (- vpn aligned-vpn))
		;; Swap running low.  Just use as much space as we got, with the vpn as low
		;; in the space as we can make it without overlapping the next SMPT entry.
		;; (This is sort of silly, we should just start asking for single pages
		;; when swap space gets low in the first place.)
		(setq aligned-vpn (min* vpn (- (+ aligned-vpn n-pages) n-pages-assigned))))
	      (smpt-create-entry aligned-vpn n-pages-assigned aligned-dpn node)
	      (values (+ aligned-dpn (- vpn aligned-vpn)) aligned-dpn n-pages-assigned))))))))

;;; Note that this does not create aligned entries, it is for allocating
;;; large chunks of swap and assumes the caller will do its own aligning
;;; (knowing better).
(defwiredfun smpt-create-n-pages (vpn n-pages)
  (ms-time *ms-time-smpt-create*
    (loop with limit-vpn = (+ vpn n-pages)
	  while (< vpn limit-vpn)
	  doing
      (multiple-value-bind (dpn node index) (smpt-lookup vpn)
	(cond (dpn
	       ;; An SMPT entry contains the initial VPN of the page
	       ;; range specified by [VPN, LIMIT-VPN).  Go to the
	       ;; end of the SMPT entry and try again.
	       (setq vpn (+ (smpt-leaf-n-pages node index)
			    (smpt-leaf-vpn node index))))
	      (t
	       ;; No SMPT entry exists containing the initial VPN of this
	       ;; range.  Create all the pages in the range, being careful
	       ;; to skip over intervals in the range already described by
	       ;; a later SMPT entry.
	       (multiple-value-bind (low-vpn missing-pages)
		   (smpt-find-missing-range vpn node index)
		 (when (< low-vpn vpn)
		   (decf missing-pages (- vpn low-vpn)))
		 (when (> missing-pages (ldb %%smpt-leaf-n-pages -1))
		   (setq missing-pages (ldb %%smpt-leaf-n-pages -1)))
		 (multiple-value-bind (dpn n-pages-assigned)
		     (swap-assign (min* missing-pages (- limit-vpn vpn)) vpn)
		   (smpt-create-entry vpn n-pages-assigned dpn node)
		   ;; This doesn't try to be tricky about skipping over
		   ;; any intervening blocks or if N-PAGES-ASSIGNED is
		   ;; less than requested since we might end up having to
		   ;; move to a different SMPT node, so just do the lookup
		   ;; loop again
		   (incf vpn n-pages-assigned)))))))))

(defwiredfun smpt-create-entry (aligned-vpn n-pages-assigned aligned-dpn node)
  (incf* *count-smpt-inserts*)
  ;; Purge the smpt-lookup cache, since *smpt-cached-node/index* may become invalid
  (setq *smpt-cached-vpn* nil)
  (if (< (smpt-count node) %smpt-leaf-max)
      ;; Normal case: room in current node, so just insert it.
      (smpt-leaf-insert node aligned-vpn n-pages-assigned aligned-dpn)
    ;; No room: check neighbors or split.
    (multiple-value-bind (l-node r-node) (smpt-neighbors node)
      (let ((l-count (and l-node (smpt-count l-node)))
	    (r-count (and r-node (smpt-count r-node))))
	(cond ((and l-node (< l-count %smpt-leaf-max)
		    (or (null r-node)
			(< l-count r-count)))
	       ;; Insert into left neighbor
	       (incf* *count-smpt-left-inserts*)
	       (let ((v (smpt-leaf-vpn-and-n-pages node 0))
		     (d (smpt-leaf-dpn node 0)))
		 (multiple-value-bind (k-node k-index) (smpt-find-branch node)
		   ;; Insert new entry into node, going backwards for efficiency.
		   (smpt-leaf-insert node aligned-vpn n-pages-assigned aligned-dpn t)
		   ;; Append prior first entry to left node.
		   ;; The entry being inserted must be greater than the first entry
		   ;; or else lookup would have selected a different node except for
		   ;; the very first leaf node, for which there is no left neighbor.
		   (setf (smpt-leaf-vpn-and-n-pages l-node l-count) v)
		   (setf (smpt-leaf-dpn l-node l-count) d)
		   (incf (smpt-count l-node))
		   (setf (smpt-branch-vpn k-node k-index) (smpt-leaf-vpn node 0)))))
	      ((and r-node (< r-count %smpt-leaf-max))
	       ;; Insert into right neighbor
	       (incf* *count-smpt-right-inserts*)
	       (let ((i (1- (smpt-count node))))	; Index of last entry in node
		 (cond ((> aligned-vpn (smpt-leaf-vpn node i))
			(multiple-value-bind (k-node k-index) (smpt-find-branch r-node)
			  ;; Just insert new vpn into right node
			  (smpt-leaf-insert r-node aligned-vpn n-pages-assigned aligned-dpn)
			  ;; Fix ascendent key for r-node
			  (setf (smpt-branch-vpn k-node k-index) aligned-vpn)))
		       (t
			(let ((v (smpt-leaf-vpn node i))
			      (n (smpt-leaf-n-pages node i))
			      (d (smpt-leaf-dpn node i)))
			  (multiple-value-bind (k-node k-index) (smpt-find-branch r-node)
			    ;; Insert new entry into current node
			    (smpt-leaf-insert node aligned-vpn n-pages-assigned aligned-dpn)
			    ;; Insert clobbered last entry to right node
			    (smpt-leaf-insert r-node v n d)
			    ;; Fix ascendent key for r-node
			    (setf (smpt-branch-vpn k-node k-index) v)))))))
	      ;; Metering suggests that it is advantageous to try a global
	      ;; balance here before creating a new node.
	      ((globally-balance-smpt-if-appropriate)
	       ;; This created room in every node, so we can just be simple.
	       (multiple-value-bind (nil new-node)
		   (smpt-lookup aligned-vpn)
		 (smpt-leaf-insert new-node aligned-vpn n-pages-assigned aligned-dpn)))
	      (t
	       ;; No room in any neighbors, create a new node
	       (let ((new-node (make-smpt-leaf (smpt-ascendent node))))
		 (cond ((null r-node)
			;; No right, don't split since vma grows sequentially
			(incf* *count-smpt-appends*)
			(if (< aligned-vpn
			       (smpt-leaf-vpn node (1- (smpt-count node))))
			    ;; Make room for insertion
			    (let ((c (1- (smpt-count node))))
			      (setf (smpt-leaf-vpn-and-n-pages new-node 0)
				    (smpt-leaf-vpn-and-n-pages node c))
			      (setf (smpt-leaf-dpn new-node 0)
				    (smpt-leaf-dpn node c))
			      (incf (smpt-count new-node))
			      (decf (smpt-count node)))))
		       (t ;;(null l-node) maybe separate clause to divide into 4ths
			;; Divide full nodes contents into three
			(incf* *count-smpt-splits*)
			;; Move last 1/3 of node into new-node
			(multiple-value-bind (k-node k-index) (smpt-find-branch r-node)
			  (do ((i (- %smpt-leaf-max (truncate %smpt-leaf-max 3)) (1+ i))
			       (j 0 (1+ j)))
			      ((= %smpt-leaf-max i)
			       (setf (smpt-count new-node) j)
			       (decf (smpt-count node) j))
			    (setf (smpt-leaf-vpn-and-n-pages new-node j)
				  (smpt-leaf-vpn-and-n-pages node i))
			    (setf (smpt-leaf-dpn new-node j) (smpt-leaf-dpn node i)))
			  ;; Copy first 1/3 of r-node into new-node
			  (do ((i 0 (1+ i))
			       (j (smpt-count new-node) (1+ j)))
			      ((= (truncate %smpt-leaf-max 3) i)
			       (incf (smpt-count new-node) i)
			       (decf (smpt-count r-node) i))
			    (setf (smpt-leaf-vpn-and-n-pages new-node j)
				  (smpt-leaf-vpn-and-n-pages r-node i))
			    (setf (smpt-leaf-dpn new-node j)
				  (smpt-leaf-dpn r-node i)))
			  ;; Close off r-node
			  (do ((i (truncate %smpt-leaf-max 3) (1+ i))
			       (j 0 (1+ j)))
			      ((= i %smpt-leaf-max))
			    (setf (smpt-leaf-vpn-and-n-pages r-node j)
				  (smpt-leaf-vpn-and-n-pages r-node i))
			    (setf (smpt-leaf-dpn r-node j) (smpt-leaf-dpn r-node i)))
			  ;; Fix ascendent key for r-node
			  (setf (smpt-branch-vpn k-node k-index)
				(smpt-leaf-vpn r-node 0)))))
		 (smpt-leaf-insert (if (or (zerop (smpt-count new-node))
					   (> aligned-vpn (smpt-leaf-vpn new-node 0)))
				       new-node
				     node)
				   aligned-vpn
				   n-pages-assigned
				   aligned-dpn)
		 (smpt-branch-create (smpt-ascendent new-node)
				     (smpt-leaf-vpn new-node 0)
				     new-node))))))))

;; Balance the SMPT only if the resulting nodes will be less than 80% full.
;; This algorithm only works because (- %smpt-leaf-max (* 0.8 %smpt-leaf-max))  2
;; so that there really is guaranteed to be at least one free slot in each node,
;; even the ones that get the residue, after globally-balance-smpt-leaves.
;; Returns T if it rebalanced.
(defwiredfun globally-balance-smpt-if-appropriate ()
  (let ((node *smpt*) (leaf-count 0) (entry-count 0))
    (when (= (smpt-type node) %smpt-leaf-node)
      (return-from globally-balance-smpt-if-appropriate nil))
    (loop do (setq node (smpt-branch-descendent node 0))
	  until (= (smpt-type node) %smpt-leaf-node))
    (loop do (incf leaf-count)
	     (incf entry-count (smpt-count node))
	     (multiple-value-setq (nil node) (smpt-neighbors node))
	  while node)
    (when (< (floor (* 10. entry-count) leaf-count)	;when less than 8/10 full
	     (* 8 %smpt-leaf-max))
      (globally-balance-smpt-leaves)
      t)))

(defwiredfun globally-balance-smpt-leaves ()
  (setq *smpt-cached-vpn* nil)
  (let ((smpt *smpt*))
    ;; If the SMPT is just one leaf, return.
    (when (= (smpt-type smpt) %smpt-leaf-node)
      (return-from globally-balance-smpt-leaves nil))
    (incf* *count-smpt-balances*)
    (let ((from-leaf smpt) to-leaf from-index to-index
	  (entry-count 0) (leaf-count 0) (leaf-number 0))
      (loop do (setf from-leaf (smpt-branch-descendent from-leaf (smpt-count from-leaf)))
	    until (= (smpt-type from-leaf) %smpt-leaf-node))
      (setq from-index (smpt-count from-leaf)
	    to-leaf from-leaf
	    to-index %smpt-leaf-max)
      ;; First pass, copy the leaves into the last half of the SMPT, and count them while
      ;; we're at it.  Iterate backward through the leaves.
      (loop named top
	    do (loop do (decf from-index)
		     until ( from-index 0)
		     do (setq from-leaf (smpt-neighbors from-leaf))
			(incf leaf-count)
		     when (null from-leaf)
		       do (return-from top)
		     do (setq from-index (smpt-count from-leaf)))
	       (loop do (decf to-index)
		     until ( to-index 0)
		     do (setq to-leaf (smpt-neighbors to-leaf)
			      to-index %smpt-leaf-max))
	       (incf entry-count)
	       (setf (smpt-leaf-vpn-and-n-pages to-leaf to-index)
		     (smpt-leaf-vpn-and-n-pages from-leaf from-index))
	       (setf (smpt-leaf-dpn to-leaf to-index)
		     (smpt-leaf-dpn from-leaf from-index)))
      ;; The first RESIDUE entries get (1+ NEW-COUNT) entries per node, and the
      ;; remaining entries get NEW-COUNT entries.
      (multiple-value-bind (new-count residue)
	  (floor entry-count leaf-count)
	(setq from-leaf to-leaf
	      from-index to-index
	      to-leaf smpt
	      to-index 0)
	(loop do (setq to-leaf (smpt-branch-descendent to-leaf 0))
		 until (= (smpt-type to-leaf) %smpt-leaf-node))
	;; Second pass, copy the leaves forward from the last half of the SMPT.
	(loop named top
	      do (loop until (< to-index (if (< leaf-number residue)
					     (1+ new-count)
					     new-count))
		       do (setf (smpt-count to-leaf) to-index)
			  (multiple-value-setq (nil to-leaf) (smpt-neighbors to-leaf))
			  (incf leaf-number)
			  (when (null to-leaf)
			    (return-from top))
			  (setq to-index 0))
		 (loop until (< from-index %smpt-leaf-max)
		       do (multiple-value-setq (nil from-leaf) (smpt-neighbors from-leaf))
			  (setq from-index 0))
		 (setf (smpt-leaf-vpn-and-n-pages to-leaf to-index)
		       (smpt-leaf-vpn-and-n-pages from-leaf from-index))
		 (setf (smpt-leaf-dpn to-leaf to-index)
		       (smpt-leaf-dpn from-leaf from-index))
		 (incf from-index)
		 (incf to-index))
	;; Final pass, adjust ascendent VPNs.
	(setq from-leaf smpt)
	(loop do (setq from-leaf (smpt-branch-descendent from-leaf 0))
	      until (= (smpt-type from-leaf) %smpt-leaf-node))
	(loop do (when (zerop (smpt-count from-leaf))
		   (setf (smpt-leaf-vpn-and-n-pages from-leaf 0)
			 (dpb -1 %%smpt-leaf-vpn 0)))
		 (smpt-adjust-ascendent-vpns (smpt-leaf-vpn from-leaf 0) from-leaf)
		 (multiple-value-setq (nil from-leaf) (smpt-neighbors from-leaf))
	      while from-leaf)))))

;;; Destruction
(defwiredfun smpt-destroy (vpn n-pages)
  (multiple-value-bind (nil node index) (smpt-lookup vpn)
    (loop named destroy-loop
	  with end-vpn = (+ vpn n-pages)
	  for index from index
	  while (plusp n-pages)
	  ;; Wrap around to the next non-empty node if necessary
	  do (loop while node
		   until (< index (smpt-count node))
		   do (multiple-value-setq (nil node) (smpt-neighbors node))
		      (setq index 0))
	  while node
	  as entry-vpn = (smpt-leaf-vpn node index)
	  ;; Done if the vpns are out of the range, all the pages deleted, or no more nodes
	  while (< entry-vpn end-vpn)
	  as entry-dpn = (smpt-leaf-dpn node index)
	  as entry-n-pages = (smpt-leaf-n-pages node index)
	  as entry-end-vpn = (+ entry-vpn entry-n-pages)
	  do (cond ((and ( entry-vpn vpn)
			 ( entry-end-vpn end-vpn))
		    ;; Destroy whole entry
		    (swap-deassign entry-dpn entry-n-pages)
		    (loop for from-idx upfrom (1+ index) below (smpt-count node)
			  for to-idx upfrom index
			  do (setf (smpt-leaf-vpn-and-n-pages node to-idx)
				   (smpt-leaf-vpn-and-n-pages node from-idx))
			     (setf (smpt-leaf-dpn node to-idx)
				   (smpt-leaf-dpn node from-idx)))
		    (decf (smpt-count node))
		    (when (zerop index)
		      (loop for node = node then rnode with rnode
			    while (zerop (smpt-count node)) do
			;; This node has become empty, so try to refill it from its neighbor.
			;; If the neighbor is already empty, then we have collected all the
			;; empty nodes at the right-hand edge of the tree, so set the VPN to
			;; a value larger than any real VPN.  This empty node will get
			;; reused later when its left neighbor becomes completely full.
			(multiple-value-setq (nil rnode) (smpt-neighbors node))
			(let ((count (and rnode (%fixnum-ceiling (smpt-count rnode) 2))))
			  (cond ((and count (plusp count))
				 (incf* *count-smpt-empty-node-steals*)
				 (dotimes (i count)
				   (setf (smpt-leaf-vpn-and-n-pages node i)
					 (smpt-leaf-vpn-and-n-pages rnode i))
				   (setf (smpt-leaf-dpn node i)
					 (smpt-leaf-dpn rnode i)))
				 (smpt-adjust-ascendent-vpns (smpt-leaf-vpn node 0) node)
				 (setf (smpt-count node) count)
				 (decf (smpt-count rnode) count)
				 (dotimes (i (smpt-count rnode))
				   (setf (smpt-leaf-vpn-and-n-pages rnode i)
					 (smpt-leaf-vpn-and-n-pages rnode (+ i count)))
				   (setf (smpt-leaf-dpn rnode i)
					 (smpt-leaf-dpn rnode (+ i count)))))
				(t
				 (incf* *count-smpt-empty-node-shifts*)
				 (setf (smpt-leaf-vpn-and-n-pages node 0)
				       (dpb -1 %%smpt-leaf-vpn 0))
				 (loop-finish))))
			finally
			  ;; Adjust branch vpn of the last node we modified
			  (smpt-adjust-ascendent-vpns (smpt-leaf-vpn node 0) node)))
		    (decf n-pages entry-n-pages)
		    (decf index))
		   (( vpn entry-vpn)
		    ;; Destroy first part of entry
		    (let ((destroy-n-pages (- end-vpn entry-vpn)))
		      (swap-deassign entry-dpn destroy-n-pages)
		      (incf (smpt-leaf-vpn node index) destroy-n-pages)
		      (incf (smpt-leaf-dpn node index) destroy-n-pages)
		      (decf (smpt-leaf-n-pages node index) destroy-n-pages)
		      (decf n-pages destroy-n-pages))
		    (when (zerop index)
		      ;; Adjust branch vpn
		      (smpt-adjust-ascendent-vpns (smpt-leaf-vpn node index) node)))
		   (( entry-end-vpn end-vpn)
		    ;; Destroy last part of entry
		    (let ((destroy-n-pages (- entry-end-vpn vpn)))
		      (swap-deassign (+ entry-dpn (- vpn entry-vpn))
				     destroy-n-pages)
		      (decf (smpt-leaf-n-pages node index) destroy-n-pages)
		      (decf n-pages destroy-n-pages)))
		   (t
		    ;; Destroy middle of entry
		    (let ((old-entry-n-pages entry-n-pages)
			  (entry-offset (- vpn entry-vpn))
			  (entry-dpn (smpt-leaf-dpn node index)))
		      (swap-deassign (+ entry-dpn entry-offset) n-pages)
		      (setf (smpt-leaf-n-pages node index) entry-offset)
		      (smpt-create-entry end-vpn
					 (- old-entry-n-pages (- end-vpn entry-vpn))
					 (+ entry-dpn (- end-vpn entry-vpn))
					 node))
		    ;; (setq n-pages 0) ;; not needed since exiting loop
		    (return-from destroy-loop))))
    (setq *smpt-cached-vpn* nil)))

(defwiredfun smpt-adjust-ascendent-vpns (vpn node)
  (multiple-value-bind (k-node k-index) (smpt-find-branch node)
    (when k-node
      (setf (smpt-branch-vpn k-node k-index) vpn))))

(defwiredfun smpt-move (new-node new-index old-node old-index)
  (let ((old-descendent (smpt-branch-descendent old-node old-index)))
    ;; put the old descendent in its new home
    (setf (smpt-branch-descendent new-node new-index) old-descendent)
    ;; make it be adopted by a new parent.
    (setf (smpt-ascendent old-descendent) new-node)))

#| This doesn't stand a chance!!  And it doesn't need to be a macro
(defmacro smpt-move (new-node new-index old-node old-index)
  `(setf (smpt-ascendent
	   (setf (smpt-branch-descendent ,new-node ,new-index)
		 (smpt-branch-descendent ,old-node ,old-index)))
	 ,new-node))
|#

(defwiredfun smpt-branch-create (node vpn descendent)
  (cond ((null node)
	 (let ((old-root *smpt*))
	   (setq node (setq *smpt* (make-smpt-branch nil)))
	   (setf (smpt-branch-descendent node 0) old-root)
	   (setf (smpt-ascendent old-root) node))))
  (setf (smpt-ascendent descendent) node)
  (if (< (smpt-count node) %smpt-branch-max)
      ;; Normal case: room in current node, so just insert it.
      (smpt-branch-insert node vpn descendent)
    ;; No room: check neighbors or split.
    (multiple-value-bind (l-node r-node) (smpt-neighbors node)
      (cond ((and l-node (< (smpt-count l-node) %smpt-branch-max))
	     ;; Insert into left neighbor
	     (incf* *count-smpt-left-inserts*)
	     (multiple-value-bind (k-node k-index) (smpt-find-branch node)
	       ;; Move ascendent key down into left node
	       (setf (smpt-branch-vpn l-node (smpt-count l-node))
		     (smpt-branch-vpn k-node k-index))
	       ;; As well as its descendent node
	       (smpt-move l-node (incf (smpt-count l-node)) node 0)
	       ;; Now insert the new entry, going backwards for efficiency.
	       (smpt-branch-insert node vpn descendent t)
	       ;; Fix ascendent key
	       (setf (smpt-branch-vpn k-node k-index)
		     (do ((node node (smpt-branch-descendent node 0)))
			 ((= %smpt-leaf-node (smpt-type node)) (smpt-leaf-vpn node 0))))))
	    ((and r-node (< (smpt-count r-node) %smpt-branch-max))
	     ;; Insert into right neighbor
	     (incf* *count-smpt-right-inserts*)
	     (multiple-value-bind (k-node k-index) (smpt-find-branch r-node)
	       (cond ((< vpn (smpt-branch-vpn node (1- (smpt-count node))))
		      ;; Move ascendent key and node down into right node
		      (smpt-branch-push r-node
					(smpt-branch-vpn k-node k-index)
					(smpt-branch-descendent node (smpt-count node)))
		      ;; Move nth key up to ascendent	       
		      (setf (smpt-branch-vpn k-node k-index)
			    (smpt-branch-vpn node (1- (smpt-count node))))
		      ;; Now insert the new entry
		      (smpt-branch-insert node vpn descendent))
		     (t
		      ;; Store new vpn in ascendent
		      (setf (smpt-branch-vpn k-node k-index) vpn)
		      (smpt-branch-push r-node
					(do ((node (smpt-branch-descendent r-node 0)
						   (smpt-branch-descendent node 0)))
					    ((= %smpt-leaf-node (smpt-type node))
					     (smpt-leaf-vpn node 0)))
					descendent)))))
	    (t
	     ;; No room in any neighbors, create a new node
	     (let ((new-node (make-smpt-branch (smpt-ascendent node)))
		   (new-vpn vpn))
	       (cond ((null r-node)
		      ;; No right, don't split since vma grows sequentially
		      (incf* *count-smpt-appends*)
		      (cond ((< vpn (smpt-branch-vpn node (1- (smpt-count node))))
			     ;; Make room in node by moving last entry to new-node
			     (smpt-move new-node 0 node (smpt-count node))
			     (setq new-vpn (smpt-branch-vpn node (decf (smpt-count node))))
			     ;; Insert new entry
			     (smpt-branch-insert node vpn descendent))
			    (t
			     (setf (smpt-ascendent
				     (setf (smpt-branch-descendent new-node 0)
					   descendent))
				   new-node))))
		     (t	;;(null l-node) maybe separate clause to divide into 4ths
		      ;; Divide full nodes contents into three
		      (incf* *count-smpt-splits*)
		      (multiple-value-bind (k-node k-index) (smpt-find-branch r-node)
			;; Move last 1/3 of node into new-node
			(let ((i (1+ (- %smpt-branch-max (truncate %smpt-branch-max 3)))))
			  ;; Special case for first entry in new-node
			  (setq new-vpn (smpt-branch-vpn node (1- i)))
			  (smpt-move new-node 0 node i)
			  (decf (smpt-count node))
			  ;; Now move the rest of the 1/3 of node into new-node
			  (do ((i i (1+ i))
			       (j 0 (1+ j)))
			      ((= %smpt-branch-max i)
			       (setf (smpt-count new-node) j)
			       (decf (smpt-count node) j))
			    (setf (smpt-branch-vpn new-node j) (smpt-branch-vpn node i))
			    (smpt-move new-node (1+ j) node (1+ i))))
			;; Copy first 1/3 of r-node into new-node
			(setf (smpt-branch-vpn new-node (smpt-count new-node))
			      (smpt-branch-vpn k-node k-index))
			(smpt-move new-node (incf (smpt-count new-node)) r-node 0)
			(do ((i 0 (1+ i))
			     (j (smpt-count new-node) (1+ j)))
			    ((= (truncate %smpt-branch-max 3) i)
			     (setf (smpt-count new-node) j)
			     (decf (smpt-count r-node) (1+ i)))	; Include key moved to k-node
			  (setf (smpt-branch-vpn new-node j) (smpt-branch-vpn r-node i))
			  (smpt-move new-node (1+ j) r-node (1+ i)))
			;; Close off r-node
			(let ((i (1+ (truncate %smpt-branch-max 3))))
			  (setf (smpt-branch-vpn k-node k-index)
				(smpt-branch-vpn r-node (1- i)))
			  (setf (smpt-branch-descendent r-node 0)
				(smpt-branch-descendent r-node i))
			  (do ((i i (1+ i))
			       (j 0 (1+ j)))
			      ((= i %smpt-branch-max))
			    (setf (smpt-branch-vpn r-node j) (smpt-branch-vpn r-node i))
			    (setf (smpt-branch-descendent r-node (1+ j))
				  (smpt-branch-descendent r-node (1+ i))))))
		      (smpt-branch-insert (if (> vpn
						 (smpt-branch-vpn node
								  (1- (smpt-count node))))
					      (progn
						(setf (smpt-ascendent descendent) new-node)
						new-node)
					    node)
					  vpn
					  descendent)))
	       (smpt-branch-create (smpt-ascendent new-node)
				   new-vpn
				   new-node)))))))

#| Faster version which only works on leaf nodes.
;;; Find the branch node containing the VPN key pointing to the leaf node
;;; Will return NIL for the node iff the node is the very first leaf node.
(defwiredfun smpt-find-branch (leaf-node)
  (declare (values branch-node index))
  (do ((ascendent (smpt-ascendent leaf-node) (smpt-ascendent ascendent))
       (vpn (smpt-leaf-vpn leaf-node 0)))
      ((null ascendent) (values nil nil))
    (multiple-value-bind (ignore index found-p) (smpt-branch-lookup ascendent vpn)
      (if found-p
	  (return ascendent index)))))
|#

(defwiredfun smpt-find-branch (node)
  (declare (values branch-node index))
  (loop for node = node then ascendent
	for ascendent = (smpt-ascendent node)
	unless ascendent return nil
	for index = (do ((i 0 (1+ i)))
			((eq node (smpt-branch-descendent ascendent i)) i))
	while (zerop index)
	finally (return (values ascendent (1- index)))))

(defwiredfun smpt-neighbors (node)
  (declare (values left-node right-node))
  (do* ((i 0 (1+ i))
	(node node asc)
	(asc (smpt-ascendent node) (smpt-ascendent node))
	index left-node right-node)
      ((or (null asc) (and left-node right-node)) (values left-node right-node))
    (setq index (dotimes (j (1+ (smpt-count asc)))
		  (if (eq node (smpt-branch-descendent asc j))
		      (return j))))
    (cond ((and (null left-node)
		(plusp index))
	   (setq left-node (smpt-branch-descendent asc (1- index)))
	   (dotimes (j i)
	     (declare (ignore j))
	     (setq left-node (smpt-branch-descendent left-node (smpt-count left-node))))))
    (cond ((and (null right-node)
		(< index (smpt-count asc)))
	   (setq right-node (smpt-branch-descendent asc (1+ index)))
	   (dotimes (j i)
	     (declare (ignore j))
	     (setq right-node (smpt-branch-descendent right-node 0)))))))

(defwiredfun smpt-find-missing-range (vpn leaf-node index)
  (declare (values low-vpn n-pages))
  (let ((lnode leaf-node)
	(lindex (1- index))
	(rnode leaf-node)
	(rindex index))
    (when (minusp lindex)
      ;; On left end of node, find neighbor to left, if any.
      (loop doing (setq lnode (smpt-neighbors lnode))
	    while lnode until (plusp (smpt-count lnode)))
      (if lnode (setq lindex (1- (smpt-count lnode)))))
    (when ( rindex (smpt-count rnode))
      ;; On right end of node, find neighbor to right, if any.
      (loop doing (multiple-value-setq (nil rnode) (smpt-neighbors rnode))
	    while rnode until (plusp (smpt-count rnode)))
      (setq rindex 0))
    (let ((low-vpn (if lnode
		       (+ (smpt-leaf-vpn lnode lindex) (smpt-leaf-n-pages lnode lindex))
		       ;; No left neighbor, low-vpn must be 0.
		       0)))
      (values low-vpn
	      (if rnode
		  (- (smpt-leaf-vpn rnode rindex) low-vpn)
		  ;; No right neighbor, return psuedo-infinite n-pages
		  (+ (ldb %%smpt-leaf-n-pages -1) (- vpn low-vpn)))))))

(defwiredfun smpt-branch-lookup (node vpn)
  (declare (values descendent index found-p))
  (do ((l 0)
       (u (1- (smpt-count node)))
       i)
      ((> l u) (values (smpt-branch-descendent node l) l nil))
    (setq i (ldb (byte 31. 1.) (+ l u)))	;fast // 2.  Both small positive fixnums.
    (let ((vpn-i (smpt-branch-vpn node i)))
      (cond ((< vpn vpn-i)
	     (setq u (1- i)))
	    ((> vpn vpn-i)
	     (setq l (1+ i)))
	    (t
	     (return (values (smpt-branch-descendent node (1+ i)) i t)))))))

(defwiredfun smpt-branch-insert (node vpn descendent &optional (reverse-p nil))
  (if reverse-p
      (setf (smpt-branch-descendent node 0) (smpt-branch-descendent node 1))
      (if (> %smpt-branch-max (smpt-count node))
	  (incf (smpt-count node))))
  (let ((i (do ((n (if reverse-p 1 -1))
		(c (1- (smpt-count node)))
		(i (if reverse-p 0 (1- (smpt-count node))) (+ i n)))
	       ((if reverse-p
		    (or (= i c)
			(> (smpt-branch-vpn node (1+ i)) vpn))
		  (or (zerop i)
		      (< (smpt-branch-vpn node (1- i)) vpn)))
		i)
	     (setf (smpt-branch-vpn node i) (smpt-branch-vpn node (+ i n)))
	     (setf (smpt-branch-descendent node (1+ i))
		   (smpt-branch-descendent node (+ 1 i n))))))
    (setf (smpt-branch-vpn node i) vpn)
    (setf (smpt-branch-descendent node (1+ i)) descendent)))

;;; Similar to an insert, but instead pushes a new (VPN0,D0) instead of
;;; the normal (VPNi,D(1+ i))
(defwiredfun smpt-branch-push (node vpn descendent)
  (do ((i (smpt-count node) (1- i)))
      ((zerop i))
    (setf (smpt-branch-descendent node (1+ i)) (smpt-branch-descendent node i))
    (setf (smpt-branch-vpn node i) (smpt-branch-vpn node (1- i))))
  (setf (smpt-branch-descendent node 1) (smpt-branch-descendent node 0))
  (setf (smpt-ascendent descendent) node)
  (setf (smpt-branch-descendent node 0) descendent)
  (setf (smpt-branch-vpn node 0) vpn)
  (incf (smpt-count node)))

(defwiredfun smpt-leaf-lookup (node vpn)
  (declare (values entry-vpn entry-n-pages entry-dpn index))
  (do ((l 0)
       (u (1- (smpt-count node)))
       i)
      ((> l u) (return (values nil nil nil l)))	; VPN not found in node
    (setq i (ldb (byte 31. 1) (+ l u)))		;fast // 2.  Both small positive fixnums.
    (let ((vpn-i (smpt-leaf-vpn node i)))
      (cond ((< vpn vpn-i)
	     (setq u (1- i)))
	    ((> vpn (+ vpn-i (1- (smpt-leaf-n-pages node i))))
	     (setq l (1+ i)))
	    (t
	     (return (values (smpt-leaf-vpn node i)
			     (smpt-leaf-n-pages node i)
			     (smpt-leaf-dpn node i)
			     i)))))))

(defwiredfun smpt-leaf-insert (node vpn n-pages dpn &optional (reverse-p nil))
  (or reverse-p
      (if (> %smpt-leaf-max (smpt-count node))
	  (incf (smpt-count node))))
  (let* ((c (1- (smpt-count node)))
	 (i (do ((n (if reverse-p 1 -1))
		 (i (if reverse-p 0 c) (+ i n)))
		((if reverse-p
		     (or (= i c)
			 (> (smpt-leaf-vpn node (1+ i)) vpn))
		   (or (zerop i)
		       (< (smpt-leaf-vpn node (1- i)) vpn)))
		 i)
	      (setf (smpt-leaf-vpn-and-n-pages node i)
		    (smpt-leaf-vpn-and-n-pages node (+ i n)))
	      (setf (smpt-leaf-dpn node i) (smpt-leaf-dpn node (+ i n))))))
    ;; Plug in new value.
    (setf (smpt-leaf-vpn-and-n-pages node i)
	  (%logdpb n-pages %%smpt-leaf-n-pages
		   (dpb vpn %%smpt-leaf-vpn
			0)))
    (setf (smpt-leaf-dpn node i) dpn)))
) ;#-VLM

;;;; Interface functions

;;; Translate a physical address (as a fixnum) into the corrosponding virtual
;;; address (a fixnum).
(defun %pma-to-vma (pma)
  (declare (sys:safeguarded-function))
  "PMA (a fixnum)  VMA (a fixnum)"
  #+VLM
  pma
  #-VLM
  (if (progn #+3600 (= (ldb %%vma-equals-amem pma) %vma-equals-amem) #+IMach nil)
      ;; A-MEM address.  The PMA is also the VMA then.
      pma
      ;; Translate the PMA into a VMA
      (#+imach %funcall-in-aux-stack #+3600 %funcall-in-auxiliary-stack-buffer #+3600 t
       (lambda (pma)
	 (declare (sys:wired-function))
	 (with-storage-lock
	   (let ((mmpt-index (mmpt-lookup (ldb %%pma-page-num pma))))
	     (or mmpt-index
		 (wired-ferror nil "Invalid PMA ~O (octal)" pma))
	     (#+imach values #+3600 return-to-main-stack-buffer
	      (deposit-vpn (mmpt-vpn mmpt-index) pma)))))
       pma)))

;;; Translate a virtual address (as a fixnum) into the corrosponding physical
;;; MM address.  Returns the PMA with VMA=PMA stored in a fixnum.
;;; Returns NIL if VMA is not resident or PMA won't fit in a VMA=PMA address.
#+3600
(defun %vma-to-pma (vma)
  "VMA (a fixnum)  PMA (a fixnum with VMA=PMA set) or NIL if not resident"
  (if (= (ldb %%vma-equals-pma vma) %vma-equals-pma)	; VMA=PMA or A-MEM
      vma
      (%funcall-in-auxiliary-stack-buffer
	t
	#'(lambda (vma)
	    (declare (sys:wired-function))
	    (return-to-main-stack-buffer
	      (with-storage-lock
		(let ((pht-index (pht-lookup (extract-vpn vma))))
		  (and pht-index
		       (zerop (pht-pending pht-index))
		       (%logdpbs %vma-equals-pma %%vma-equals-pma
				 ;; %%VMA-PAGE-NUM to clear old vpn
				 (pht-ppn pht-index) %%vma-page-num vma))))))
	vma)))

;;; Combines parts of structure-wired-p and %vma-to-pma.  Returns a physical
;;; address (as a fixnum) if the address is resident and wired, otherwise NIL.
#+3600
(defun %vma-to-wired-pma (vma)
  "VMA (a fixnum)  PMA (a fixnum with VMA=PMA set) or NIL if not wired"
  (if (= (ldb %%vma-equals-pma vma) %vma-equals-pma)
      vma					;VMA=PMA or A-MEM
      (%funcall-in-auxiliary-stack-buffer
	t
	#'(lambda (vma)
	    (declare (sys:wired-function))
	    (return-to-main-stack-buffer
	      (with-storage-lock
		(let ((pht-index (pht-lookup (extract-vpn vma))))
		  (and pht-index
		       (let ((pht-entry (pht-entry pht-index)))
			 (and (zerop (ldb %%pht-entry-pending pht-entry))
			      (let* ((ppn (ldb %%pht-entry-ppn pht-entry))
				     (mmpt-index (mmpt-lookup ppn)))
				(and mmpt-index
				     (= (mmpt-status mmpt-index) %mmpt-status-wired)
				     (%logdpbs %vma-equals-pma %%vma-equals-pma
					       ;; %%VMA-PAGE-NUM to clear old vpn
					       ppn %%vma-page-num vma))))))))))
	vma)))

;;; Returns a DTP-PHYSICAL-ADDRESS to the word pointed to by VMA or NIL
#+Imach
(defwiredfun %vma-to-pma (vma)
  #+VLM
  (and (pht-lookup (extract-vpn (%pointer vma))) (%set-tag vma dtp-physical-address))
  #-VLM
  (progn
    (%set-trap-mode trap-mode-extra-stack)
    (setq vma (%pointer vma))
    (if (= (ldb %%vma-equals-pma vma) %vma-equals-pma)	; VMA=PMA
	(%make-physical-address (%logdpb 0 %%vma-equals-pma vma))
	(with-storage-lock
	  (let ((pht-index (pht-lookup (extract-vpn vma))))
	    (and pht-index
		 (zerop (pht-pending pht-index))
		 (%make-physical-address (%logdpb (pht-ppn pht-index) %%pma-page-num vma))))))
    ))

;;; Returns a DTP-PHYSICAL-ADDRESS to the word pointed to by VMA or NIL
#+Imach
(defwiredfun %vma-to-wired-pma (vma)
  #+VLM
  (and (pht-lookup (extract-vpn (%pointer vma))) (%set-tag vma dtp-physical-address))
  #-VLM
  (progn
    (%set-trap-mode trap-mode-extra-stack)
    (setq vma (%pointer vma))
    (if (= (ldb %%vma-equals-pma vma) %vma-equals-pma)	; VMA=PMA
	(%make-physical-address (%logdpb 0 %%vma-equals-pma vma))
	(with-storage-lock
	  (let ((pht-index (pht-lookup (extract-vpn vma))))
	    (and pht-index
		 (zerop (pht-pending pht-index))
		 (let* ((ppn (pht-ppn pht-index))
			(mmpt-index (mmpt-lookup ppn)))
		   (and mmpt-index
			(= (mmpt-status mmpt-index) %mmpt-status-wired)
			(%make-physical-address (%logdpb ppn %%pma-page-num vma))))))))))

;;; Callable on the normal stack, no inhibit-gc-flips required.
(defwiredfun wire-words (pointer n-words)
  (if (not (%auxiliary-stack-p))
      (%funcall-in-aux-stack #'wire-words pointer n-words)
    (when (plusp n-words)
      (let* ((address (%pointer pointer))
	     (from-vpn (extract-vpn address))
	     (to-vpn (extract-vpn (address-plus address n-words -1))))
	(wire-pages from-vpn (1+ (- to-vpn from-vpn)))))))

;;; Callable on the normal stack, no inhibit-gc-flips required.
(defwiredfun unwire-words (pointer n-words)
  (if (not (%auxiliary-stack-p))
      (%funcall-in-aux-stack #'unwire-words pointer n-words)
    (when (plusp n-words)
      (let* ((address (%pointer pointer))
	     (from-vpn (extract-vpn address))
	     (to-vpn (extract-vpn (address-plus address n-words -1))))
	(unwire-pages from-vpn (1+ (- to-vpn from-vpn)))))))

;;; Callable on the normal stack, no inhibit-gc-flips required.
(defwiredfun words-wired-p (pointer n-words)
  #+VLM
  ;; Perhaps the VLM will someday do something?
  (progn pointer n-words t)
  #-VLM
  (if (not (%auxiliary-stack-p))
      (%funcall-in-auxiliary-stack-buffer t #'words-wired-p pointer n-words)
    (when (plusp n-words)
      (let* ((address (%pointer pointer))
	     (from-vpn (extract-vpn address))
	     (to-vpn (extract-vpn (address-plus address n-words -1))))
	(#+3600 return-to-main-stack-buffer #+IMach values
	  (loop for vpn from from-vpn to to-vpn
		as pht-index = (pht-lookup vpn)
		as mmpt-index = (and pht-index (mmpt-lookup (pht-ppn pht-index)))
		always (and mmpt-index (= (mmpt-status mmpt-index) %mmpt-status-wired))))))))

;;; Must be called on auxiliary stack.
(defwiredfun wire-pages (base-vpn n-pages)
  #+VLM
  ;; Perhaps the VLM will someday advise the host to lock?
  (progn 
    (incf* *wire/unwire-tick*)
    (incf* (aref *zone-count-wired-pages* (ldb %%vpn-zone-num base-vpn))
	   n-pages)
    nil)
  #-VLM
  (enter-storage-system *ms-time-wiring-and-unwiring-pages*
    (loop repeat n-pages for vpn from base-vpn do
      (when (< (+ *count-flushable-pages* *count-normal-pages*) *unwired-min*)
	;; There aren't enough available frames to satisfy the request.  Unwire the
	;; ones we've already done and signal an error.
	(unwire-pages base-vpn (- vpn base-vpn))
	(wired-ferror nil "Trying to wire ~D pages but only ~D are available"
		      n-pages (+ *count-flushable-pages* *count-normal-pages*))
	;; Just in case the error's proceedable somehow.
	(return-from wire-pages))
      (let ((pht-index (pht-lookup vpn)))
	;; If we run into a nonresident page, prefetch it and all the remaining pages.
	(when (null pht-index)
	  (prefetch-pages-internal vpn (+ base-vpn n-pages) nil nil t)
	  (setq pht-index (pht-lookup vpn)))
	;; If the page is still nonresident (the prefetch above might screw up and swap
	;; if out, despite its best efforts), or if the page isn't idle, call the page
	;; fault handler to make the thing resident.  Note that just waiting for the
	;; page to be idle isn't enough because it might be on its way out.  We have
	;; to loop because the page fault handler can return with the page not actually
	;; resident (consider a fault on a pending page).
	(let ((vma (deposit-vpn vpn 0)))
	  (loop
	    (cond ((null pht-index)
		   (let ((wait-pht-index (pht-miss-handler vma)))
		     (when (not (null wait-pht-index))
		       ;; Disk done calls normalize which sets caches
		       (wait-for-page-idle vpn wait-pht-index))))
		  ((not (page-idle-p vpn pht-index))
		   (resident-page-fault vma %page-pht-miss pht-index))
		  (t (return)))
	    (setq pht-index (pht-lookup vpn))))
	(wire-frame (mmpt-lookup (pht-ppn pht-index)) pht-index))))
  nil)

;;; Must be called on auxiliary stack.
(defwiredfun unwire-pages (base-vpn n-pages)
  #+VLM
  ;; Perhaps the VLM will someday advise the host to (un)lock?
  (progn
    (decf* *wire/unwire-tick*)
    (decf* (aref *zone-count-wired-pages* (ldb %%vpn-zone-num base-vpn))
	   n-pages)
    nil)
  #-VLM
  ;; Doesn't need to call enter-storage-system since this can't cause a page-trace-insert
  (ms-time *ms-time-wiring-and-unwiring-pages*
    (with-storage-lock
      (with-quick-pht-accessors
	(loop repeat n-pages for vpn from base-vpn do
	  (let ((pht-index (pht-lookup vpn)))
	    (when (and (not (null pht-index)) (= (pht-pending pht-index) 0))
	      (unwire-frame (mmpt-lookup (pht-ppn pht-index)) pht-index)))))))
  nil)

#+VLM 
(defun wire-consecutive-words (vma n-words)
  (values vma n-words))

#-VLM (PROGN					;Kludge for PC-METERING
;;; Wire at least n-words in consecutive physical memory starting at the specified address.
;;; Doesn't need to be wired.  This is a normal stack entry point.
(defun wire-consecutive-words (vma n-words)
  ;; %funcall-in-aux-stack doesn't work for functions which return values.
  (%funcall-in-auxiliary-stack-buffer t
    (lambda (vma n-words)
      (declare (wired-function))
      (#+3600 return-to-main-stack-buffer #+IMach values
	(enter-storage-system *ms-time-wiring-and-unwiring-pages*
	  (wire-consecutive-words-handler vma n-words))))
    vma n-words))

;;; Must be called on the auxiliary stack.
;;; Wire at least n-words in consecutive physical addresses.  Return the physical
;;; address of the first word.
(defwiredfun wire-consecutive-words-handler (vma n-words)
  (setq vma (%pointer vma))
  (let* ((vpn (extract-vpn vma))
	 (n-pages (- (extract-vpn (address-plus vma n-words -1)) vpn -1))
	 first-ppn)
    (when (and (plusp n-words)
	       ;; No page in the vma range can already be wired.
	       (loop for vpn from vpn below (+ vpn n-pages)
		     as pht-index = (pht-lookup vpn)
		     never (and pht-index
				(= %mmpt-status-wired
				   (mmpt-status (mmpt-lookup (pht-ppn pht-index)))))))
      ;; First throw out any resident page in the VPN range
      (loop for vpn from vpn below (+ vpn n-pages)
	    as pht-index = (pht-lookup vpn)
	    doing (and pht-index (remove-page-internal (pht-ppn pht-index))))
      ;; Find a contiguous range of PPNs which can be removed.
      (loop with last-ppn = nil
	    and n-needed
	    for mmpt-index below *mmpt-size*
	    as ppn = (mmpt-index-to-ppn mmpt-index)
	    do
	    (cond ((and (eq last-ppn (1- ppn))
			(bit-member (mmpt-status mmpt-index) *normalizable-status*))
		   ;; Continuing found range
		   (decf n-needed)
		   (setq last-ppn ppn))
		  ((bit-member (mmpt-status mmpt-index) *normalizable-status*)
		   ;; Start of a new range
		   (setq n-needed (1- n-pages)
			 first-ppn ppn
			 last-ppn ppn))
		  (t (setq first-ppn nil)))
	    until (and n-needed (zerop n-needed)))
      (when first-ppn
	;; Found a contiguous range of PPNs
	;; Prefetch the vpns into the newly selected ppns.
	(loop for vpn from vpn below (+ vpn n-pages)
	      for ppn from first-ppn
	      as mmpt-index = (mmpt-lookup ppn)
	      do
	  ;; Remove the ppn's current page
	  (remove-page-internal ppn)
	  (prepare-frame mmpt-index vpn)
	  ;; Prefetch the vpn into the frame
	  (swap-prefetch vpn mmpt-index nil))
	;; Wait for the prefetches to complete
	(wait-for-disk-done)
	;; And then wire all the pages.
	(wire-pages vpn n-pages)
	;; Finally, return the physical address
	(%make-pointer dtp-locative (%logdpbs %vma-equals-pma %%vma-equals-pma
					      first-ppn %%pma-page-num
					      (ldb %%vma-word-offset (%pointer vma))))))))
); #-VLM

;;; Must be called on auxiliary stack.
#+IMach
(defwiredfun wire-stack-pages (base-vpn wire-n-pages create-n-pages)
  #+VLM
  ;; Perhaps the VLM will someday advise the host to lock the pages?
  (when (plusp create-n-pages)
    (create-pages (deposit-vpn (+ base-vpn wire-n-pages) 0) (deposit-vpn create-n-pages 0)))
  #-VLM
  (enter-storage-system *ms-time-wiring-and-unwiring-stack-pages*
    (loop repeat (+ wire-n-pages create-n-pages) for vpn from base-vpn do
      (let ((pht-index (pht-lookup vpn)))
	;; If we run into a nonresident page, prefetch it and all the remaining pages.
	(when (and (null pht-index) (< vpn (+ base-vpn wire-n-pages)))
	  (prefetch-pages-internal vpn (+ base-vpn wire-n-pages) nil nil t)
	  (setq pht-index (pht-lookup vpn)))
	;; If the page is still nonresident (the prefetch above might screw up and swap
	;; if out, despite its best efforts), or if the page isn't idle, call the page
	;; fault handler to make the thing resident.  Note that just waiting for the
	;; page to be idle isn't enough because it might be on its way out.  We have
	;; to loop because the page fault handler can return with the page not actually
	;; resident (consider a fault on a pending page).
	(let ((vma (deposit-vpn vpn 0)))
	  (loop
	    (cond ((null pht-index)
		   (cond ((< vpn (+ base-vpn wire-n-pages))
			  (let ((wait-pht-index (pht-miss-handler vma)))
			    (when (not (null wait-pht-index))
			      ;; Disk done calls normalize which sets caches
			      (wait-for-page-idle vpn wait-pht-index))))
			 (t
			  ;; This is one of the createable pages, so we don't need to go to the disk.
			  (create-page-in-frame (find-frame create-n-pages t) vpn)
			  ;; Initialize the storage to avoid double-bit-errors.
			  (%block-store-tag-and-pointer vma page-size dtp-null vma 1))))
		  ((not (page-idle-p vpn pht-index))
		   (resident-page-fault vma %page-pht-miss pht-index))
		  (t (return)))
	    (setq pht-index (pht-lookup vpn))))
	(wire-frame (mmpt-lookup (pht-ppn pht-index)) pht-index)
	;; The processor must never fault while scrolling the stack cache, so if
	;; sysout is enabled, defeat it to prevent write-first faults.
	(when *sysout-enabled-p*
	  (setf (sysout-bitmap vpn) t)
	  (setf (pht-modified pht-index) 1)
	  (setf (pht-write-protect pht-index) 0)
	  (cache-remove (deposit-vpn vpn 0))))))
  nil)

;;; Must be called on auxiliary stack.
#+IMach
(defwiredfun unwire-stack-pages (base-vpn unwire-n-pages evict-n-pages)
  #+VLM
  ;; Perhaps the VLM will someday advise the host to (un)lock?
  (progn base-vpn unwire-n-pages evict-n-pages nil)
  #-VLM
  ;; Doesn't need to call enter-storage-system since this can't cause a page-trace-insert
  (ms-time *ms-time-wiring-and-unwiring-stack-pages*
    (with-storage-lock
      (with-quick-pht-accessors
	(loop repeat (+ unwire-n-pages evict-n-pages) for vpn from base-vpn do
	  (let ((pht-index (pht-lookup vpn)))
	    (when (and (not (null pht-index)) (= (pht-pending pht-index) 0))
	      (unwire-frame (mmpt-lookup (pht-ppn pht-index)) pht-index))))
	#+ignore
	(loop repeat evict-n-pages for vpn from (+ base-vpn unwire-n-pages) do
	  (let ((pht-index (pht-lookup vpn)))
	    (when (and (not (null pht-index)) (= (pht-pending pht-index) 0))
	      (let ((mmpt-index (mmpt-lookup (pht-ppn pht-index))))
		(setf (pht-modified pht-index) 0)
		(unwire-frame mmpt-index pht-index)
		(when ( (mmpt-status mmpt-index) %mmpt-status-wired)
		  (flush-frame mmpt-index pht-index t)))))))))
  nil)


;;;; Read-Only facility

;;; Must be called on the auxiliary stack.  If READ-ONLY-P is true write protects all resident
;;; pages in the word range.  Otherwise unprotects all resident pages in the range.
;;; Doesn't change the region information, so access modification only lasts while resident.
(defwiredfun set-words-read-only (vma n-words &optional (read-only-p t))
  (let ((write-protect (if read-only-p 1 0))
	(vma (%pointer vma)))
    (loop for vpn from (extract-vpn vma)
		  to   (extract-vpn (address-plus vma n-words -1))
	  do
      (let ((pht-index (pht-lookup vpn)))
	(when (and pht-index (= (pht-pending pht-index) 0))
	  ;; Page is assigned to a main memory frame with a different protection
	  #+3600 (let ((mmpt-index (mmpt-lookup (pht-ppn pht-index))))
		   (when ( (mmpt-write-protect mmpt-index) write-protect)
		     (setf (mmpt-write-protect mmpt-index) write-protect)
		     (cache-remove (deposit-vpn vpn 0))))
	  #+IMach (when ( (pht-write-protect pht-index) write-protect)
		    (setf (pht-write-protect pht-index) write-protect)
		    (cache-remove (deposit-vpn vpn 0))))))))

;;; Must be called on the auxiliary stack.
;;; This is a brute-force way to get the caches consistent after %PERMIT-READ-ONLY.
;;; Use recompute-from-first-principles-p to force recomputation of the write-protect
;;; bits from the sysout map and region tables.
(defwiredfun recompute-read-only-bits (&optional recompute-from-first-principles-p)
  (let ((sysout-enabled-p *sysout-enabled-p*)
	(*sysout-bitmaps* *sysout-bitmaps*))
    (declare (zl:unspecial *sysout-bitmaps*))
    #+VLM
    (dotimes (region (si:n-regions))
      (unless (eq (ldb %%region-space-type (region-bits region)) %region-space-free)
	(when (ldb-test %%region-read-only (region-bits region))
	  ;; --- Bleah, this needs a co-proc op to quickly set them
	  (loop for vpn upfrom (extract-vpn (region-origin region))
		repeat (ceiling-page-size (region-free-pointer region))
		do (vm-write-attribute write-fault (vm-lookup vpn) t)))
	))
    #-VLM
    (macrolet ((compute-write-protect (vpn)
		 `(cond ((and sysout-enabled-p (not (sysout-bitmap ,vpn)))
			 1)
			((let ((region (%region-number (deposit-vpn ,vpn 0))))
			   (and region (ldb-test %%region-read-only (region-bits region))))
			 1)
			(t 0))))
      #+3600
      (with-quick-mmpt-accessors
	(loop for mmpt-index below *mmpt-size* do
	  (let ((mmpt-entry (mmpt-entry mmpt-index)))
	    (when (= (mmpt-entry-invalid-vpn mmpt-entry) 0)
	      (let ((vpn (mmpt-entry-vpn mmpt-entry)))
		(when (and ( (mmpt-entry-write-protect mmpt-entry) 0)
			   ( (mmpt-entry-modified mmpt-entry) 0))
		  (cache-remove (deposit-vpn vpn 0)))
		(when recompute-from-first-principles-p
		  (setf (mmpt-entry mmpt-index)
			(dpb (compute-write-protect vpn)
			     %%mmpt-write-protect
			     mmpt-entry))))))))
      #+IMach
      (si:saving-registers-for-effect (%register-bar-1)
	(setf (%block-register 1) *pht-base*)
        (loop repeat *pht-size* do
	  (let ((pht0 (%block-read 1 :fixnum-only t :set-cdr-next nil))
		(pht1 (%block-read 1 :fixnum-only t :set-cdr-next nil)))
	    (unless (= (pht0-vpn pht0) %pht0-invalid-vpn)
	      (when* (or recompute-from-first-principles-p
			 (zerop (ldb %%pht1-write-protect pht1)))	;write enabled
		(%p-dpb (compute-write-protect (pht0-vpn pht0))
			%%pht1-write-protect
			(%pointer-plus (%block-register 1) -1))))))
	(%clear-map-cache))))
  nil)

;;; Must be called on the auxiliary stack.
(defwiredfun %inhibit-read-only ()
  (incf *inhibit-read-only-in-progress*))

;;; Must be called on the auxiliary stack.
(defwiredfun %permit-read-only ()
  (unless (plusp *inhibit-read-only-in-progress*)
    (wired-ferror nil "%PERMIT-READ-ONLY called without matching %INHIBIT-READ-ONLY."))
  (decf *inhibit-read-only-in-progress*)
  (when (zerop *inhibit-read-only-in-progress*)
    (with-storage-lock
      (if (< *read-only-n-written-pages* %read-only-written-pages-size)
	  (dotimes (i *read-only-n-written-pages*)
	    #+3600 (cache-remove (deposit-vpn (mmpt-vpn (aref *read-only-written-pages* i)) 0))
	    #+IMach (let ((vpn (mmpt-vpn (aref *read-only-written-pages* i))))
		      (setf (pht-write-protect (pht-lookup vpn)) 1)
		      (cache-remove (deposit-vpn vpn 0))))
	(recompute-read-only-bits)))
    (setf *read-only-n-written-pages* 0)))

;;; Turn on sysout accounting.
#-VLM						;for now
(defwiredfun enable-sysout ()
  (when (not *sysout-enabled-p*)
    (if (not (%auxiliary-stack-p))
	(%funcall-in-aux-stack #'enable-sysout)
      (with-storage-lock
	(when (null *sysout-bitmaps*)
	  (setq *sysout-bitmaps* (create-dynamic-array art-q %number-of-bitmaps)))
	(dotimes (i %number-of-bitmaps)
	  (let ((sysout-map (aref *sysout-bitmaps* i))
		(load-map (aref *load-bitmaps* i)))
	    (when (not (null load-map))
	      (let ((map-size (#+3600 array-normal-length-field #+IMach length load-map)))
		(when (or (null sysout-map)
			  ( (#+3600 array-normal-length-field #+IMach length sysout-map)
			     map-size))
		  (setf (aref *sysout-bitmaps* i)
			(setq sysout-map (create-dynamic-array art-boolean map-size))))
		(dotimes (j map-size)
		  ;; If it isn't still in the load bitmap, have to assume it is modified.
		  (setf (aref sysout-map j)
			(or (not (aref load-map j))
			    ;; This code protects us from write-protecting wired stack pages.
			    #+imach
			    (let ((pht-index (pht-lookup (dpb i %%vpn-bitmap-num j))))
			      (and pht-index (not (zerop (pht-modified pht-index))))))))))))
	(setq *sysout-enabled-p* t *enable-sysout-at-cold-boot* t)
	(recompute-read-only-bits t)))))

;;; Turn off sysout accounting.
#-VLM						;for now
(defwiredfun disable-sysout ()
  (when *sysout-enabled-p*
    (if (not (%auxiliary-stack-p))
	(%funcall-in-aux-stack #'disable-sysout)
      (with-storage-lock
	(setq *sysout-enabled-p* nil *enable-sysout-at-cold-boot* nil)
	(recompute-read-only-bits t)))))

#-VLM
(defwiredfun map-over-load-map-entries (function)
  (declare (sys:downward-funarg function))
  "Function gets called with 4 arguments: index, vpn, dpn, npages"
  (dotimes (index load-map-size)
    (funcall function index
	     (load-map-vpn index) (load-map-dpn index) (load-map-n-pages index))))

;;; Create a new page full of pointer traps.
;;; Called by CONS when the free pointer crosses a page boundry.
;;; Numerous speedups can be made here later.  Can optimize out prepare-frame
;;; and normalize-frame though the savings isn't major there.  Maybe work a page
;;; ahead, sort of a new page queue, so just have to plop in vpn.
;;; This is really just wired to avoid a page fault during ms-time
#-VLM
(defwiredfun create-pages (vma n-words)
  (declare (unsafeguarded-reference dbg:check-arg-1 n-words))
  (zl:check-arg n-words plusp "A positive number")
  (cond (storage-exists		;This will get called even if it storage isn't initialized
	 (%funcall-in-aux-stack
	   (lambda (vma n-words)
	     (let ((from-vpn (extract-vpn (address-plus vma page-size -1)))
		   (to-vpn (extract-vpn (address-plus vma n-words -1))))
	       (enter-storage-system *ms-time-create-pages*
		 (create-page-range from-vpn (1+ (- to-vpn from-vpn))))))
	   vma n-words))
	(t
	 ;; Initialize all the storage to make sure we don't get double-bit-errors
	 ;; because lots of things use %P-STORE-CONTENTS and the like.
	 ;; Must clear specified region and up to the next page boundary, since won't get
	 ;; called again for small allocations within the same page.
	 (%block-store-tag-and-pointer
	   vma
	   (address-difference (logior (address-plus vma n-words -1) (1- page-size)) vma -1)
	   dtp-null vma 1)))
  t)

#+VLM
(defwiredfun create-pages (vma n-words)
  (declare (unsafeguarded-reference dbg:check-arg-1 n-words))
  (zl:check-arg n-words plusp "A positive number")
  (let ((requested (extract-vpn n-words)))
    (%set-min-trap-mode trap-mode-extra-stack)
    (prog1
      (loop do
	(unless ( *count-remaining-swap-pages* requested)
	  (wired-ferror
	    :proceedable-halt
	    "About to exceed requested virtual image size.  Type :Continue to proceed."
	    )
	  ;; Increment by a random amount --- later let the FEP
	  ;; specify an amount?
	  (let ((increment (floor *count-swap-pages* 4)))
	    (incf *count-remaining-swap-pages* increment)
	    (incf *count-swap-pages* increment)))
	(let ((allocated (with-vm-coprocessor
			   (setf (vm-register address) vma
				 (vm-register extent) n-words)
			   ;; This creates pages with no faults enabled.  Flip and
			   ;; %allocate-transport-block enable transport faults
			   (vm-command create 0)
			   (and (vm-reply) (vm-register extent)))))
	  (if (and allocated ( (extract-vpn allocated) requested))
	      (return t)
	      (wired-ferror
		:proceedable-halt
		"Unable to grow virtual image.  Use /sbin/swapon to add paging and type :Continue to proceed."
		))))
      (decf *count-remaining-swap-pages* requested)
      (incf* *count-created-pages* requested))))



;;; This has to be non-interruptible, even from sequence-breaks, since a window
;;; exists between the pht-lookup determining the page isn't resident and
;;; create-page-in-frame making it be so.
;;; Note that it isn't important if the page exists on disk since that would mean
;;; the free pointer has been bumped down, releasing space.  If we allocate a new
;;; memory page, it will merely overwrite the old disk page.  However, we must check
;;; to see if the page is extant, else multiple MM frames would contain the same page.
(defwiredfun create-page-range (base-vpn n-pages)
  #+VLM
  (create-pages (deposit-vpn base-vpn 0) (deposit-vpn n-pages 0))
  #-VLM
  (let ((bound-vpn
	  (multiple-value-bind (dpn base-dpn n-pages)
	      (smpt-create base-vpn)
	    (+ base-vpn (- (+ base-dpn n-pages) dpn)))))
    (loop for remaining downfrom n-pages above 0
	  for vpn from base-vpn
	  as vma = (deposit-vpn vpn 0)
	  do
      (when *sysout-enabled-p*
	;; Newly created pages (in the load map range) count as modified.
	(setf (sysout-bitmap vpn) t))
      (if (not (null (pht-lookup vpn)))		;+++ shouldn't need this
	  ;; Just initialize the storage.
	  (%block-store-tag-and-pointer vma page-size dtp-null vma 1)
	;; Page isn't resident.  Create a new one.
	(incf* *count-created-pages*)
	;; Don't want the load copy anymore.
	(load-bitmap vpn (setf (aref map index) nil))
	;; The SMPT entry must be created prior to finding a frame to create the
	;; page in.  Otherwise, smpt-create could use the same frame if it makes
	;; a new node, ending up in the smpt node getting swapped out.
	(when ( vpn bound-vpn)
	  (multiple-value-bind (dpn base-dpn n-pages)
	      (smpt-create vpn)
	    (setq bound-vpn (+ vpn (- (+ base-dpn n-pages) dpn)))))
	(let* ((mmpt-index (find-frame remaining t))
	       (pht-index (prepare-frame mmpt-index vpn)))
	  ;; If flush-writing, the VPN will be pending.  Must wait for the flush-write to
	  ;; complete before trying to normalize the frame.
	  (wait-until-frame-prepared pht-index)
	  ;; Mark page as modified, since we're about to modify it anyway.
	  #+3600 (setf (mmpt-modified mmpt-index) 1)
	  #+IMach (setf (pht-modified pht-index) 1)
	  (normalize-frame mmpt-index pht-index)
	  ;; Initialize the storage to avoid double-bit-errors in case of %P-STORE-CONTENTS,
	  ;; etc.  Then turn off the gc page tag, which could have been turned on by
	  ;; initializing storage.  This saves an unnecessary call to GC-PAGE-OUT later if
	  ;; this page is in ephemeral space.
	  (%block-store-tag-and-pointer vma page-size dtp-null vma 1)
	  #+3600 (%gc-tag-write (deposit-ppn (pht-ppn pht-index) 0) nil)
	  #+IMach (when (= (ldb %%vpn-zone-num vpn) %ephemeral-zone)
		    ;; Don't reset this to zero unconditionally, since we want to leave it
		    ;; set to #b1111 if it's a binding stack.
		    (setf (pht-ephemeral-reference pht-index) 0))
	  #+IMach (cache-remove vma)
	  (when *page-trace-array*
	    (page-trace-insert %page-trace-create-page vma)))))))

;;; Get rid of this section of address space.  
;;; Turn off the load-bitmap bits so create-pages won't get confused,
;;; mark whole contained pages as invalid so (at least) %permit-read-only won't
;;; get confused, and move the pages from the smpt back into the swap map.
#-VLM
(defun destroy-pages (vma n-words)
  (declare (safeguarded-function))
  (let ((from-vpn (extract-vpn (address-plus vma page-size -1)))
	(to-vpn (extract-vpn (address-plus vma n-words -1))))
    (%funcall-in-auxiliary-stack-buffer nil
      #'destroy-page-range from-vpn (1+ (- to-vpn from-vpn)))))

#+VLM
(defun destroy-pages (vma n-words)
  (declare (safeguarded-function))
  (let ((destroyed (with-vm-coprocessor
		     (setf (vm-register address) vma
			   (vm-register extent) n-words)
		     (vm-command destroy)
		     ;; --- should equal n-words
		     (and (vm-reply) (vm-register extent)))))
    (when destroyed
      (incf *count-remaining-swap-pages* (extract-vpn destroyed)))))

;;; Must be called on the aux stack.
#-VLM
(defwiredfun destroy-page-range (base-vpn n-pages)
  (enter-storage-system *ms-time-destroy-pages*
    ;; Remove all resident pages in range.
    (loop repeat n-pages for vpn from base-vpn do
      ;; If the page is resident, remove it without writing it out if modified.
      #+3600 (let ((ppn (or (let ((tmp (%physical-address-cache (deposit-vpn vpn 0))))
			      (and tmp (extract-ppn tmp)))
			    (let ((pht-index (pht-lookup vpn)))
			      (and pht-index (pht-ppn pht-index))))))
	       (when (not (null ppn))
		 (remove-frame (mmpt-lookup ppn) nil t)))
      #+IMach (let ((pht-index (pht-lookup vpn)))
	       (when (not (null pht-index))
		 (remove-frame (mmpt-lookup (pht-ppn pht-index)) pht-index nil t)))
      ;; Make sure the page isn't in the load map any more.
      (load-bitmap vpn
	(setf (aref map index) nil))
      ;; Also don't need to sysout the page anymore as well.
      (when *sysout-enabled-p*
	(setf (sysout-bitmap vpn) nil)))
    ;; Now destroy the page entries in the ESRT
    (esrt-delete-range base-vpn (+ base-vpn n-pages))
    ;; Now destroy the page entries in the SMPT
    (smpt-destroy base-vpn n-pages))
  #+3600 (%resume-main-stack-buffer))

;;; Set the value of *LOAD-PAGES-TO-SWAP-AREA-P*.  Note the special stuff
;;; done if changing from NIL to T.
#-VLM						;for now
(defwiredfun set-*LOAD-PAGES-TO-SWAP-AREA-P* (t-or-nil)
  "Can be called from either stack."
  (cond ((not (%auxiliary-stack-p))
	 (%funcall-in-aux-stack #'set-*LOAD-PAGES-TO-SWAP-AREA-P* t-or-nil))
	((not t-or-nil)
	 ;; turning off migration.  Everything in main memory is fine.  Just set it.
	 (setq *LOAD-PAGES-TO-SWAP-AREA-P* t-or-nil))
	(t
	 ;; Turning on migration.  Have to make sure all pages in main
	 ;; memory will go to the swap map.  This combines parts of
	 ;; swap-fetch-1 and fetch-load-complete.
	 (setq *LOAD-PAGES-TO-SWAP-AREA-P* t-or-nil)
	 (dotimes (mmpt-index *mmpt-size*)
	   (let* ((vpn (mmpt-vpn mmpt-index)))
	     (load-bitmap vpn
	       (when (swap-read-lookup vpn)
		 ;; set the modified bit so it will get written and turn
		 ;; off the *load-bitmap* bit.
		 (when (zerop (mmpt-invalid-vpn mmpt-index))
		   #+3600 (setf (mmpt-modified mmpt-index) 1)
		   #+IMach (setf (pht-modified (pht-lookup vpn)) 1))
		 (setf (aref map index) nil)
		 ;; finally assign it some swap space (do this last so it
		 ;; doesn't accidentally kick out the page we are looking
		 ;; at in case the SMPT has to grow.
		 (swap-write-lookup vpn))))))))



;; This is pretty meaningless for the VLM, but we still need to make
;; sure it never gets turned on!
#-VLM (PROGN

;;;; Page tracing

(defun flush-all-main-memory-pages ()
  (without-interrupts				;not very useful otherwise
    (%funcall-in-aux-stack #'write-all-modified-pages)	;goes much faster after this
    (%funcall-in-aux-stack #'remove-all-pages)))

(defsubst page-trace-index (array)
  (array-leader array 1))

;;; ARRAY can be NIL to turn off tracing, or an array with a leader-length of two
(defun page-trace (array)
  (when array
    (if (< (array-leader-length array) 2)
	(error "~S should have a leader length of 2 to be a page trace array" array))
    (or (si:structure-wired-p array)
	(error "~S must be wired" array))
    (setf (fill-pointer array) (length array))
    (setf (page-trace-index array) 0))
  (setq *page-trace-array* array))

(defwiredfun page-trace-open (start-time)
  (when (zerop *page-trace-in-progress*)
    (setq *page-trace-start-time* start-time
	  *page-trace-first-done* nil))
  (incf* *page-trace-in-progress*))

#+ignore ;#+imach
(defwiredvar *page-fault-high-pc* nil)
#+ignore ;#+imach
(defwiredfun page-fault-pcs ()
  (values #'page-fault
	  (or *page-fault-high-pc*
	      (setq *page-fault-high-pc*
		    (with-system-block-registers (1)
		      (setf (%block-register 1) #'page-fault)
		      (loop until (= (ldb %%q-cdr-code-within-tag
					  (%tag (%block-read 1 :cycle-type %memory-scavenge
							       :set-cdr-next nil)))
				     sequencing-fence))
		      (%pointer-plus (%block-register 1) -1))))))

(defwiredfun page-trace-appropriate-pc ()
  #+3600
  (let ((pc %other-pc))
    (cond ((or (= 0 (%pointer-difference pc restart-trapped-call-escape-pc))
	       (= 7 (%pointer-difference pc #'si:%funcall-in-aux-stack)))
	   (frame-return-pc %other-frame-pointer))
	  (t
	   pc)))
  #+imach *page-fault-program-counter*)

(defwiredfun page-trace-insert-open ()
  (let* ((array *page-trace-array*)
	 (index (page-trace-index array))
	 (max (fill-pointer array)))
    (cond ((< (+ index 3) max)			;Must have room for minimum entry.
	   (setf (aref array index) (page-trace-appropriate-pc))
	   (setf (aref array (incf index)) *page-trace-start-time*)
	   (setf (page-trace-index array) (1+ index))
	   (setq *page-trace-first-done* t))
	  (t (setq *page-trace-array* nil)))))

(defwiredfun page-trace-close ()
  (when (and (zerop (decf* *page-trace-in-progress*))
	     *page-trace-first-done*)
    (if metering:*new-page-fault-metering*
	(metering:define-wired-metering-point (page-fault-end
						*page-fault-end-metering-trigger*
						*enable-metering-on-page-fault*)
					      (starting-time faulting-pc)
	  *page-trace-start-time*
	  (page-trace-appropriate-pc))
	(let* ((array *page-trace-array*)
	       (index (page-trace-index array))
	       (max (fill-pointer array)))
	  (cond ((< index max) 
		 (setf (aref array index)
		       #+3600 (%logdpb %page-trace-end (byte 04 34)
				       (wired-time-difference (%microsecond-clock)
							      *page-trace-start-time*))
		       #+imach (%set-tag (wired-time-difference (%microsecond-clock)
								*page-trace-start-time*)
					 (dpb %page-trace-end (byte 4 0)
					      dtp-packed-instruction-60)))
		 (setf (page-trace-index array) (1+ index)))
		(t (setq *page-trace-array* nil)))))))

;;; Internal routine to record the page trace information
(defwiredfun page-trace-insert (trace-type vma)
  (when (zerop *page-trace-in-progress*)
    (wired-ferror :fatal "Inserting a page trace entry on a closed trace array."))
  (if metering:*new-page-fault-metering*
      (progn
	(setq *page-trace-first-done* 't)
	(metering:define-wired-metering-point (page-fault
						*page-fault-metering-trigger*
						*enable-metering-on-page-fault*)
					      (trace-type vma)
	  trace-type
	  vma))
      (unless *page-trace-first-done*
	(page-trace-insert-open))
      (let ((array *page-trace-array*))
	(when array				;Could have been nullified
	  (when (bit-member trace-type *page-trace-enables*)
	    (let ((index (page-trace-index array))
		  (max (fill-pointer array)))
	      (cond ((< index max)
		     (setf (aref array index)
			   #+3600 (%logdpb trace-type (byte 04 34) vma)
			   #+imach (%set-tag vma
					     (dpb trace-type (byte 4 0)
						  dtp-packed-instruction-60)))
		     (setf (page-trace-index array) (1+ index)))
		    (t (setq *page-trace-array* nil)))))))))


;;;; SET-MEMORY-SIZE

(defwiredfun aux-set-memory-size (n-pages)
  (with-storage-lock
    (cond ((> *count-usable-pages* n-pages)
	   ;; Shrink memory to the specified number of pages
	   (loop for mmpt-index below *mmpt-size*
		 as status = (mmpt-status mmpt-index)
		 as ppn = (mmpt-index-to-ppn mmpt-index)
		 while (> *count-usable-pages* n-pages)
		 unless (or (null ppn)
			    (= status %mmpt-status-wired)
			    (= status %mmpt-status-frame-error))
		   do (remove-page-internal ppn t)))
	  ((< *count-usable-pages* n-pages)
	   ;; Grow memory to the specified number of pages
	   (loop for mmpt-index below *mmpt-size*
		 while (< *count-usable-pages* n-pages)
		 do
	     (when (= (mmpt-status mmpt-index) %mmpt-status-frame-error)
	       (alter-mmpt mmpt-index *mmpt*
			   invalid-vpn 1	; Just in case
			   status %mmpt-status-flushable)
	       (flushable-enqueue mmpt-index t)
	       ;; GC page tag must be off for invalid pages
	       #+3600 (%gc-tag-write (deposit-ppn (mmpt-index-to-ppn mmpt-index) 0) nil)
	       (incf* *count-usable-pages*)
	       (incf* *count-flushable-pages*)))))))

(defun set-memory-size (n-pages)
  (%funcall-in-aux-stack #'aux-set-memory-size n-pages))

) ;#-VLM


;;;; Disk interface

#+3600 (progn

(defwiredfun disk-enqueue-page-read (class dpn ppn)
  (si:disk-enq-page-read class dpn ppn))

(defwiredfun disk-enqueue-page-write (class dpn ppn)
  (si:disk-enq-page-write class dpn ppn))

(defwiredfun disk-enqueue-wakeup () (si:aux-disk-enq-wakeup nil))

(defwiredfun disk-enqueue-background-page-write (class dpn ppn)
  (si:disk-enq-background-page-write class dpn ppn))

(defwiredfun disk-background-space-p () (si:disk-background-space-p))
(defwiredfun disk-background-full-p () (si:disk-background-full-p))
(defwiredfun disk-background-delete (ppn) (si:disk-background-delete ppn))
(defwiredfun disk-background-promote-all () (si:disk-background-promote-all))

(defwiredfun disk-background-geometry (dpn)
  ;; BATCH-P indicates that contiguous transfers are very desirable for that unit, so VM
  ;; should attempt to make its transfers contiguous even at the expense of doing some extra
  ;; work (such as writing out a resident unmodified page that lies between two modified
  ;; pages on disk).  This should be T for disks with unnatural sector sizes, and probably T
  ;; for G-machines.
  (declare (values base-dpn n-pages batch-p))
  (let* ((unit (ldb %%dpn-unit dpn))
	 (sectors/track (si:disk-n-pages-per-track unit))
	 (sectors/cylinder (si:disk-n-pages-per-cylinder unit)))
    (multiple-value-bind (cylinder remainder)
	(floor (ldb %%dpn-page-num dpn) sectors/cylinder)
      (multiple-value-bind (track sector)
	  (floor remainder sectors/track)
	(declare (ignore sector))
	(values (sys:%logdpb unit
			     %%dpn-unit
			     (+ (* cylinder sectors/cylinder) (* track sectors/track)))
		sectors/track
		;; NBS performs better with blocked writes.
		(eq *io-board-type* :nbs))))))
)

;;; Currently there is no I-machine disk system, and the toy disk driver implements
;;; the full disk protocol.


;;;;; ECC Facility

;; --- Make sure the scrubber never starts on VLM
#-VLM (PROGN

#+IMach
;; Find the next valid ppn after this one by looking in the mmpt tables
(defun next-ppn (ppn)
  (declare (values new-ppn))
  (loop as new-offset = (1+ (ldb %%ppn-mmpt-x ppn))
	as new-mmpt-y = (ldb %%ppn-mmpt-y ppn)
	;; check for oveflow to next quantum
	unless (zerop (ldb %%ppn-mmpt-y new-offset))
	  do (loop with limit = (length *mmpt-y*)
		   for y first (1+ new-mmpt-y) then (1+ y)
		   when ( y limit)
		     do (setq y 0)
		   until ( (mmpt-y-entry-valid (mmpt-y-entry y)) 0)
		   finally (setq new-mmpt-y y
				 new-offset 0))
	do (setq ppn (dpb new-mmpt-y %%ppn-mmpt-y new-offset))
	while (let ((index (mmpt-lookup ppn)))
		(or
		  ;; invalid frames may not be initialized
		  ( (mmpt-invalid-vpn index) 0)
		  ;; skip bad pages (they either don't exist or are broken)
		  (select (mmpt-status index)
		    ((%mmpt-status-frame-error %mmpt-status-data-error) t))))
	finally (return ppn)))

#+IMach
(defwiredfun initialize-ecc-log ()
  (setf *ecc-log-counter* 0)
  (setf *ecc-log-ptr* -1)
  (setf *ecc-notification-on* nil)
  (dotimes (i *ecc-log-size*)
    (setf (aref *ecc-error-log* i) 0)))

#+IMach
(defwiredfun check-for-memory-ecc-error (&optional scanning-ppn)
  (declare (values log-address-if-errors-lost))
  (multiple-value-bind (ecc-log ecc-log-address ecc-lost)
      (memory-ecc-error)
    (when ecc-log
      (log-memory-ecc ecc-log ecc-log-address scanning-ppn)	;log the error 
      (when *ecc-notification-on*
	(si:aux-process-wakeup *ecc-process*)))
    ;; return next address to scan
    (when ecc-lost ecc-log-address)))

#+IMach
;; check registers for new ecc error.  return info contained in
;; %REGISTER-ECC-LOG and %REGISTER-ECC-LOG-ADDRESS, respectively, if
;; there is an error, otherwise return nil
(defwiredfun memory-ecc-error()
  (declare (values log address lost-p))
  (let* ((ecc-log-address (%read-internal-register %register-ecc-log-address))
	 (ecc-log (%read-internal-register %register-ecc-log)))
    (when (ldb-test %%ecc-log-error-occurred ecc-log)
      (values ecc-log
	      ecc-log-address
	      (ldb-test sys:%%ecc-log-error-lost ecc-log)))))

#+IMach
;; PHT-REMOVE will call this before the page is removed lest we lose the
;; translation of an error
(defwiredfun log-memory-ecc (ecc-log ecc-log-address &optional scanning-ppn)
  (let ((index)
	(ecc-physical-address)
	(ecc-ppn (extract-ppn ecc-log-address)))
    ;; determine if virtual or physical address -- do we care?
    (cond ((eql (extract-ppn ecc-log-address) scanning-ppn)
	   (setf ecc-physical-address ecc-log-address)
	   ;; a (non-fatal) error in a page the scrubber was scanning
	   (let ((pma (%make-physical-address ecc-log-address)))
	     ;; re-write the corrected data
	     (%memory-write pma
			    (%memory-read pma :cycle-type %memory-raw :set-cdr-next nil))
	     ;; let the cache know what you did
	     (cache-purge ecc-log-address 1)
	     ;; see how you did
	     (compiler::for-effect
	       (%read-internal-register %register-ecc-log)	;flush read error
	       (%memory-read pma :cycle-type %memory-raw :set-cdr-next nil))
	     (setf (ldb %%ecc-log-access-mask ecc-log)
		   (if (ldb-test %%ecc-log-error-occurred
				 (%read-internal-register %register-ecc-log))
		       ecc-error-stuck
		       ecc-error-repaired))
	     ;; The scrubber can often encounter more than one error,
	     ;; but it always backs up to the last error and continues,
	     ;; son don't log the additional errors
	     (setf (ldb-test %%ecc-log-error-lost ecc-log) nil)
	     ))	   
	  ;; Not clear if we should try to fix any of these (errors that
	  ;; occurred other than by scrubbing).  For now, we just record
	  ;; and ignore them, assuming the scrubber will get to them
	  ;; eventually.  We assume access was virtual by default; the
	  ;; only real way to know for addresses that are valid physical
	  ;; and virtual would be by re-reading the location and
	  ;; checking for an error.  --- We don't do that yet.
	  ((eql (ldb %%vma-equals-pma ecc-log-address) %vma-equals-pma)
	   ;; vma=pma - virtual
	   (setf ecc-physical-address (%logdpb 0 %%vma-equals-pma ecc-log-address))
	   (setf (ldb %%ecc-log-access-mask ecc-log) ecc-error-virtual))
	  ((and (setq index (pht-lookup (extract-vpn ecc-log-address)))
		(zerop (pht-pending index)))
	   ;; valid vma, translate to physical
	   (setf ecc-physical-address
		 (%logdpb (pht-ppn index) %%pma-page-num ecc-log-address))
	   (setf (ldb %%ecc-log-access-mask ecc-log) ecc-error-virtual))
	  (t
	   ;;invalid virtual -- probably physical
	   (setf ecc-physical-address ecc-log-address)
	   (setf (ldb %%ecc-log-access-mask ecc-log)
		 ;; sanity-check that physical makes sense
		 (if (and (< (ldb %%ppn-mmpt-y ecc-ppn) (length *mmpt-y*))
			  (mmpt-lookup ecc-ppn))
		     ecc-error-physical
		     ;; somehow got by us (shouldn't happen)
		     ecc-error-unknown))))
    (when (> (+ *ecc-log-ptr* 2) *ecc-log-size*)
      (setq *ecc-log-ptr* -1)) ;;wrap-around 
    (setf (aref *ecc-error-log* (incf *ecc-log-ptr*)) ecc-log)
    (setf (aref *ecc-error-log* (incf *ecc-log-ptr*)) ecc-physical-address)
    (si:incf* *ecc-log-counter*)))

#+IMach
;;; This scans a page of physical memory using
;;; check-for-memory-ecc-error to report any pre-existing errors and to
;;; fix any errors found in this page
(defun scan-page-for-ecc-errors (ppn)
  (let ((pma (%make-physical-address (deposit-ppn ppn 0))))
    (with-block-registers (1)
      (loop with offset = 0
	    until (= offset page-size)
	    do
	(%write-internal-register (%pointer-plus pma offset) %register-bar-1)
	;; Flush and log log 
	(%funcall-in-aux-stack #'check-for-memory-ecc-error)
	;; unroll-block-forms is careful not to pre-fetch off the end of
	;; memory (it uses :prefetch nil for the last two iterations)
	(sys:unroll-block-forms ((- sys:page-size offset) 8)
	  (compiler:for-effect
	    (%block-read 1 :cycle-type %memory-raw)))
	(setq offset
	      (let ((next (%funcall-in-aux-stack #'check-for-memory-ecc-error ppn)))
		(if next
		    (1+ (ldb %%vma-word-offset next))
		    sys:page-size)))
	))))
) ;#-VLM
